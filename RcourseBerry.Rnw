\documentclass[xcolor=table,      handout ,    xcolor=dvipsnames]{beamer} % , handout, draft
\usetheme{Madrid} % Madrid, Warsaw, Berlin
\usecolortheme{beaver}

\usepackage[latin1]{inputenc} % windows
%\usepackage[utf8]{inputenc} %linux
\usepackage[T1]{fontenc} % for textbackslash
\usepackage[german, english]{babel}
\usepackage{float} % placing floats (table and figures) where they should be
\usepackage{lmodern} % make tiny font shape warnings within the beamer class diappear
\usepackage{tabu, multirow, url, hyperref, textcomp, amsmath, listings, datetime, graphicx, booktabs, xcolor, multicol, setspace}
\usepackage[absolute,overlay,showboxes]{textpos}

\hypersetup{pdfstartview={XYZ null null 1}}
\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue}

\setbeamertemplate{footline}[text line]{%
  \parbox{\linewidth}{\vspace*{-8pt}
  \href{https://github.com/brry/course\#slides}{github.com/brry/course} \hfill
  \hyperlink{toc}{TOC} ~~ \insertframenumber / \inserttotalframenumber~~~~~~~~~}}
\setbeamertemplate{navigation symbols}[only frame symbol]

\beamersetleftmargin{0.3cm}
\beamersetrightmargin{0.3cm}

% Reduce spacing in table of contents (toc) http://tex.stackexchange.com/questions/51452
\usepackage{etoolbox}
\makeatletter
\patchcmd{\beamer@sectionintoc}{\vskip1.5em}{\vskip0.1em}{}{} % vskip0.5em
\makeatother

% Remove Bullets and Numbers in TOC: http://tex.stackexchange.com/questions/54656
\setbeamertemplate{sections/subsections in toc}[default]

% white letters in enumerate bullet points
%\definecolor{stupidblue}{RGB}{51,51,178}
\setbeamercolor{item projected}{fg=white}%fg=blue,bg=red!75!black} % fg=white , bg=stupidblue
\setbeamercolor{frametitle}{fg=black}
% Block title color
\setbeamercolor{block title}{fg=white}%fg=blue,bg=red!75!black} % white
%\setbeamertemplate{item projected}[square]


% define an environment for the exercises
\newcounter{exercisecount}
\setcounter{exercisecount}{0}
\newenvironment{exercise}[1]
{% This is the begin code
\stepcounter{exercisecount}
\begin{block}{Exercise \arabic{exercisecount}: #1}
}
{% This is the end code
\end{block} }

\resetcounteronoverlays{exercisecount}

% format inline R command names in blue courier and lightgrey background:
\newcommand{\rcode}[1]{\texttt{\textcolor{Blue}{#1}}}
\newcommand{\key}[1]{\colorbox{gray!30}{\texttt{\textcolor{Blue}{#1}}}}


% links to files
\newcommand{\datalinkRaw}[1]{\href{https://raw.githubusercontent.com/brry/course/master/data/#1}{#1}}
\newcommand{\datalinkBlob}[1]{\href{https://github.com/brry/course/blob/master/data/#1}{#1}}
\newcommand{\datalinkText}[1]{\href{https://github.com/brry/course/blob/master/data/#1}{#1} 
                            {\footnotesize \textit{(rightclick \textbf{Raw}, save as)}}}
                           
% Format month with leading zero:
\newcommand{\leadingzero}[1]{\ifnum #1<10 0\the#1\else\the#1\fi}

% "#' " for doc files:
\newcommand{\doc}{\#\textquotesingle~}

% remove empty lines between code and output. apparently hard to get rid of without turning off syntax highlighting


%------------------------------------------------------------%
%------------------------------------------------------------%
\begin{document}
%------------------------------------------------------------%
%------------------------------------------------------------%

\AtBeginSubsection[]
{
\begin{frame}%[shrink]
{Outline}
\scriptsize
\tableofcontents[sectionstyle=show/shaded, subsectionstyle=show/shaded/hide]
\end{frame}
}

%\def\newblock{}	% beamer---natbib bugfix

<<setup, include=FALSE>>=
library(knitr)
# install packages, if not available
packinst <- function(n) if(!requireNamespace(n, quietly=TRUE)) install.packages(n)
dummy <- sapply(c("berryFunctions", "numbers", "TeachingDemos", "devtools",
                  "microbenchmark", "zoo", "extremeStat", "nortest", "xts",
                  "maptools", "rgeos", "sp", "geoR"), packinst)

# set global chunk options   maybe use   out.width='.55\\linewidth'
opts_chunk$set(fig.path='./fig/', fig.align='center', fig.show='hold', out.width='\\textwidth', fig.height=3, fig.width=6, cache=TRUE)
options(replace.assign=FALSE, width=50) # width 40 or 60

# set locale to US, which makes sure that eg month names are in english
# Sys.setlocale("LC_ALL", "US") # Windows
Sys.setlocale("LC_ALL","English")
Sys.setenv(LANG = "en") # english errors and warnings

# set r course working directory
# if(.Platform$OS.type=="unix") if(Sys.getenv("username") == "hydro")
# try(setwd("S:/Dropbox/Public/R_course_Berry"))
# if(Sys.info()["nodename"]=="GK-PC-2") setwd("C:/Users/boessenkool/Dropbox/Public/R_course_Berry")

ThemeBerry <- list(highlight="
\\definecolor{fgcolor}{rgb}{0, 0, 0}
\\newcommand{\\hlnum}[1]{\\textcolor[rgb]{0,0,0}{#1}}
\\newcommand{\\hlstr}[1]{\\textcolor[rgb]{0.545,0.137,0.137}{#1}}
\\newcommand{\\hlcom}[1]{\\textcolor[rgb]{0,0.392,0}{\\textit{#1}}}
\\newcommand{\\hlopt}[1]{\\textcolor[rgb]{0,0,0}{#1}}
\\newcommand{\\hlstd}[1]{\\textcolor[rgb]{0,0,0}{#1}}
\\newcommand{\\hlkwa}[1]{\\textcolor[rgb]{1,0,0}{\\textbf{#1}}}
\\newcommand{\\hlkwb}[1]{\\textcolor[rgb]{0,0,0}{#1}}
\\newcommand{\\hlkwc}[1]{\\textcolor[rgb]{1,0,1}{#1}}
\\newcommand{\\hlkwd}[1]{\\textcolor[rgb]{0,0,1}{#1}}
", background="#F5F5F5", foreground="black")
knit_theme$set(ThemeBerry)
rm(ThemeBerry)
@


%------------------------------------------------------------%
%------------------------------------------------------------%
\section{R course info}
%------------------------------------------------------------%
%------------------------------------------------------------%

<<slidebg, echo=F, fig.show='hide', fig.height=4.5>>=
library("berryFunctions")
par(mar=c(0,0,0,0))
plot(1:10, axes=F, type="n", ann=FALSE, xaxs="i", yaxs="i")
set.seed(007)
for(i in 1:50)
  {
  x <- seq(1,10, length=sample(10:100,1))
  y <- rescale(cumsum(rnorm(length(x)+30))[-(1:30)], -1, 13)
  lines(x, y, col=addFade(sample(colors(),1), 0.1), lwd=2)
  }
@

{\usebackgroundtemplate{\includegraphics[width=\paperwidth]{fig/slidebg-1.pdf}}
\begin{frame}
\begin{center}
    \begin{columns}
    \column{22.0em}
    \begin{block}{}{\Large ~Introductionary + advanced~ \includegraphics[width=0.7cm]{externalfig/Rlogo.png}~course}
    \end{block}
    \end{columns}
\vspace{1em}
Berry Boessenkool, \texttt{berry-b@gmx.de}\\
Hints and corrections are very welcome!\\[1em]
Download the current slides, source code and datasets at\\
\Large
\href{https://github.com/brry/course}{github.com/brry/course}\\[1em]
\normalsize
These slides are licenced under
\href{https://creativecommons.org/licenses/by/4.0}{\includegraphics[width=3em]{externalfig/ccby.png}},\\
so you can use the material freely as long as you cite me.\\[2em]
% \alert{guest account. example PC: ~ Einstein, 141.89.114.20\\user: gast\_20 ~ pw: 20-einstein. (mind the dot)}\\[1em]
\scriptsize
PDF created on \the\year-\leadingzero{\month}-\leadingzero{\day}, \currenttime\ \\[1em]
\end{center}
\end{frame}
}

%------------------------------------------------------------%

\begin{frame}{Outline}
%%%\hspace{0.9em} \hyperlink{titlepage}{R course Info}\\[0.4em]
\tableofcontents[hideallsubsections]
\label{toc}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{1. One-Session-Intro}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Intro, objects, vectors}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{\rcode{print("Hello world!")}}
\begin{itemize}[<+->]
\item Berry Boessenkool $\rightarrow$ berry-b@gmx.de
\item Geoecology @ Potsdam University
\item R Fan\onslide<+->atic \onslide<+-> since 2010
\begin{itemize}
\item Programming: \href{https://github.com/brry/rdwd\#rdwd}{\texttt{rdwd}},
      \onslide<+->\href{https://github.com/brry/extremeStat}{\texttt{extremeStat}}, 
      \onslide<+->\href{https://github.com/brry/OSMscale}{\texttt{OSMscale}}
\item Community: \href{https://www.meetup.com/de-DE/Berlin-R-Users-Group/}{\includegraphics[width=3em]{externalfig/BRUG_full.png}}
\item Training \& Consulting: \href{https://brry.github.io}{\includegraphics[width=0.5cm]{externalfig/Blogo.png}}

\end{itemize}
%\item \alert{Jump to beta distribution \hyperlink{beta}{example lecture}}
\item These slides were originally based on a one week course held in 2013 for \href{http://www.cawa-project.net/ru/news-detail/news/cawa-training-course-statistical-analysis-in-hydrology-introduction-into-r/}{CaWa} with Mathias Seibert (GFZ) in Bishkek, Kyrgyzstan
\item R installation instructions: \href{https://github.com/brry/course\#install}{github.com/brry/course\#install}
\item \alert{If we're proceeding too fast, please interrupt!}
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Why programming?}
\pause
\begin{itemize}[<+->]
  \item Data analysis
  \item Plotting
  \onslide<+->  \vspace{-0.5em} ~~~~~~~~~ \textit{Excel could do that, but is lacking} \vspace{0.5em}
  \item Awesomeness
    \begin{itemize}
    \item efficiency
    \item flexibility
    \item automatization
    \item transparency, reproducibility
    \item complex statistical procedures
    \item \textcolor{ForestGreen}{job chance advantage}
    \end{itemize}
\end{itemize}
\onslide<+-> Why R? (and not matlab, python, java, html, C++, fortran)
\begin{itemize}[<+->]
  \item Open Source $\rightarrow$ free!
  \item Large community $\rightarrow$ stunning lots of methods!
  \item Interpreter language $\rightarrow$ no compilation, human readable code
  \item The standard for data analysis in many universities and industries
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{In the future, programming will save you time!}
\includegraphics[width=0.99\textwidth]{externalfig/xkcd3.PNG}\\
I find that when someone's taking time to do something right in the present, they're a perfectionist with no ability to prioritize, whereas when someone took time to do something right in the past, they're a master artisan of great foresight. (\href{https://xkcd.com/974/}{xkcd.com/974})\\
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Course plan}
\hyperlink{plansessionone}{Jump to plan Session 1}\\[2em]

One slide about Rstudio, and then we'll finally start...

\end{frame}

%------------------------------------------------------------%

\begin{frame}{Integrated Development Environment (IDE): RStudio}
\label{iderstudio}
  \begin{figure}
  \includegraphics[width=0.95\textwidth]{./externalfig/Rstudio2.png}
  \end{figure}
\label{rstudio}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Get started in R}
\pause
\begin{exercise}{R is an awesome calculator}
In the console, calculate ~ 21+21 ~,~ 7*6 ~ and ~ $\frac{0,3}{4}*\sqrt{313600}$\\
\textit{If you don't know how to compute a square root in R, you can google it!}
\end{exercise}
\vspace{-1em}
\pause
<<sol_Rcalc, eval=F>>=
21+21 ; 7*6 ; 0.3/4*sqrt(313600)
@
\vspace{-1em}
\pause
\begin{itemize}[<+->]
  \item objects: assignment ~ \rcode{$<-$} ~ Rstudio Keyboard shortcut:  \key{ALT} + \key{-}  \\
        \rcode{nstudents <- 15\\nstudents\\nstudents > 12}
  \item What's a good object name? \onslide<+-> $\rightarrow$ short, but explanatory,
        \onslide<+-> lowerCamelStandard\_or\_underscore are good naming conventions
  \item comments: \texttt{\textcolor[rgb]{0,0.392,0}{\# everything after a hashtag is not executed.}}
  \item scripts: Rstudio
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Objects: vectors}
\begin{itemize}[<+->]
  \item To create a vector with values, use the syntax\\
  \rcode{values <- c(3, -11, 13, 5.94)} \texttt{\textcolor[rgb]{0,0.392,0}{\# \textbf{c}oncatenate, \textbf{c}ombine}}
  \item To obtain a subset (=indexing), use square brackets: \rcode{values[2]}
\end{itemize}
\onslide<+->
\begin{exercise}{Vector indexing}
\begin{enumerate}
  \item Create a vector with body sizes of people around you. You can also use the values 1.75, 1.76, 1.83, 1.84, 1.77, 1.76, 1.77, 1.66, 1.86, 1.76. Assign it to an object with a useful name (\rcode{YourObject} is not one!).
  \item What does \rcode{3:6} create? What does \rcode{YourObject[3:6]} do?
  \item What does \rcode{YourObject[-4]} do?
  \item BONUS (for fast people): Analyze the descriptive statistics: \rcode{mean(YourObject), median, min, max, range, quantile}
  \item BONUS 2: Help your peers - there's no reason to be bored ;-)
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Vector task solutions}
<<vectsol, eval=FALSE>>=
size <- c(1.75, 1.76, 1.83, 1.84, 1.77, 1.76,
          1.77, 1.66, 1.86, 1.76)
3:6 # A vector with consecutive integers
size[3:6] # Select the corresponding elements of a vector
size[-4] # Select all but the fourth value
@
<<vectsol2, echo=-1, size="scriptsize">>=
size <- c(1.75, 1.76, 1.83, 1.84, 1.77, 1.76, 1.77, 1.66, 1.86, 1.76)
c(mean(size), median(size), min(size), max(size)); range(size); quantile(size)
@

\rcode{mean} and \rcode{median} are similar, hinting at a symmetric data distribution\\
\rcode{range} returns a composite of \rcode{min}imum and \rcode{max}imum\\
\rcode{quantile} returns \href{http://lmgtfy.com/?q=quantile}{quantiles} (now that is surprising...)
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Files, data.frames}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Reading files}
<<datageneration, echo=F, eval=F>>=
set.seed(42)
age1 <- runif(50, 5, 25)
height1 <- 2.4e-05*age1^3 - 0.051*age1^2 + 3*age1 - 7.6 + rnorm(50, sd=3)
age2 <- runif(50, 5, 25)
height2 <- 2.4e-05*age2^3 - 0.051*age2^2 + 2.5*age2 - 7.6 + rnorm(50, sd=3)
treesize <- data.frame(age=round(c(age1,age2),1),
                       height=round(c(height1,height2),1),
                       measured=rep(c("A","B"), each=50))
treesize <- treesize[sample(1:100), ]
write.table(treesize, file="data/treesize.txt", quote=F, row.names=F)
plot(height~age, data=treesize, col=measured)
@
\onslide<+->
\begin{exercise}{Reading files}
Copy the file \datalinkText{treesize.txt} and tell R where to look for it with:\\
\rcode{setwd("C:/path/to/input")} \texttt{\textcolor[rgb]{0,0.392,0}{ \# change back- to forwardslashes}}\\
  \onslide<+-> Read the file into R with the command \rcode{read.table}, assigning it to an object with a good name.\\
  \onslide<+-> Use the documentation to find out the correct settings of the arguments:\\
  \onslide<+-> \rcode{help(read.table)}, \rcode{?read.table}, or press F1.\\
  \onslide<+-> If R tells you "no such file" exists, check the output of \rcode{dir()}.\\
  \onslide<+-> Check the object with \rcode{head(YourObject)}.\\
  \onslide<+-> \rcode{str(YourObject)} must yield the column data types: \texttt{num, num, factor}. \\
  \onslide<+-> You need to set the argument \texttt{header}.
  \end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: Reading files}
<<solreadfile, eval=F>>=
treesize <- read.table(file="treesize.txt", header=TRUE)
str(treesize)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Objects: data.frames}
\vspace{-0.5em}
\begin{itemize}[<+->]
  \item For tables with different data types (numbers, characters, categories, integers), R has the object type data.frame: \\\rcode{data.frame(count=c(2,6,5), type=c("a","k","k"))}
  \item \rcode{read.table} also returns a data.frame
  \item If we have the object \rcode{DF}, we can subset with \rcode{DF[rows,columns]}
  \item \rcode{DF[1,2:4]; \onslide<+-> DF[2, ]; \onslide<+-> ~ DF[ ,"name"]; \onslide<+-> DF\$name}
  \item Logical values: \rcode{vect[c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE)]}
\end{itemize}
\onslide<+->
\begin{exercise}{Data.frame indexing}
  From the dataset \rcode{treesize} from the previous exercise, obtain:
  \begin{enumerate}
  \item The first 5 values in column 2
  \item The maximum "Height" (the maximum of the values in that column)
  \item For each entry: is the measurement equal to (\rcode{==}) A?
  \item BONUS 1: The height entries for trees older than 23.5 years
  \item BONUS 2: All rows, excluding rows 3,7,8,9,...,90
  \end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: subsetting data.frames I}
<<sol_treessubset, eval=T, echo=-(1:2), size="scriptsize">>=
options(width=80)
treesize <- read.table(file="data/treesize.txt", header=TRUE)
treesize[1:5, 2]
max(treesize$height)  ;   max(treesize[ ,"age"])

treesize$measurement=="A"
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: subsetting data.frames II}
<<sol_treessubset2, size="scriptsize">>=
treesize[ treesize$age >= 23.5 , "height"]
@
<<sol_treessubset3, eval=F, size="scriptsize">>=
treesize[ -c(3,7:90) , ]

#
@
\vspace{-3em}
<<sol_treessubset4, echo=F, size="scriptsize">>=
options(width=50)
head(treesize[ -c(3,7:90) , ],12); cat("...")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Plotting}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Plotting I}
General code for scatterplots: \rcode{plot(x, y, ...)}
\pause
<<plot_indo1, echo=-1>>=
par(mar=c(2.8,2.8,1.5,0), mgp=c(1.8,0.7,0))
plot(x=Indometh$time, y=Indometh$conc,
     col="orange", pch=16, main="Awesome Graph!")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plotting I}
General code for scatterplots: \rcode{plot(x, y, ...)}
<<plot_indo2, echo=-(1:2)>>=
par(mar=c(2.8,2.8,1.5,0), mgp=c(1.8,0.7,0))
plot(x=Indometh$time, y=Indometh$conc,
     col="orange", pch=16, main="Awesome Graph!")
points(4, 1.5, pch=22, bg="yellow", cex=4, col="red")
# PointCHaracter, BackGround, Character EXpansion
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plotting I}
General code for scatterplots: \rcode{plot(x, y, ...)}
<<plot_indo3, echo=-(1:3)>>=
par(mar=c(2.8,2.8,1.5,0), mgp=c(1.8,0.7,0))
plot(x=Indometh$time, y=Indometh$conc,
     col="orange", pch=16, main="Awesome Graph!")
points(4, 1.5, pch=22, bg="yellow", cex=4, col="red")
lines(x=c(2,5,6,7), y=c(1,2.3,-3,1),
      col="blue", type="b", lwd=5)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plotting II: Our treesize dataset}
\vspace{-1em}
%Code to read the file:
<<readtreesize, eval=F, size="small">>=
treesize <- read.table(file="data/treesize.txt", header=TRUE)
@
\pause
%General code for scatterplots:
<<generalplot, eval=FALSE>>=
plot(x=xvalues, y=y_values, xlab="nice axis label",
     main="graph title", las=1)
@
\pause
\begin{exercise}{Scatterplots, sample distribution graphs}
\begin{enumerate}%[<+->]
  \item Plot tree height over age.
  \item Add labels to the plot.
  \item Change the point character (\rcode{pch}) and color (\rcode{col}).
  \item BONUS 1: Use a vector for colors, e.g. treesize\$measurement
  \item BONUS 2: Compare the histogram (\rcode{hist}) of the heights with the \rcode{boxplot} and \rcode{quantile(x, probs=c(0.1, 0.8))}.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Scatterplots}
<<solscatplot, fig.show="hide", size="footnotesize", fig.height=4>>=
treesize <- read.table(file="data/treesize.txt", header=TRUE)

plot(treesize$age, treesize$height)
plot(treesize$age, treesize$height, las=1, ylab="Tree height [m]",
     xlab="Tree age [years]", col=treesize$measurement,
     main="Older trees are larger", pch=3)

quantile(treesize$height, probs=c(0.1, 0.8))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Scatterplot}
\includegraphics[width=\linewidth]{fig/solscatplot-2.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Histogram}
<<solscathist>>=
hist(treesize$height, col="purple", breaks=20, las=1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Boxplot}
<<solscatbox>>=
boxplot(treesize$height, col="cyan", horizontal=TRUE, 
        notch=TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{commonly needed \rcode{plot} arguments}
<<plotoverview, eval=FALSE>>=
plot(x, y, # point coordinates
col="lightblue", # point color
pch=0, # point character (symbol)
xlab="My label  [km]", ylab="", # axis labels
main="Graph title", # title
cex=1.8, # character expansion (symbol size)
type="l", # draw lines instead of points
lwd=3, # line width (thickness of lines)
las=1, # label axis style (axis numbers upright)
xaxt="n" # axis type (none to suppress axis)
)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Packages, regression}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{R Packages}
\begin{itemize}[<+->]
\item Many people write code for specific tasks and publish it on CRAN, the Comprehensive R Archive Network
\item Packages for a range of topics: \href{http://cran.r-project.org/web/views/}{cran.r-project.org/web/views}
\item All $>$10'500 available packages: \href{http://cran.r-project.org/web/packages/}{cran.r-project.org/web/packages}
\item \rcode{install.packages("ggplot2")} to download and install.\\
      \footnotesize (only needs to be executed once, works on user level, no admin rights required)\\
      You can do this in Rstudio \normalsize
\item \rcode{library("ggplot2")} to load it \\
      \footnotesize (needed in every new R session) Put this in the script for reproducibility \normalsize
\item Better to use the \rcode{package::function} syntax
\item Regularly run \rcode{update.packages()} or use the Rstudio button
\item Rarely needed: \rcode{remove.packages("packagename")}
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Packages and linear regression}
\begin{exercise}{Packages, linear regression}
\begin{enumerate}
  \item Install and load the package \rcode{berryFunctions}
  \item Pass the \datalinkText{treesize.txt} data to \rcode{linReg}.
        Don't use (x,y) coordinates, but a (y\textasciitilde x) formula, read as "y dependent on x".
        Use the \texttt{data} argument as described in the "Examples" section of the \rcode{linReg} manual.
        Describe the resulting graph (height vs age).
  \item Feed the data into \rcode{lm}, assign the output to an object (useful name!).
  \item Briefly explain the \rcode{summary} of the linear model.
  \item BONUS1: Look into the source code of \rcode{linReg}. 
        % \textit{If you don't know how to view the source code of a function in R, you can google it!}
        You can print the function by calling it without brackets.
        You can also open it on github with \rcode{berryFunctions::funSource}.
  \item BONUS2: What is the backbone for the calculation in \rcode{linReg}?
  \item BONUS3: install \href{https://github.com/brry/rskey\#rskey}{rskey}, 
        set a keyboard shortcut for \rcode{funSource} and use it to get the source code of some function.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Linear regression}
\vspace{-1em}
<<sollinreg, eval=FALSE, size="footnotesize">>=
library("berryFunctions")
linReg(height~age, data=treesize)
linReg
funSource(linReg) # berryFunctions/R/linReg.R  -  working horse: lm
linear_model <- lm(height~age, data=treesize)
summary(linear_model)
@
\vspace{-1em}
\small
\href{http://blog.yhat.com/posts/r-lm-summary.html}{blog.yhat.com/posts/r-lm-summary.html}\\
\href{http://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output}{stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output}
\normalsize
<<sollinreg2, echo=F, fig.height=2.1>>=
treesize <- read.table(file="data/treesize.txt", header=TRUE)
par(mar=c(2.5,3,2,1), mgp=c(2,0.7,0))
library("berryFunctions")
linReg(height~age, data=treesize, pos1="topleft", xlab="", inset=-0.03)
title(xlab="age", mgp=c(1.5,0,0))
@
\end{frame}

%' %------------------------------------------------------------%
%' %------------------------------------------------------------%
%' \subsection{Packages, normality test}
%' %------------------------------------------------------------%
%' %------------------------------------------------------------%
%'
%' \begin{frame}[fragile]{Test for normality of a distribution}
%' \pause
%' \begin{itemize}[<+->]
%'   \item If a population is normally distributed, it is described by only two parameters: the mean (position) and the sd (width, dispersion) of the bell shaped curve.
%'   \item This is an important assumption for many classical statistical methods.
%'   \item Whether a dataset is normally distributed can be checked with a histogram (visually effective, but the class limits are subjective), with qqplots (I don't find them very intuitive), or with statistical tests.
%' \item
%' <<normaltest, eval=F>>=
%' data <- rnorm(1000, mean=97, sd=8.9)
%' shapiro.test(data)
%' ks.test(data, "pnorm", mean(data), sd(data))
%' # if p > 0.05: accept the Null-hypothesis
%' # that data are normally distributed.
%' @
%' \end{itemize}
%' \end{frame}
%'
%' %------------------------------------------------------------%
%'
%' \begin{frame}{Packages, normality test}
%' \begin{itemize}[<+->]
%'   \item Many people write code for specific tasks and publish it on CRAN, the Comprehensive R Archive Network
%'   \item \rcode{install.packages("ggplot2")} to download and install\\ (only needs to be executed once, requires internet connection)
%'   \item \rcode{library("ggplot2")} to load it (in every new R session)
%' \end{itemize}
%' \onslide<+->
%' \begin{exercise}{Packages, normality test}
%' \begin{enumerate}
%'   \item Install and load the package \rcode{nortest}
%'   \item Open the package documentation (see \rcode{?help})
%'   \item Run and compare several tests for normality: \rcode{shapiro.test}, \rcode{ks.test}\\
%'         Lilliefors (Kolmogorov-Smirnov), Anderson-Darling, Cramer-von Mises, Pearson chi-square, Shapiro-Francia
%'   \item BONUS: With random numbers generated from a normal distribution (\rcode{rnorm}),
%'         study the sensitivity / stability of each of the tests (What do you obtain in repeated application?).
%' \end{enumerate}
%' \end{exercise}
%' \end{frame}
%'
%' %------------------------------------------------------------%
%'
%' \begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: normality test}
%' \vspace{-1em}
%' <<solnortest, eval=TRUE, size="footnotesize">>=
%' if(!requireNamespace("nortest")) install.packages("nortest")
%' library(nortest)          # with Lilliefors-correction!
%' help(package="nortest")
%' d <- treesize$height[treesize$measurement=="A"]
%' lillie.test(d)  # Lilliefors (Kolmogorov-Smirnov) test for normality
%' ad.test(d)      # Anderson-Darling test for normality
%' @
%' \end{frame}
%'
%' %------------------------------------------------------------%
%'
%' \begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: normality test}
%' <<solnortest2, eval=TRUE, size="tiny">>=
%' cvm.test(d)     # Cramer-von Mises test for normality
%' pearson.test(d) # Pearson chi-square test for normality
%' sf.test(d)      # Shapiro-Francia test for normality
%' @
%' \end{frame}

%------------------------------------------------------------%

\begin{frame}{Time to put all of this into practice}
\begin{exercise}{Reading files, subsetting, comparing}%1
\begin{enumerate}
  \item Start a new session of R. Read in the tree size data.
  \item Check that everything is read correctly with \rcode{str}.
  \item \rcode{which} rows of the data.frame have measurement equal to (\rcode{==}) B?
  \item Plot the linear regression for measurement method B, then add the points and regression line for A in a different color and shape.
  \item BONUS 1: use \rcode{boxplot} with a formula (\rcode{height\textasciitilde measurement})
               for an automatic boxplot comparison with median difference notches.
 \item BONUS 2: Visually compare the effect of Girth and Height on Volume in the dataset \rcode{trees}. Here's one idea (of many possible): Plot with two panels below each other (\rcode{par(mfrow=c(2,1)}), with the linear regression plots (\rcode{berryFunctions::linReg}) for each variable. Make it look nice with the graphical \rcode{par}ameters \texttt{mar} and \texttt{mgp}, as well as by specifying some of the linReg arguments.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Reading files, subsetting}
<<introsol1, eval=FALSE, size="footnotesize">>=
setwd("D:/my/path")
treesize <- read.table(file="data/treesize.txt", header=TRUE)
str(treesize)
@
\vspace{-1em}
<<introsol2, fig.show="hide", eval=T, size="footnotesize", fig.height=4>>=
which(treesize$measurement=="B")
treeA <- treesize[treesize$measurement=="A", ]
treeB <- treesize[treesize$measurement=="B", ]
library("berryFunctions")
linReg(height~age, data=treeA, pos1="topleft")
linReg(height~age, data=treeB, add=T, colline="blue",
       pos1="bottomright", inset=0.05)
points(height~age, data=treeB, pch=3, col="blue")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Plotting, linear Regression}
\includegraphics[width=.99\textwidth]{fig/introsol2-1.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.BONUS 1}
<<introsol3, fig.height=3, echo=-1>>=
par(mar=c(3,3,0.5,0.5), las=1)
boxplot(height~measurement, data=treesize,
        col=c("blue","orange"), notch=TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.BONUS 2}
<<introsol4, size="scriptsize", fig.height=3.5, fig.width=6, out.width='.95\\textwidth'>>=
par(mfrow=c(2,1), mar=c(3,3,1.5,0.5), mgp=c(1.9,0.7,0), las=1)
linReg(Volume~Height, data=trees, col="blue", pos1="topleft")
linReg(Volume~Girth, data=trees, col="forestgreen", pos1="topleft")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{2. Getting started: Background, GUI and first steps}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Background information}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{R - What and Why?}
\pause
\vspace{-0.5em}
\begin{itemize}%[<+->]
\item R is a standard environment for statistical computing
\item and an object-oriented programming language.
\item It is developed and maintained by the R development core team
\item and has thousands of add-on packages written by the community.
\item There are mailing lists where users (\& developers) help users
\item and blogs to communicate analysis and coding to the public.
\item R allows complex data analysis of big data sets with current methods
\item and the creation of advanced professional (even interactive) graphics.
\item Coding and programming forces you to keep track of your work
\item and allows you to efficiently customize and automatize your analysis.
\item R is very versatile: you can write your own functions and packages,
\item implement new methods and make them available to everyone.
\item Being capable of programming helps finding a job
\item and the best part: \textcolor{green}{R is open source and free!}
\end{itemize}
% \pause
\small \href{http://fantasyfootballanalytics.net/2014/01/why-r-is-better-than-excel.html}{fantasyfootballanalytics.net/2014/01/why-r-is-better-than-excel.html}
\href{http://thegrantlab.org/bio3d/tutorials/79-static-content/85-why-use-r}{thegrantlab.org/bio3d/tutorials/79-static-content/85-why-use-r}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{interpreter language - no compilation}
\pause
\centering
\includegraphics[height=0.65\textheight]{externalfig/compiling.png}\\
\href{https://xkcd.com/303/}{xkcd.com/303}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}{R is growing increasingly popular}
%   \begin{figure}[h]
%   	\begin{center}
% 		\includegraphics[width=.8\linewidth]{./externalfig/jobgraph.png}
% 		\caption{\href{http://www.indeed.com/jobanalytics/}{www.indeed.com/jobanalytics}}
% 		\label{fig:r-jobs}
%     \end{center}
% 	\end{figure}
% \end{frame}

%------------------------------------------------------------%

\begin{frame}{Where to get R}
%\pause
Instructions online: \href{https://github.com/brry/course\#install}{github.com/brry/course\#install}\\[1em]
\begin{itemize}%[<+->]
%   \item base R itself: \href{https://cloud.r-project.org/}{r-project.org}.\\
%         \href{https://cran.r-project.org/bin/linux/ubuntu/README.html}{Official} and \href{https://www.r-bloggers.com/how-to-install-r-on-linux-ubuntu-16-04-xenial-xerus/}{helpful} hints for Linux Ubuntu users.
%   \item \href{https://www.rstudio.com/products/rstudio/\#Desktop}{R-Studio} (widely spread, easy to use)
%   
\item Editor alternative to Rstudio: \href{http://sourceforge.net/projects/tinn-r/}{Tinn-R}
\item Only for Windows OS, but flexible window arrangement
\item Needs some initial tweaking, see \href{https://rclickhandbuch.wordpress.com/install-r/tinn-r_english}{Berry's TinnR Page} % pdf cannot be completed without this percent sign
\item Since Rstudio has become so incredibly awesome, you should use it!
\end{itemize}
\label{installR}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Rstudio + Git}
%------------------------------------------------------------%
%------------------------------------------------------------%

% \begin{frame}{Working with R: Basic R GUI and Command line}
%   \begin{figure}[h]
%   \includegraphics[width=\textwidth]{./externalfig/rgui.png}
%   \end{figure}
% \end{frame}

%------------------------------------------------------------%

\begin{frame}{RStudio overview}
  \begin{figure}
  \includegraphics[width=0.95\textwidth]{./externalfig/Rstudio.png}
  \end{figure}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{RStudio configuration}
Recommended settings for reproducible research under\\
\alert{Rstudio - Tools - Global Options - General}\\
\textbf{OFF}: Restore .Rdata into workspace at startup\\
Save workspace to .RData on exit: \textbf{NEVER}\\[0.5em]
\pause
\textit{Instead use \rcode{save(object, file="object.Rdata")} after long computations.
You can load them later with \rcode{load("object.Rdata")}.}\\[0.5em]
\pause
More at \href{https://github.com/brry/course\#settings}{github.com/brry/course\#settings}\\[0.5em]
\pause
\href{https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts}{keyboard shortcuts} (\key{ALT}+\key{SHIFT}+\key{K})
\pause
\begin{enumerate}[<+->]
\item \key{CTRL} + \key{ENTER} (in source script) send line/selection to console 
\item \key{CTRL} + \key{UP} (in console) command history
\item \key{CTRL} + \key{SHIFT} + \key{N} new R script
\item \key{CTRL} + \key{O} open file
\item \key{CTRL} + \key{S} save script
\item \key{CTRL} + \key{TAB} next Tab
\item \key{CTRL} + \key{SHIFT} + \key{TAB} previous Tab
\end{enumerate}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Rstudio Tips and Tricks}
\begin{enumerate}[<+->]
\item \href{https://rviews.rstudio.com/2016/11/11/easy-tricks-you-mightve-missed/}{RStudio IDE Easy Tricks You Might've Missed}
and \href{https://rviews.rstudio.com/categories/tips-and-tricks/}{rviews.rstudio.com/categories/tips-and-tricks}
\item Work with Rstudio projects!
\item \key{ALT} + mouse for multiline cursor. \textit{or}: \key{CTRL} + \key{ALT} + \key{UP}/\key{DOWN}
\item \key{CTRL} + \key{1} cursor to panel \scriptsize{(1:source, 2:console, 3:help, 4:history, 5:files, 6:plot...)}
\item \key{CTRL} + \key{SHIFT} + \key{1}/\key{2}/\key{3}/\key{...} panel full view
\item \key{ALT} + \key{UP}/\key{DOWN} move line of code
\item \key{CTRL} + \key{SHIFT} + \key{P} rerun previous code region
\item \key{CTRL} + \key{SHIFT} + \key{S}/\key{ENTER} source document
\item \key{CTRL} + \key{SHIFT} + \key{C} (un)comment lines
\item \key{CTRL} + \key{SHIFT} + \key{M} insert pipe operator
\item tearable panes
\item \key{CTRL} + \key{SHIFT} + \key{O} Document outline
\end{enumerate}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Install git (program for version control)}
\label{installGit}
\begin{enumerate}
\item Create a github account at \url{https://github.com/join}\\[1em]
\item Download and install git, see \url{https://git-scm.com/downloads}\\[1em]
\item Connect git to Rstudio: up to \rcode{git config user.name} at \url{https://www.r-bloggers.com/rstudio-and-github}\\[1em]
\item Excellent tutorial on git in general (mostly without Rstudio): \url{http://kbroman.org/github\_tutorial}
\end{enumerate}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Clone github repo from within Rstudio I}
\footnotesize
Go to \url{https://github.com/brry/course} -> \colorbox{Green}{\textcolor{White}{Clone or download}} -> Copy URL
\begin{figure}
\includegraphics[width=0.8\textwidth]{./externalfig/git_clone_1.PNG}
\end{figure}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Clone github repo from within Rstudio II}
\footnotesize
Rstudio - File - New Project - Version Control - Git\\
paste the URL, set the subdirectory and create project.\\
I recommend to keep the Project directory name for your own projects.
\begin{figure}
\includegraphics[width=0.9\textwidth]{./externalfig/git_clone_Rstudio.png}
\end{figure}
From now on, get the latest version of my slides with a single click on \key{Pull}:
\begin{figure}
\includegraphics[width=0.4\textwidth]{./externalfig/git_clone_6.PNG}
\end{figure}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{Tinn R}
%   \begin{figure}[h]
%     \begin{center}
%     \includegraphics[width=.8\linewidth]{./externalfig/TinnR_gui.PNG}
% 		\caption{screenshot Tinn-R}
% 		\label{fig:how to start R from Tinn-R}
%     \end{center}
% 	\end{figure}
% <<trpaths, eval=FALSE, size="scriptsize">>=
% # enable sending of blocks up to the next blank line:
% .trPaths <- paste(Sys.getenv('LOCALAPPDATA'),
% '\\Temp\\Tinn-R', c('', 'search.txt', 'objects.txt',
% 'file.r', 'selection.r', 'block.r','lines.r'),sep='\\')
% # write this in  C:/Program Files/R/R-3.2.2/etc/Rprofile.site
% @
% \end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Getting help}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Getting help: Inside R}
  R-Help
<<help-r, eval=FALSE, echo=TRUE, tidy=FALSE>>=
help("apply") # get help for the function
?apply # The same. saves typing effort.
# Press F1 while the cursor is at a command.

apropos("apply")
help.search("apply")
??apply

help.start() # html help Manuals, Material, search engine
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Getting help: Outside R}
\pause
\begin{itemize}[<+->]
  \item \href{https://cran.r-project.org/manuals.html}{R-Manuals} for introduction to the language
  \item R Wiki: \href{http://rwiki.sciviews.org/}{rwiki.sciviews.org}
  \item Ref Cards:
    \href{https://www.rstudio.com/wp-content/uploads/2016/09/r-cheat-sheet-1.pdf}{base} and
    \href{https://www.rstudio.com/wp-content/uploads/2016/02/advancedR.pdf}{advanced} cheatsheets from
    \href{https://www.rstudio.com/resources/cheatsheets/}{Rstudio},\\
    RefCards originally by Tom Short from
    \href{https://github.com/jonasstein/R-Reference-Card/raw/master/R-refcard.pdf}{Stein} (recommended),
    \href{https://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}{Baggot},
    \href{http://www.u.arizona.edu/~kuchi/Courses/MAT167/Files/R-refcard.pdf}{Tanbakuchi},
    \href{http://atrey.karlin.mff.cuni.cz/~morf/vyuka/pas/materialy/R-refcard.pdf}{cuni} or
    \href{http://statmaster.sdu.dk/bent/courses/ST501-2011/Rcard.pdf}{Joergensen}
	\item \href{www.rseek.org}{rseek.org} for R related internet search
  \item \href{www.StackOverflow.com}{StackOverflow} for programming questions <-- \alert{main resource}
  \item \href{www.CrossValidated.com}{CrossValidated} for statistical questions
	\item Mailing lists: ask other experienced users for help
	\begin{itemize}
  \item \href{http://www.r-project.org/mail.html}{R-help mailing list}
  \item \href{http://r.789695.n4.nabble.com/}{Nabble}: Forum-like view of the r-help mailing list
  \item ONLY post on mailing lists when all other options are exploited and you are sure there's no answer out there. FIRST read the \href{http://www.r-project.org/posting-guide.html}{posting guide}.
\end{itemize}
\end{itemize}
\label{refcards}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{R related internet search}
%   \begin{figure}[h]
%     \begin{center}
% 		\includegraphics[width=.75\linewidth]{./externalfig/rseek.png}
% 		\caption{\href{http://www.rseek.org}{www.rseek.org}}
% 		\label{fig:rseek}
%     \end{center}
% 	\end{figure}
% \end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Good References, books }%(\datalinkRaw{books.zip})}
\vspace{-0.8em}
\begin{itemize}[<+->]
\item Grolemund \& Wickham (2017) \href{http://r4ds.had.co.nz/}{R for Data Science}
\item J. Adler (2010): R in a Nutshell
\item U. Ligges (2008): Programmieren mit R (German)
\item M. Crawley (2007): The R-book
\item H. Wickham (2014) \href{http://adv-r.had.co.nz}{Advanced R}
\item H. Wickham (2015) \href{http://r-pkgs.had.co.nz}{R Packages}
\item domain specific: \href{http://www.crcpress.com/browse/series/crctherser}{Chapman and Hall R Series}
\item Many more listed at \href{https://github.com/RomanTsegelskyi/rbooks}{github.com/RomanTsegelskyi/rbooks}
\item Review list at \href{https://web.archive.org/web/20130619094650/http://ecotope.org/blogs/page/R-Book-Review.aspx}{ecotope.org, through the wayback machine}
\end{itemize}
\onslide<+-> Tutorials:
\begin{itemize}[<+->]
%\item \href{http://RclickHandbuch.wordpress.com}{RclickHandbuch.wordpress.com} (German)
\item \href{https://www.edx.org/course/introduction-r-programming-microsoft-dat204x-0#!}{Microsoft + Datacamp} (best course I know of, with login, but free)
\item \href{http://tryr.codeschool.com/levels/1/challenges/1}{tryR.codeschool.com} (interactive)
\item \href{http://stat545-ubc.github.io/topics.html}{STAT 545}
\end{itemize}
\label{books}
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{R syntax}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{get started, comments}
Please start R via the editor you like.\\[\baselineskip]
Comments start with a hash key \# %\textbf{\#}\\

<<comments, eval=TRUE, echo=TRUE, tidy=FALSE>>=
17-42 # This is a comment, thus not executed
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Please calculate the following tasks}
\begin{exercise}{Basic operators} %ex1
\begin{enumerate}
  \item 4 * 9\\
  \item 2 + 4,8 (International decimal sign: ".")\\
  \item $3^2$\\
  \item $\frac{\pi}{2}$\\
  \item sinus of 15$\,^{\circ}$. Must be 0.26. Remember: $ radians = degrees*\frac{\pi}{180\,^{\circ} } $\\ % $ for math\\
  \item $\sqrt{81}$  (square root)\\
  \item $|-12|$ (absolute value)\\
  \item log(100) (--$>$ should return 2, as $10^2$ = 100 )\\
  \item 5! (factorial)\\
  \item $e^3$ (exponential function)\\
  \item Bonus: How is 3.91 * $10^{ -3}$ written in scientific notation?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1-8: Basic operators}
<<ex1sola, eval=FALSE>>=
4*9 # this is our first calculation with a comment
2 + 4.8
3^2
pi/2
sin(15*pi/180)
?sqrt # get the offline help about the function sqrt
sqrt(81) # square root
abs(-12) # absolute value
log(100)
help(log) # natural logarithm
log10(100) # log base 10
log(100, base=10) # another way
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.9-11: Basic operators}
<<ex1solb, eval=FALSE>>=
factorial(5)
e^3 # does not work
??exponential
exp(3) # exponential function
exp(1) # the value of e
3.91 * 10^-3
3.91e-3 # no spaces possible in scientific notation
help.start() # offline search, manuals, etc
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Source code of R commands}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}
Source code: \href{https://github.com/wch/r-source/tree/trunk/src/library}{github.com/wch/r-source/src/library}/base (or stats, utils, ...)\\
CRAN packages source code: \href{https://github.com/cran}{github.com/cran}\\
HTML Documentation: \href{https://www.rdocumentation.org/packages/berryFunctions/versions/1.12.3/topics/colPoints}{www.rdocumentation.org}\\[0.5em]

\href{http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function}{excellent post}

ncol - .Primitive("dim") - NROW
head.matrix
https://github.com/wch/r-source/blob/trunk/src/library/utils/R/head.R
https://github.com/wch/r-source/blob/trunk/src/library/base/R/matrix.R

\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{3. Objects}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Assignments}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Assignment:  Create an object with data in the workspace I}
<<assignmentsa>>=
a <- 15.4
@
\onslide<2->
<<assignmentsb>>=
a
@
\onslide<3->
<<assignmentsc>>=
a > 2 # is a bigger than 2?  --> logical value (boolean)
@
\onslide<4->
<<assignmentsd>>=
A # not an existing object (R is case sensitive)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Assignment:  Create an object with data in the workspace II}
\vspace{-0.5em}
Don't assign to existing objects or functions like \rcode{mean, c, T, data, sin}; 
\onslide<+-> Later on, you will hardly be able to distinguish what object 
(original or custom) you are referring to.\\ 
% \onslide<+-> (Advanced users: your own funtions will be lost if you overwrite them).\\
\onslide<+->
As R is Case SeNsitivE, \rcode{Data} would be OK, but it's not useful. 
Use object names that are short, but still meaningful.\\
\onslide<+->
One convention is lowerCamel:\\
\rcode{dailyRainBerlin} is short and readable through capital letters.
\vspace{-0.5em}
\onslide<+->
<<rstudio_assign>>=
# Rstudio: press 'ALT' + '-'  for   " <- "
@
\onslide<+->
Don't use \rcode{=} for assignments. Most R users connotate "=" with function 
arguments and prefer " <- " for objects (\href{http://google-styleguide.googlecode.com/svn/trunk/Rguide.xml}{style guide}).
Also, "=" is only allowed on the top level:\\ \onslide<+->
\rcode{median(x <- 1:10)} also creates the object in \rcode{globalenv()}, 
while \rcode{median(x=1:10)} does not. This is used in \rcode{NCOL}, for example.\\
\onslide<+->
\footnotesize{
\href{http://blog.revolutionanalytics.com/2008/12/use-equals-or-arrow-for-assignment.html}{http://blog.revolutionanalytics.com/2008/12/use-equals-or-arrow-for-assignment.html}
\href{https://csgillespie.wordpress.com/2010/11/16/assignment-operators-in-r-vs/}{https://csgillespie.wordpress.com/2010/11/16/assignment-operators-in-r-vs/}}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Vectors, indexing}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Vectors I}
<<cleanWorkspace, echo=FALSE>>=
rm(list=ls())
@
In R, Vectors are not geometric constructs, but an ordered set of values.\\
\onslide<+->
Create a vector with \rcode{c} (stands for Combine or Concatenate), separating each entry with a comma:
\onslide<+->
<<vectors1, eval=TRUE, echo=TRUE>>=
b <- c(3, 7, -2.5, 11, 3.8, 9)
@
\onslide<+->
spaces make code easier to read:
<<CodeReadability>>=
b<-c(3,7,-2.5,11,3.8,9)
b <- c(3, 7, -2.5, 11, 3.8, 9)
@
\onslide<+->
<<vectors2a, eval=TRUE, echo=TRUE>>=
print(b) # or just write   b
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Vectors II: Other ways to generate vectors}
\pause
<<vectors3a, eval=TRUE, echo=TRUE>>=
1:5  # integer numbers  from : to
@
\onslide<3->
<<vectors3b, eval=TRUE, echo=TRUE>>=
rep(1:4, times=3) # repeat entries several times
@
\onslide<4->
<<vectors4, eval=TRUE, echo=TRUE>>=
v <- rep(1:3, each=3, times=2)
v
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Vectors III: Yet other ways to generate vectors}
\pause
<<vectors4b, results="hold">>=
seq(from=5, to=-1, by=-0.5) # Sequence
# by must be negative for descending sequences
@
\onslide<3->
<<vectors4c>>=
seq(1.32, 6.1, length.out=15) # 15 elements
@
\onslide<4->
<<vectors4d, eval=FALSE>>=
seq(1.32, 6.1, len=15) # abbreviate argument names
?seq # read more about it...
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
% \subsection{Indexing}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Indexing on vectors (subsets) I: square brackets}
<<vectors5, eval=TRUE, echo=TRUE, highlight=T>>=    % highlight=F (off) to remove space
b # remember b?
b[1] # first element
@
\onslide<2->
<<vectors5b, eval=TRUE, echo=TRUE>>=
b[2:4] # several elements

b[ c(2,5,1,6,1) ] # flexible
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Indexing on vectors (subsets) II}
<<vectors6, eval=TRUE, echo=TRUE, highlight=T>>=    % highlight=F (off) to remove space
b

b[-2] # all but the second element
@
\onslide<2->
<<vectors6b, eval=TRUE, echo=TRUE>>=
a <- seq(from=1, to=100, by=0.1)

head(a) # only first 6 elements (or rows)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Indexing on vectors (subsets) III}
<<vectors7, eval=TRUE, echo=TRUE>>=
head(a)
a[2] <- 87 # manipulate single elements of object
head(a)
@
\onslide<+->
<<vectors2b>>=
ls() # list objects in workspace
rm(b) # remove an object
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Data types}
R can handle data of a variety of types: Numbers like \rcode{42.6}, characters like \rcode{"R rocks"}, complex numbers like \rcode{8+4i}, categories with \rcode{as.factor(c("blue", "green"))}, logical or boolean values \rcode{c(TRUE, FALSE)} and a few others. They should usually not be mixed. For example, you can't perform algebraic computation on characters:
\onslide<2->
<<datatypes, eval=FALSE>>=
p9 <- "1.3"  ; p9 # show assignment result
2*p9              # error, as p9 is a character
2*as.numeric(p9)  # make it a number first
p9                # p9 itself has not changed
is.numeric(p9)    # FALSE
mode(p9)          # character
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Integer vs decimal numbers: arithmetic precision}
\label{intnum}
\vspace{-1em}
<<intnum0, eval=FALSE>>=
6  ==  3 + 3          # TRUE
@
\pause
\vspace{-1em}
<<intnum1, eval=FALSE>>=
0.5 - 0.2  ==  0.3    # TRUE
@
\vspace{-1em}
\pause
<<intnum2, eval=FALSE>>=
0.4 - 0.1  ==  0.3    # FALSE
@
\vspace{-1em}
\pause
<<intnum3>>=
print(0.4-0.1 , digits=22)
@
\vspace{-1em}
\pause
<<intnum4>>=
round(0.4-0.1, digits=6)  ==  round(0.3, 6)
@
\pause
Test for equality only with integers / with rounding (see also \rcode{signif}), or use \rcode{all.equal}.
\pause
More pitfalls like this in the \href{http://www.burns-stat.com/pages/Tutor/R_inferno.pdf}{R inferno}.
\end{frame}

%------------------------------------------------------------%

\begin{frame}%{Vector and statistics - exercises}
\begin{exercise}{Vectors and statistics} %ex2
\begin{enumerate}
  \item Repeat your favorite number 6 times using \rcode{rep}.
  \item With \rcode{seq}uence, generate one vector from -1 to 4 in steps of 0.5 and one with a length of 21 elements. Then add a number to the vector.
  \item Assign a vector with the body heights of a few people around you to an object with a useful name.
  \item Print only the 4th and 2nd element (one single vector). BONUS: All but the 2nd to 4th elements.
  \item \rcode{sort} the numbers decreasingly.
\item Calculate the average size (\rcode{mean}), the variance (\rcode{var}) and the standard deviation (\rcode{sd}) of this dataset, as well as the \rcode{min}, \rcode{max}, \rcode{median} and 80\% \rcode{quantile} (20\% of the entries are larger than this value).
  \item BONUS 1: Explain what \rcode{length} does.
  \item BONUS 2: Generate the numbers from 1 to 10 in three different ways.
  \item BONUS 3: Explain and relate to each other: mean, var, sd, median, quantile.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1-2: Vectors}
\vspace{-0.5em}
<<ex2sola, size="small", eval=FALSE>>=
# repeat and sequence:
rep(5, times=6)
seq(from=-1, to=4, by=0.5)
vec2 <- seq(-1, 4, length.out=21)
seq(-1, 4, len=21)
@
\vspace{-0.5em}
\small You can leave argument names away, if you specify their content in the right order.
If it is unambiguous, you can use partial argument names.
\normalsize
\vspace{-0.5em}
\onslide<+->
<<ex2solc, size="small", eval=FALSE>>=
# add a number to a vector:
c(vec2, 8) # does not change vec2
vec3 <- c(vec2, 8) # creates a new object
vec2 <- c(vec2, 8) # changes the object vec2
# Another way:
vec2 <- seq(-1, 4, length.out=21)
vec2[21] <- 5 # changing one element
vec2
vec2[22] # returns NA - there is no value here
vec2[26] <- 8
vec2 # is now changed
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3-6: Vectors}
<<ex2sole, eval=FALSE>>=
# vector with body heights:
heights <- c(192, 171, 178, 175, 185, 145, 164) # cm
# print selected elements:
heights[ c(4,2) ]
# sort:
sort(heights, decreasing=T)
# statistics:
mean(heights)
var(heights) # cm^2
sd(heights) # cm
min(heights)
max(heights)
median(heights)
quantile(heights, probs=0.80)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.BONUS: Vectors}
<<ex2solg, eval=FALSE>>=
length(heights) # number of elements in vector
# Numbers from 1 to 10:
1:10  ;  seq(1,10)  ;  c(1,2,3,4,5,6,7,8,9,10)
# mean vs median:
mean(   replace(heights, 1, 292) ) # subject to outliers
median( replace(heights, 1, 292) ) # indifferent to extrema
@
\onslide<+->
70\% of values in a normal distribution lie between mean-sd and mean+sd:
<<ex2solh, echo=FALSE, fig.height=2, fig.width=5, out.width='.77\\textwidth'>>=
library(berryFunctions)
# par(mar=c(3,6,1.8,1))
normPlot(172.9, 15.3, xlab="Height  [cm]")
abline(v=c(172.9-15.3, 172.9+15.3), lwd=3)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Data.frames}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{data.frames}
\rcode{data.frame}s are the most common form of tables in R. \onslide<2-> Each column can have a different data type (numeric, character, factor, etc), but within a column, it stays the same.\\
\onslide<3->
Columns as well as rows can have names (\rcode{colnames, rownames}). If these start with a number, an "X" will be prefixed. \onslide<4-> This may happen when reading data, which is usually stored as a \rcode{data.frame} in R.\\
\onslide<5->
<<df0, eval=FALSE>>=
?data.frame
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Creating data.frames}
<<df1, size="small">>=
df <- data.frame(col_a=11:14, ColName2=letters[1:4],
                 LogicalCol=(1:4)>2)
df
str(df)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Subsetting data.frames by index numbers}
<<df2, size="small" >>=
nrow(df)
ncol(df) # see also dim(df)
@
\onslide<2>
<<df2b, size="small", eval=TRUE, echo=TRUE>>=
df[ 3 , 1] # 3rd row, 1st column
df[   , 2] # all rows, 2nd column (as vector)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Subsetting data.frames by names}
\vspace{-0.5em}
<<df3, size="small" >>=
df[ "LogicalCol" ] # no comma -> data.frame
@
\onslide<+-> \vspace{-0.5em} Bad practice, unclear to user whether rows or columns are indexed!\vspace{-0.5em}
<<df3a, eval=FALSE>>=
df[ , "LogicalCol", drop=FALSE ]  # better
@
\onslide<+->
<<df3b, size="small", eval=TRUE, echo=TRUE>>=
df$col_a
@
\onslide<+-> \vspace{-0.5em}
<<df3c, size="small", eval=TRUE, echo=TRUE>>=
df[2, ] # full row
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Some hints about data.frames}
\begin{itemize}[<+->]
\item If \rcode{nrow(df)} returns \rcode{NULL}, \texttt{df} might in fact be a vector.
\item \rcode{NROW(df)} will show \rcode{length(df)} if \texttt{df} is a vector.
\item Also, remember you can check the object with \rcode{class} and \rcode{mode}, as well as \rcode{is.vector}.
\item Objects like matrices can be converted with \rcode{as.data.frame(theMatrix)}
\item \rcode{colnames(df)} will show the column names. (see also \rcode{rownames})
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]
\begin{exercise}{data.frames}
Working with the dataset \rcode{state.x77} (comes built-in with R)
\begin{enumerate}
\item Change the object type to a data.frame.
\item What are the 3 ways to select the population column? Which one doesn't work for Life expectancy? Why not? (This only applies if you used \rcode{as.data.frame}, not \rcode{data.frame})
\item How can you subset a single column, without the result being simplified to a vector? (you want to keep it as a data.frame, but with one single column only. Hint: \rcode{?"["})
\item How could the \rcode{\$} subsetting method be dangerous when misspelling columns?
\item By which two ways can you select the Income and Illiteracy columns?
\item How can you select all the states (=rows) with an income above 5000?
\item BONUS: Why does \rcode{state.x77\$Income} not work on the original dataset? (use \rcode{rm(state.x77)} to remove your changed object from the workspace, if you didn't assign it to a different name.)
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: subsetting data.frames}
<<sol_dfs, eval=F>>=
state <- as.data.frame(state.x77)
state[,1] # not safe, columns could be in different position
state[ , "Population"] # safe and readable
state$Population # quicker to type, has autocomplete
# $  doesn't work (at least not without quotation marks)
   # with a space, it's an invalid column name
state[ , "Population", drop=FALSE]
state$Iilleeteeraacyy # does not give an error!!!
state[ , c("Income","Illiteracy")]
state[ , 2:3]
state[state$Income>=5000, ]
# Because it is a matrix, not a data.frame
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Matrices, apply function}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Creating matrices}
<<mat1, tidy=F, results='markup'>>=  %BB: tidy=F stops line breaks
matrix(data=1:6 , nrow=2, ncol=3)
@
\onslide<2>
<<mat1b, eval=TRUE, tidy=F, echo=TRUE>>=
m <- matrix(1:6 , nrow=2, ncol=3, byrow=T)
print(m)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Manipulating matrices, row and column names}
<<mat2, tidy=F>>=
colnames(m) <- c("A", "B", "C")
m[1,1] <- c(989)
print(m)
@
\onslide<2>
<<mat2b, eval=TRUE, tidy=F, echo=TRUE>>=
rownames(m) <- c("row1", "row2")
m
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Matrices only have one single data type}
<<mat3>>=
m[1,1] <- "a"
m
@
All are converted to character (see \hyperlink{datatypes}{order of coercion})
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Apply function to matrix rows / columns}
<<mat_apply1>>=
m <- matrix(1:12, ncol=4)
rowMeans(m)
apply(m, MARGIN=1, FUN=median) # MARGIN=1: Keep x dimension
apply(m, MARGIN=2, median, na.rm=TRUE) # apply to columns
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{combining matrices}
\footnotesize
<<mat_combine_objects>>=
m <- matrix(11:16, ncol=3) ; m # 2 x 3
p <- matrix(21:32, ncol=4) ; p # 3 x 4
r <- matrix(31:39, ncol=3) ; r # 3 x 3
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{combining matrices ~ ~ m: 2 x 3 ~ ~ p: 3 x 4 ~ ~ r: 3 x 3}
\footnotesize
\vspace{-1.5em}
<<mat_combine_bind1>>=
rbind(m,r) # row-bind: number of columns must match
# rbind(m,p) # Error: 3 and 4 columns
@
\pause
\vspace{-1.5em}
<<mat_combine_bind2>>=
cbind(p,r) # column-bind: nrows must match
# cbind(m,r) # Error: 2 and 3 rows3
@
\end{frame}


%------------------------------------------------------------%

\begin{frame}[fragile]{combining matrices}
\footnotesize
<<mat_combine_t>>=
m
t(m) # transpose
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Write a function and apply it to a matrix}
\vspace{-1.5em}
\begin{exercise}{functions + matrices} %ex3
\begin{enumerate}
\footnotesize
\item What do you get with   \rcode{vect <- c(5, 3, 9, 1, 7, 4, 8, 6)     ;   which.min(vect)}?
\item How do you exclude the sixt element of \rcode{vect} (return all of \rcode{vect} except the value at position 6)?
\item Write a function to get the second-largest value of a vector and test it on \rcode{vect}.
\item Create a matrix with the integers from 1 to 12 organized in three columns (filled column-wise).
\item Apply the function row-wise and column-wise.
\item What type of object does that return? (Hint: it's not a matrix as you might have expected.)
\item BONUS: Write a function that can optionally return the third/fourth/etc-largest value of a vector. 
 Remember to use curly braces (\rcode{\{...\}}) around the body of the function if several statements are involved.
 You can create and access objects within a function in the same way you would in the global workspace.
\item tough BONUS: Have the function \rcode{stop} with an informative error if the number to exclude is larger than the length of the vector. Handle the input 0.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1-3: functions + matrices}
\rcode{which.min} returns the position (index) of smallest value.\\
<<ex_fm_sol1>>=
vect <- c(5, 3, 9, 1, 7, 4, 8, 6)
secondMax <- function(x) max(x[-which.max(x)])
secondMax(vect)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.4-6: functions + matrices}
\vspace{-2em}
\small
<<ex_fm_sol2>>=
z <- matrix(1:12, ncol=3)   ;   z
apply(z, MARGIN=1, secondMax)
apply(z, MARGIN=2, secondMax)
@
\vspace{-0.7em}
MARGIN: dimension to keep when function reduces vectors to a single number.\\
\rcode{apply} then takes these single numbers (one per row/column) and combines them into a vector.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.7-8: functions + matrices}
<<ex_fm_sol3, eval=FALSE>>=
nthMax <- function(x, n_exclude=0)
  {
  x <- sort(x, decreasing=TRUE)
  if(n_exclude >= length(x)) 
     stop("Can't exclude ", n_exclude,
          " elements from a vector with length ", length(x))
  if(n_exclude > 0) x <- x[-(1:n_exclude)]
  max(x)
}
nthMax(vect) ; max(vect)            # 9
nthMax(vect, 1) ; secondMax(vect)   # 8
nthMax(vect, 2)                     # 7
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Lists, lapply/sapply functions}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Lists}
Lists store any R object type (vectors, data.frames, \ldots) in one object.
<<list1, size="small", tidy=F>>=
list("df"=df[1:2, ], matrix=m, character="TEXT")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List basics I}
<<listbasics1>>=
# create a list: an object with several 'objects' inside it
L1 <- list(first="result of function 'list'",
           second=345:287, third=rnorm(10),
           fourth=data.frame(a=6:3, b=rexp(4)),
           fifth=LETTERS, sixth=letters,
           seventh=sample(300), eigth="goodbye")
@
\pause
<<listbasics1b, eval=F>>=
# print the whole thing:
L1
@
\pause
<<listbasics1c, eval=F>>=
# print only the first 4 elements of the list
head(L1,4)
tail(L1) # or the last n elements (by default 6)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List basics II}
<<listbasics1d, size="small">>=
# Structure of the list
str(L1, max.level=1, vec.len=3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List basics II}
\vspace{1.45em}
<<listbasics1e, size="small">>=
# str down to each level of the list
str(L1, vec.len=3) # see the df for the difference
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List indexing I}
<<listindex1, size="small">>=
# Assessing list elements (indexing) with double square brackets:
L1[[3]]
@
\pause
<<listindex2, size="small">>=
# What's different if you use only single brackets?
L1[3]
# HINT: look at the class of the results
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List indexing II}
\vspace{-1.5em}
<<listindex_list, eval=FALSE>>=
class(L1[3]) # list
class(L1[[3]]) # numeric
@
\vspace{-1em}
\rcode{L1[3]} returns a list (with a single element).\\
\rcode{L1[[3]]} returns that single element as is (in this case: a vector with 10 numbers). 
\footnotesize
\pause
<<listindex5>>=
# Several elements of the list (the result is still a list):
L1[4:5]
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List indexing III}
<<listindex3>>=
# Assesing elements by name
L1$eight # NULL if not existent, so watch out with spelling!
L1$eigth
@
\pause
<<listindex4>>=
names(L1) # as with names(VECTOR) or rownames(DATAFRAME)
names(L1)[2] <- "second elem."
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{List indexing IV}
<<listindex6, eval=F>>=
# changing elements:
L1[c(3,6)]  <- c(77777777, 3333333)
head(L1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{L-apply}
\vspace{-1.5em}
<<lapply1>>=
typeof(L1[[1]])
@
\vspace{-1.5em}
\pause
<<lapply1b, eval=F>>=
# Apply a function to each element of the list:
lapply(X=L1, FUN=typeof)
@
\pause
\vspace{-2em}
\begin{columns}
\hspace{-5em}
\begin{column}{.4\textwidth}
<<lapply1b1, echo=F>>=
# Apply a function to each element of the list:
lapply(X=L1[1:4], FUN=typeof)
@
\end{column}
%\hfill
\hspace{-7em}
\begin{column}{.4\textwidth}
<<lapply1b2, echo=F>>=
# Apply a function to each element of the list:
lapply(X=L1[5:8], FUN=typeof)
@
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{S-apply I}
<<sapply, echo=-1>>=
options(width=60)
# simplify that output (if possible):
    sapply(X=L1, FUN=typeof)
@
\pause
<<sapply2, eval=F>>=
# simplifying not possible if FUN(L1[[1]]) and FUN(L1[[2]])
# return different results:
sapply(X=L1, FUN=head)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{S-apply II}
\begin{columns}
%\hspace{-5em}
\begin{column}{.45\textwidth}
<<sapply3a>>=
# List with vectors:
L2 <- list(3:7, 8:4, 5:9)
L2
@
\end{column}
%\hfill
\pause
%\hspace{-7em}
\begin{column}{.45\textwidth}
<<sapply3b>>=
sapply(L2, I)
@
\rcode{I} basically returns the input as is.\\
This is useful for \rcode{tapply} results!
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{S-apply III}
<<sapply4>>=
# That doesn't work for vectors of different lengths:
L3 <- list(AB=c(6,9,2,6), BC=1:8, CD=c(-3,2) )
sapply(L3, I)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{S-apply IV}
<<sapply5, size="small", echo=-1>>=
options(width=60)
# the solution: berryFunctions::l2df
# list to data.frame conversion
if(!require(berryFunctions)) install.packages("berryFunctions")
library(berryFunctions)

l2df(L3)
# vectors are padded with NAs, names are kept
@
<<resetopts, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{S-apply V}
<<sapply6>>=
L3
# nested subsetting: get the third element of each vector:
sapply(L3, "[", 3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{apply functions to vectors \& further arguments}
<<lapply_vector1>>=
sample(x=1:100, size=5)
@
\pause
<<lapply_vector2>>=
lapply(c(6,2,13), sample, x=1:100)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Practice lists}
\footnotesize
\vspace{-1em}
\begin{exercise}{lists} %ex
\begin{enumerate}
  \item Create a matrix with some numbers you like, with >= 2 rows and columns.
  \item Create a list (with meaningful element names!) that contains the previous matrix, your name, the current \rcode{Sys.time()}, the number of this exercise, and the haircolors of at least two of your neighbours.
  \item What do you get with \rcode{mean(mylist[1])}? Why?
  \item Using the appropriate function from the apply family, get the \rcode{length} for each element. What is surprising about he result?
  \item BONUS 1: Can a list containing another list be created?
  \item BONUS 2: Change the \texttt{haircolors} element class into a category with \rcode{as.factor}. Inspect the new list with \rcode{str}.
  \item tough BONUS 3: instead of using \rcode{DF[3,4]}, you can also explicitely call the subset function with \rcode{"["(DF, i=3, j=4)}. Create \rcode{datalist <- list(iris=head(iris), indo=head(Indometh), beaver=head(beaver1))}.\\
  How can you get the second column of each \texttt{datalist} element? \\
  How the third row? (Reminder: for a single DF, you need \rcode{DF[3, ]} with an empty entry for j.)
\end{enumerate}
\end{exercise}
\end{frame}
%------------------------------------------------------------%

\begin{frame}[fragile]{list exercise solutions}
\small
<<matlistsol, eval=FALSE>>=
mat <- matrix(c(42,007,123,7777,-17,88), ncol=2)
mylist <- list(matrix=mat, creator="Berry",
     created=Sys.time(), exerciseNumber=11,
     haircolor=c("brunette", "red", "blonde", "blonde")  )
# 3 see below
sapply(mylist, length) # matrix length is 6 (=ncol*nrow)
# B1: Yes, you'll create a so-called recursive list.
mylist$haircolor <- as.factor(mylist$haircolor)
str(mylist)
sapply(datalist, "[", , 2) # or sapply(datalist, "[", 2)
sapply(datalist, "[", 3, )

@
3: \rcode{mean(mylist[1])} returns NA (along with a warning) because \rcode{mean} needs a numerical input.
\rcode{mylist[1]} returns a list with a single element. \rcode{mean(mylist[[1]])} is needed instead.\\
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{apply custom functions to lists}
Function to get the sum of elements 3,4,5 in a vector:
\vspace{-0.8em}
<<listsum35a>>=
sum35 <- function(x) sum(x[3:5])
sum35(1:9)
@
\pause \vspace{-0.8em}
<<listsum35b>>=
L <- list(1:7, c(42,007,pi,2,4), rnorm(15), 99:96)
sapply(L, sum35)
@
\pause \vspace{-0.8em}
<<listsum35c, eval=FALSE>>=
sapply(L, function(x) sum(x[3:5])  )
@
\vspace{-0.8em}
called "anonymous" function (not defined with a name)
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{list and df exercise}
\small
\vspace{-0.8em}
\begin{exercise}{lists and dataframes}
\begin{enumerate}
\item Create a list with the following built-in datasets (i.e. available directly in R):
\rcode{infert, Indometh, euro, esoph, VADeaths, sleep}. 
Use custom element names and a useful object name. Check it with \rcode{str}.
\item Now change the esoph element to keep only the numerical columns.
\item For each of the following tasks, compare \rcode{lapply} and \rcode{sapply}.
If simplification doesn't work, analyze why and see if you can exclude elements of the list to make it work.
For each element, get the \rcode{class, dim, ncol, NCOL, median, range, summary}.
\item Instead of using \rcode{ToothGrowth[5,2]}, you can also explicitely call the subset function with \rcode{"["(ToothGrowth, 5, 2)}.\\
Reminder: for a row, you need \rcode{ToothGrowth[5, ]} with an empty entry for j.
Get the third column of \rcode{ToothGrowth} in this explicit way.
\item Get the second column of each data.frame element of the previous list, again comparing \rcode{lapply} and \rcode{sapply}. Then get the third row of each element.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{list and df exercise solution}
\footnotesize
<<ldfex, eval=FALSE>>=
manyDatasets <- list(infertility=infert, indo=Indometh,
    euro=euro, cancer=esoph, deathrates=VADeaths, sleep=sleep)
manyDatasets$cancer <- manyDatasets$cancer[,4:5]
str(manyDatasets)
lapply(manyDatasets, class)
sapply(manyDatasets, class)
sapply(manyDatasets[-2], class)
sapply(manyDatasets[-3], dim)
sapply(manyDatasets, ncol) # NULL for vector, cannot be simplified
sapply(manyDatasets, NCOL)
sapply(manyDatasets[c(3,5)], median) # other are DFs = non-numerics
sapply(manyDatasets[3:5], range) # range can handle all-numeric DFs

"["(ToothGrowth,,3)

lapply(manyDatasets[-3], "[", , j=2)
lapply(manyDatasets[-3], "[", 3, )
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Classes and methods, data types and object types}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Determine the class of an object}
	Everything is an object that belongs to an existing class!!
<<class1, eval=TRUE, echo=T>>=
class(v)
class(df)
class(m)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Usage of class in functions}
<<advanced_class>>=
x <- 10
class(x) <- c("a", "b")
# error:
if( class(x) == "b"   ) message("class of x contains b")
# use this instead
if( inherits(x, "b")  ) message("good coding!")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Examining objects}
Every object class has attributes and methods:
<<class2, size="footnotesize", eval=TRUE, echo=T>>=
str(v)
str(df)
str(m)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Overview of some useful functions}
<<cfunc1, eval=TRUE, echo=T>>=
length(v)
names(df)
dim(m)
which(v > 4)
@
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{Please note ...}
% \begin{block}{Parentheses and square brackets of functions and objects}
% \pause
% \begin{description}[<+->]
% \item[objects] are variables and contain your data. The indexing (accessing of items) is done by brackets \texttt{[ ]}
% \item[functions] are methods (built-in or self-made) and they perform an analysis or start a process. When functions are called, you have to use parentheses \texttt{( )}, in which the arguments are put.
% \end{description}
% \end{block}
% \onslide<4-> With \rcode{newtable <- edit(oldtable)}, you can change cells in a table by hand. \alert{As this is not reproducible, this is bad practice!}. \rcode{fix} is even worse, as it changes the object itself.\\
% With \rcode{View}, you can look at a table in an external viewer. This is useful for large tables, as the console is not cluttered with data.
% \end{frame}

%------------------------------------------------------------%

\begin{frame}{Overview: data types}
\scriptsize In order of coercion (if mixed, TRUE is converted to 1,~  3.14 to "3.14" etc)
\vspace{-0.7em}
\small
<<coercion, eval=FALSE, echo=FALSE>>=
l <- list(null=NULL, na=NA, logi=TRUE, factor=as.factor("hi"), int=7L, double=3.14,
          complex=5+3i, char="hello", time=Sys.time(), date=as.Date("2017-05-02"), func=ncol)
sapply(l, function(x) c(mode=mode(x), typeof=typeof(x), class=class(x)[1]))
sapply(l, function(x) sapply(l, function(y)  class(c(x,y))[1] ))
sapply(l, function(x) sapply(l, function(y) typeof(c(x,y)) ))
@
\begin{center}
\begin{tabu}{| l | l | l | l |}   \hline
Description      & example         & \rcode{typeof} & \rcode{class}      \\ \hline  \hline
empty set        & NULL                 & NULL      & NULL               \\ \hline
not available    & NA                   & logical   & logical            \\ \hline
logical          & c(T, F, FALSE, TRUE) & logical   & logical            \\ \hline
category         & factor("left")       & integer   & \textbf{factor}    \\ \hline
integer number   & 4:6  ; 7L            & integer   & integer            \\ \hline
decimal          & 8.7                  & double    & \textbf{numeric}   \\ \hline
complex          & 5+3i                 & complex   & complex            \\ \hline
character string & "homer rocks"        & character & character          \\ \hline
time             & Sys.time()           & double    & \textbf{POSIXct}   \\ \hline
date             & as.Date("2017-05-02")& double    & \textbf{Date}      \\ \hline
function         & ncol                 & closure   & \textbf{function}  \\ \hline
\end{tabu}
\end{center}
\vspace{-0.7em}
\scriptsize
\pause
\href{http://adv-r.had.co.nz/Data-structures.html}{adv-r.had.co.nz/Data-structures}.
\pause
%See also e.g. Uwe Ligges (2006) - Programmieren mit R\\
\rcode{as.character}\texttt{(3.14)} converts a data type;  \pause \rcode{is.integer}\texttt{(4:6)} checks. \pause
\rcode{str} shows an abbreviation of \rcode{class}. \pause
\rcode{mode} (for users) is like \rcode{typeof} (R internal), but combines
integer and double to numeric (\& closure, special and builtin to function). \pause
Other rare typeofs: raw, environment, promise, ... \pause
When mixing date/time with others, the order of appearance determines the output class.
\label{datatypes}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Overview: Object types}
\vspace{-2em}
\begin{center}
%\begin{tabu}{| l | m{4cm} | m{3cm} | l |}  \hline
\begin{tabu}{| l | l | l | l |}  \hline
Object     & example                                   & \rcode{typeof}      & \rcode{class}\\ \hline   \hline
vector     & \textit{see data types}                   & ...                 & ...          \\ \hline
matrix     & matrix(9:15, ncol=2)                      & ...                 & matrix       \\ \hline
array      & array(letters[1:24], dim=c(2,6,4))        & ...                 & array        \\ \hline
data.frame & \small data.frame(C1=4:5, C2=c("a","b"))  & list                & data.frame   \\ \hline
list       & list(el1=7:15, el2="big")                 & list                & list         \\ \hline
function   & function(x) 12+0.5*x                      & closure             & function     \\ \hline
...        & lm(b $\sim$ a)                            & list                & lm           \\ \hline
\end{tabu}
\end{center}
\vspace{-0.5em}
\pause A \rcode{matrix} consists of only one data type.
If you accidentally change one element to a character, all are converted and calculations are not possible any more
(See coercion order in previous slide).\\
\pause \rcode{data.frame}s can have multiple data types, but a column in itself also has only one type.\\
\pause \rcode{list}s can combine anything, even other lists.\\
\pause \rcode{is.atomic}\texttt{(Object)} returns TRUE (vector, matrix, array) or FALSE\\
\pause \rcode{as.matrix}\texttt{(Object)} converts the class of an object by force.
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{4. "Real" data}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Reading and writing data}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Data I/O functions (Input / Output)}
R \textbf{reads and writes} data formats like ASCII files, GEOTIFF, GRIB, NETCDF, HDF \ldots
\pause
<<data1, eval=FALSE, echo=T, tidy=FALSE>>=
read.csv("relative/path/to/input/file.csv")
# Combined with a variable assignment:
mydata <- read.table("C:/path/to/input/file.txt")
write.table(x=mynewdata, file="output.txt")
@
Windows users: change all \ \textbackslash \ to \ \textbackslash\textbackslash \ \ or \ / \\[\baselineskip]
\pause
Relative file names (minimal changing of working directory):
<<data2, eval=FALSE, echo=TRUE>>=
setwd("C:/Users/berry/Desktop") # set working directory
dir() # show files in current folder
mydata <- read.table("filename.txt", header=TRUE, sep="\t")
# use a better object name!
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Folder management}
<<folders, eval=FALSE>>=
setwd("..") # sets working directory path up one level
getwd() # shows the current wd path
dir(recursive=TRUE) # also list items in subfolders
dir("../other_subfolder") # list files in different folder
file.create() # some file operations
file.rename()
file.remove() # see also unlink()
file.copy()
dir.create() # some folder (directory) operations
file.exists()
dir.exists()
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Some of the arguments for read.table}
\footnotesize
\begin{tabu}{l l}
  \onslide<+->{ header = TRUE      & read first line as column names}\\
  \onslide<+->{ dec = ","          & comma as decimal mark}\\
  \onslide<+->{ sep = "\_"         & underscore as column separator ("\textbackslash t" for tabstop)}\\
  \onslide<+->{ fill = T           & fill incomplete rows with NAs at the end}\\
  \onslide<+->{ skip = 12          & ignore the first 12 lines (eg with meta data)}\\
  \onslide<+->{ comment.char = "\%"        & omit (rest of) lines that start with \% (like R's \#)}\\
  \onslide<+->{ na.strings = c(-999, "NN") & identify NA entries (missing values)}\\
  \onslide<+->{ stringsAsFactors=FALSE     & do not convert characters to factors}\\
  \onslide<+->{ as.is=TRUE                 & the same, but less typing, and potentially columnwise}\\
\end{tabu}~\\[1em]
\normalsize
\onslide<+->
Alternatives to read.table:
\begin{description}[<+->]
  \item[scan]     At the core of read.table - for complicated things
  \item[read.csv] comma separated values (different defaults than read.table)
  \item[read.fwf] fixed width formatted data
  \item[read\_excel] Excel files (install package, see \href{https://github.com/hadley/readxl#overview}{github.com/hadley/readxl})
\end{description}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Practice reading tables and subsetting data.frames}
\begin{exercise}{data.frames - working with tables} %ex3
\begin{enumerate}
  \item Read the file \datalinkText{animals.txt} with the correct settings for each needed argument and assign it to an object.
  \item Check whether everything is read correctly with \rcode{str}.
  \item Print only the first column (BONUS: in 3 different ways of subsetting).
  \item \rcode{which} element of this vector is equal to (\rcode{==}) "Sparrow"?
  \item Can the elephant fly? Find out with a logical query.
  \item Find out how many legs the mammals have on average. Interpret the result.
  \item BONUS 1: Use \rcode{tapply} to find the average cuteness score for each animal class.
  \item BONUS 2: Read the file "\datalinkBlob{days.txt}" in a way that days, months, and years each have their own column. What other function besides \rcode{read.table} might be useful for that?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1-2: data.frames}
<<ex3sola, eval=FALSE>>=
# set working directory to path with files:
setwd("C:/Dokumente und Einstellungen/hydro/Desktop")
# which files are there:
dir()
# step by step, specify the arguments of read.table...
animals <- read.table("data/animals.txt", sep="\t",
                      header=TRUE, dec=",")
animals
str(animals) # ... until all numbers are num.
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3-5: data.frames}
<<ex3solb, eval=FALSE>>=
# first column, and which is Sparrow:
animals$Name
animals[ ,"Name"] # more typing
animals[ ,1] # hard to interpret later on
animals$Name == "Sparrow"
which( animals$Name == "Sparrow" )

# Can the elephant fly? Automatic query:
animals[4,3]
animals[ animals$Name == "Elephant" , 3 ]
animals[ animals$Name == "Elephant" , "can.fly" ]
animals[ animals$Name == "Sparrow"  , "can.fly" ]
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.6-7: data.frames}
<<ex3solc, eval=FALSE>>=
# How many legs do the mammals have on average?
animals[ animals$Class == "Mammal" , "n.legs" ]
mean( animals[ animals$Class == "Mammal" , "n.legs" ] )
# How cute are they, on average?
mean( animals[ animals$Class == "Mammal" , "cuteness" ] )

# How cute is each category of animals?
tapply(X=animals$cuteness, INDEX=animals$Class, FUN=mean)
# separates cuteness into groups, categorized by Class,
# then calculates mean for each group
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.8: data.frames}
<<ex3sold, eval=FALSE>>=
# Read "days.txt" with columns for days, months and years
dir()
days <- read.table("days.txt", sep=".")
head(days)
str(days)

# custom names of columns
colnames(days) <- c("day", "month", "year")
head(days)

# other way:
read.fwf("data/days.txt", widths=c(2,1,2,1,4))

# usage example: return months for e.g. vegetation index:
days$month
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Frequent mistakes with \rcode{read.table}}
\small
\begin{tabular}{|m{0.45\textwidth}|m{0.45\textwidth}|}\hline
\alert{Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : line \_ did not have \_ elements} & usually \rcode{header}, \rcode{sep} or \rcode{fill} is given incorrectly.\\
\hline
\pause
\alert{Warning message: \newline In read.table("\_.txt", \_) : \newline incomplete final line found by \newline readTableHeader on 'C:\textbackslash\_.txt'}& Open the file and at the end, add a line break (with ENTER) = line feed = newline = carriage return.\\
\hline
\pause
\rcode{str(DataframeIreadIn)}  yields \newline "factor" in some numeric columns & Check data file! \newline \rcode{dec} may need to be corrected\\
\hline
\end{tabular}\\[\baselineskip]
\pause
<<commadec, eval=FALSE>>=
as.numeric( as.character(df$col) )
as.numeric( gsub(pattern=",", replacement=".", x=df$col) )
# If you try to read data in the format "3,590.18", run
df$col <- as.numeric(gsub(",", "", df$col))
@
\pause
Note: \alert{error}s stop function execution, \alert{warning}s can influence function performance and should only be ignored if you know what they really mean.
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Factors, tapply function}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Factors = categorical variables}
<<factors, size="footnotesize">>=
iris$Species[63] # how factors are printed
class(iris$Species)
levels(iris$Species)

# R saves factors as numbers internally
as.numeric(iris$Species)[c(1,63,105)]
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{factors, explained with \datalinkBlob{animals.txt}: the danger}
\vspace{-0.9em} \pause
<<factorissue1a, size="footnotesize">>=
ac <- read.table(file="data/animals.txt", sep="\t", header=T)$cuteness
ac # R calls  print.factor ,  see methods(print)
@
\vspace{-0.9em} \pause
<<factorissue1b, size="footnotesize">>=
class(ac); typeof(ac)
@
\vspace{-0.9em} \pause
<<factorissue1c, size="footnotesize">>=
as.numeric(ac) # don't ever do this!!
@
\vspace{-0.9em} \pause
<<factorissue1d, size="footnotesize">>=
char <- as.character(ac)
as.numeric(sub(",",".", char))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{factors, explained with \datalinkBlob{animals.txt}: the solution}
\vspace{-0.9em} \pause
<<factorissue2sol, size="footnotesize">>=
df <- read.table(file="data/animals.txt", sep="\t", header=T, as.is=TRUE)
str(df)
@
Now Name and cuteness are character strings instead of factors.\\
\texttt{as.is=TRUE}~ is a special case of ~\texttt{stringsAsFactors=FALSE}: with the first you can specify the latter per column (I use it because I can type it more quickly).
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{factors are very useful to apply a function per group}
\pause
<<factorissue2, size="scriptsize">>=
str(PlantGrowth)
@
\pause
<<factorissue2b, size="small">>=
tapply(X=PlantGrowth$weight, INDEX=PlantGrowth$group, FUN=mean)
@
\pause
\href{http://adv-r.had.co.nz/Data-structures.html#attributes}{This part of Hadley's book} is a good intro to factors.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{factors are also useful for plotting specifics}
col can be a factor vector, integers correspond to \rcode{palette()}
\pause
<<factorissue3, size="small", echo=-1>>=
par(mar=c(4,4,1,1), mgp=c(2.5, 0.8, 0))
plot(rate~conc, data=Puromycin, col=state, pch=16, las=1)
legend("bottomright", levels(Puromycin$state), col=1:2, pch=16)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{practice working with categories}
\begin{exercise}{Factors, tapply}
\begin{enumerate}
\item Plot the Puromycin dataset, but use the 3rd and 4th color of the default \rcode{palette()}
\item BONUS 1: Use custom colors. \\Hint: create a vector with the colors, then index from it.
\item BONUS 2: In the \rcode{iris} dataset, add a row for the \textit{Iris sintenisii}. \\Hint: add a level to the factor first.
\item Using \rcode{tapply}, find out what you should feed chickens according to the measurements in \rcode{chickwts}.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: factors, tapply}
<<factor_ex, eval=FALSE, size="small">>=
plot(rate~conc, data=Puromycin, col=as.integer(state)+2, pch=16)

mycol <- c("orange", "mediumpurple2")
plot(rate~conc, data=Puromycin, col=mycol[state], pch=16)

levels(iris$Species) <- c(levels(iris$Species), "sintensii" )
iris[151, ] <- c(6,3,5,2,"sintensii")
@
\pause
<<chickwts, echo=2:3, size="small">>=
options(width=60)
sort(tapply(chickwts$weight, chickwts$feed, median))
sort(tapply(chickwts$weight, chickwts$feed, min))
options(width=50)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Merging data.frames}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Merge (join) tables}
If you haven't already, now is a good time to download (and unzip!) \href{https://minhaskamal.github.io/DownGit/\#/home?url=https://github.com/brry/course/tree/master/data}{all datasets}.
\begin{exercise}{Merge} %ex4
\begin{enumerate}
  \item Read the files \datalinkText{mergeApples1.txt} and \datalinkBlob{mergeApples2.txt} into separate data.frames.
  \item Use \rcode{rbind} to combine both tables line-wise and assign the output to e.g. \rcode{apples}.
  \item Read \datalinkBlob{mergeAge.txt} into e.g. \rcode{age}.
  \item Describe what \rcode{merge(age, apples, by.x="Name", by.y="Person")} does.
  \item What happens if you set \texttt{all=TRUE} or \texttt{all.x=TRUE}?
  \item BONUS 1: What is the difference between \rcode{cbind} and \rcode{rbind}?
  \item BONUS 2: Why does \rcode{cbind} not work with age and apples?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Merge}
<<ex4sola, eval=FALSE>>=
ma1 <- read.table("data/mergeApples1.txt", header=T)
ma2 <- read.table("data/mergeApples2.txt", header=T)
apples <- rbind(ma1, ma2)
apples
age <- read.table("data/mergeAge.txt", header=T)

merge(age, apples, by.x="Name", by.y="Person")
# combine the information from both datasets
# for names that occur in both tables

merge(age, apples, by.x="Name", by.y="Person", all=T)
# Keep all entries, pad with NAs

# rbind: combine rows below each other
# cbind: bind columns beside each other
# dimensions and names must be correct
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Management of NAs, apply function}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{NA-values (NA=not available)}
Creating a table with \textbf{NA} values
<<na1, eval=TRUE, tidy=F, echo=T>>=
# create some test data. "c" around ":" is not necessary
df <- data.frame(x= c(1:10), y=11:20 )
df[3,2] <- NA
head(df)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{NA-values}
	Handling of \textbf{NA} values
<<na2, eval=TRUE, echo=T>>=
plot(df$x, df$y, pch=19, col="red")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{NA-values}
	Checking for \textbf{NA} values
	\begin{columns}
	\begin{column}{.48\textwidth}

<<na3, eval=TRUE, echo=T>>=
is.na(df)
@
	\end{column}
	\hfill
	\pause
	\begin{column}{.48\textwidth}
<<na4, eval=T, echo=T>>=
na.omit(df)
@
	\end{column}
	\end{columns}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{NA-values}
<<na5, echo=FALSE, size="scriptsize">>=
df
@
\vspace{-0.5em} \pause
<<na6, eval=T, echo=T>>=
mean(df$x) ; mean(df$y)
@
\vspace{-0.5em} \pause
<<na7, eval=T, echo=T>>=
mean(df$y, na.rm=TRUE) # dangerous with sums
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{apply: execute a function on each row (col) of a \rcode{matrix}}
\vspace{-1em}
\pause
<<apply1, size="small", echo=-(1:2), tidy=FALSE>>=
df <- data.frame(x= c(1:10), y=11:20 )
df[3,2] <- NA
# Compute the column- and row sums of a data.frame (df)
apply(X=df, MARGIN=2, FUN=sum) # column wise
@
\vspace{-1em}
\pause
<<apply2, size="small", tidy=FALSE>>=
apply(df, 1, sum) # line by line
@
\vspace{-1em}
\pause
<<apply3, size="small", tidy=FALSE>>=
apply(df, 2, sum, na.rm=TRUE) # with further arguments
@
\vspace{-1em}
\pause
\begin{exercise}{apply}
Compute the median of each column in the dataset \rcode{iris}.\\
Hint: leave out the non-numeric column.
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{apply practice solution}
<<iris_apply, echo=-1>>=
options(width=53)
apply(iris[ ,-5], MARGIN=2, median)
@
\pause
<<iris_apply2, echo=2>>=
options(width=53)
apply(iris[ ,-5], MARGIN=2, mean)
options(width=50)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Reproducible coding}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Working with Scripts}
For any real data analysis, you should work with scripts that save your code.\\
\pause
For that reason, you don't have to save your workspace when you close R.\\
\pause
If you save it, you don't know where it is stored by default. \\ In the next R session, all objects will be available again, which is convenient, but dangerous, as it reduces reproducibility.\\
\pause
Scripts can easily be exchanged with research partners, clients or employers. They may also develop into packages...\\
\pause
Before sending, close R, open a clean (!) session, and check whether everything is running.\\
\pause
Scripts should have lots of comments! \pause \texttt{\textcolor[rgb]{0,0.392,0}{ \# seriously.}}

\end{frame}

%------------------------------------------------------------%

\begin{frame}{Creating documents, Organizing your files}
\label{rnw}
Rstudio - file - new -\\
- R HTML (no \LaTeX required on system)\\
- R markdown (easy to learn, creates .pdf or .docx)\\
- R sweave (very powerful through \LaTeX. This is what I use for these slides.)\\[1em]
\pause
I use knitr, as it is more advanced than the default sweave. For that, set:\\
Rstudio - tools - global options - Sweave - weave using: knitr\\
Save as .Rnw file. See the knitr demo files: \href{http://yihui.name/knitr/demo/minimal/}{yihui.name/knitr/demo}\\[1em]
\pause
There are tips online on how to organize data, scripts, plots etc.
\href{http://stackoverflow.com/questions/1266279/how-to-organize-large-r-programs}{stackoverflow: How to organize large R programs}\\
\href{http://stats.stackexchange.com/questions/2910/how-to-efficiently-manage-a-statistical-analysis-project}
{stackexchange: How to efficiently manage a statistical analysis project?}\\
Here are some tips by Hadley:
\href{http://r-pkgs.had.co.nz/style.html}{http://r-pkgs.had.co.nz/style.html}
\end{frame}


%------------------------------------------------------------%

\begin{frame}[fragile]{Real Datasets online}
\begin{itemize}%[<+->]
\item \href{https://www.ncdc.noaa.gov/}{NOAA (USA)} weather data: \href{http://www1.ncdc.noaa.gov/pub/data/normals}{www1.ncdc.noaa.gov/pub/data/normals}
\item \href{http://www.dwd.de}{DWD} Climate Data Center: \href{ftp://ftp-cdc.dwd.de/pub/CDC/observations\_germany/climate/hourly/precipitation/recent/}{CDC/observations\_germany/climate}
<<klima_ftp, eval=FALSE, size="footnotesize">>=
library(rdwd) # github.com/brry/rdwd
clim <- dataDWD(selectDWD(id=02080, res="daily", var="kl",
                          per="hist"), dir="DWDdata")
@
\item \href{https://data.fivethirtyeight.com/}{data.fivethirtyeight.com} 
\item \href{https://data.unicef.org/}{data.unicef.org} (potentially add .xls etc as file extension)
\item \href{https://github.com/okulbilisim/awesome-datascience\#data-sets}{github.com/okulbilisim/awesome-datascience\#data-sets}
\item \href{https://github.com/caesar0301/awesome-public-datasets}{github.com/caesar0301/awesome-public-datasets}
\item \href{https://ropensci.org/packages/index.html}{ropensci.org/packages/index.html}
\item \href{https://dataviz.tools/category/data-sources/}{dataviz.tools/category/data-sources/}
\item \href{https://docs.google.com/document/d/1Ads4XsCjXmDrdGRgfmm_OgRdpFcl6Qhs6SOllNGyq7Y/edit}{StorytellingWithData dataviz challenge 2018}
\end{itemize}
\vspace{-0.5em}
%\pause
\begin{exercise}{Real Data}
Download, read and (visually) analyze a dataset that interests you.
\end{exercise}
\label{realdata}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{5. Plotting}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Syntax, adjustments, labeling}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Plot I: the dataset}
<<plot1, size="footnotesize">>=
head(beaver2, 4)
str(beaver2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot II}
% The basic syntax is \rcode{plot(x, y, adjustments)}
<<plot2, size="footnotesize", echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0))
# The basic syntax is plot(x, y, adjustments)
plot(beaver2$time, beaver2$temp)
#
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot III}
<<plot3, size="footnotesize", echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0))
plot(beaver2$time, beaver2$temp, ylab="Body temperature  [ \U00B0 C]",
     main="Beavers get warm late in the evening",
     xlab="Observation time [0330 for 3:30AM]", col="red")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot IV}
<<plot4, size="footnotesize", echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0))
plot(beaver2$time, beaver2$temp, pch=2, cex=2.8, las=1)
# pch: PointCHaracter, cex: CharacterEXpansion
# las: LabelAxisStyle (numbers upright)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Overview of Point CHaracters (more in \href{https://www.dropbox.com/s/ogonyju4fumrupa/Anhang.pdf?dl=0}{bF Anhang})}
<<pch, echo=F, eval=T, tidy=FALSE, fig.width=4, out.width='0.7\\textwidth'>>=
par(mar=c(0,0,2,0))
PCH <- 0:25
X <- c(1:7, 1:8, 1:6, 1:5)
Y <- rep(4:1,c(7,8,6,5))
plot(X,Y, pch=PCH, ylim=c(0.8,4.6), main="plot ( x, y,  pch =   _  )",
     xlim=c(0.6,8.4), bg="red", cex=1.6)
text(X,Y+.35, PCH, cex=1)
abline(h=c(1.7, 2.7, 3.7))
text(6.1, 1.15,"21:25\nfill color with bg", adj=0, cex=0.9, col="red")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Lines}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Plot with lines I}
<<lines1, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
k <- c(3,0,-10,8,6,3)   ; l <- c(-4,2,-6,-12,7,-3)
plot(k)  # standard (default) type: "p" for points
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot with lines II}
<<lines2, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(k, type="l")
# type="l" for lines
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot with lines III}
<<lines3, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(k, type="b", lwd=4)
# type="b" for both points and lines. # lwd: line width
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot with lines IV}
<<lines4, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(k, type="o", lty=2)
# type="o" for both overplotted. # lty: line type
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Overview of types (more in \href{https://www.dropbox.com/s/ogonyju4fumrupa/Anhang.pdf?dl=0}{bF Anhang})}
<<plot_types, echo=F>>=
par(mar=c(0,0,2,0), cex=1.5)
a=1:4; b=c(0.5,4,2,1)  ; tp=c("p","l","b","o","c","n","s","S","h")
plot(1:12, type="n", ylim=c(0,14), axes=FALSE)
title(main="plot ( x, y,  type =   _  )")
i <- 1
for(y in 3:1)
   for(x in 1:3) {
      points(a+4*x-4, b+5*y-5, type=tp[i])
      text(3.5+4*x-4, 3+5*y-5, paste0("\"",tp[i],"\"")) ; i <- i+1 }
abline(v=c(5,9)-.5, h=c(4,9)+.75, col="gray" )
box("plot")
@
\end{frame}


%------------------------------------------------------------%

\begin{frame}[fragile]{Overview of line types (more in \href{https://www.dropbox.com/s/ogonyju4fumrupa/Anhang.pdf?dl=0}{bF Anhang})}
<<plot_lty, echo=F>>=
x <- c(4, 8, 9)
y <- c(8, 8, 9)
par(mar=rep(1,4))
plot(x,y, type="n", ylim=c(1.5,8.5), xlim=c(0,9), axes=FALSE, main="plot ( x, y,  lty = _ )", asp=1)
for(n in 0:6) lines(x, y-n, lty=n)
for(n in 0:6) text(3.7, 8-n, n)
Names=c("dashed","dotted","dotdash","longdash","twodash")
text(3.2, 8, "\"blank\" (no line)", adj=1)
text(3.2, 7, "\"solid\" (default)", adj=1)
text(3.2, 7-(1:5), paste0("\"", Names, "\""), adj=1)
box("plot")
@
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Limits, adding to graphics}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{One data.frame instead of two vectors}
Default method if x is a data.frame:
<<plot_df, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot( beaver2[ ,2:3] )
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot limits I}
xlim with a two-value vector with lower and upper limit.
<<plot_lim1, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(beaver2[ ,2:3], xlim=c(-1000,3000),  ylim=c(36,40))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Plot limits II}
xaxis decreasing (can be very misleading!):
<<plot_lim2, echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(beaver2[ ,2:3], xlim=c(3000,-1000), ylim=c(36,40))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Adding datapoints}
<<plot_add, size="scriptsize", echo=-1>>=
par(mar=c(3.5,4,2,1), mgp=c(2.4,0.7,0), las=1)
plot(beaver2[ ,2:3])
points(100, 37.5, pch=21, bg=5, cex=4, col="red", lwd=3)
lines(x=c(5,120,514,918), y=c(37,39,38,37.5), col="green4", type="b")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Now it's your turn...}
\begin{exercise}{Plotting} %ex5
\begin{enumerate}
  \item Plot a dataset of your choice (eg from \rcode{library(help = "datasets")}).
  \item Add some red dotted lines between big quadratic points, filled with blue color.
  \item Label the axis and give your graph a big italic header with \texttt{cex.main, font.main}, see \rcode{?par}.
  \item Plot with a logarithmic scale on one axis.
  \item Set the axis to a certain limit. With \texttt{yaxs}, suppress the default 4\% range extension.
  \item Using \texttt{xaxt}, plot without an x-axis. Look in the help of \rcode{par} how this can be done. Then add a custom \rcode{axis}.
  \item Add a \rcode{legend} to the plot and thick-lined \rcode{box} around the final plot.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Plotting I}
<<ex5sola, size="small", eval=T, fig.height=3.6, fig.show="hide">>=
# generate "random" data:
set.seed(42) ; numbers <- cumsum(rnorm(40)) + 20
x <- c(10, 15, 31, 33); y <- c(19, 22, 17, 23)
# Basic plot:
plot(numbers, type="l", xlab="Time",
     main="Fake Time Series", cex.main=3, font.main=3,
     log="y", xlim=c(0,50), xaxs="i", xaxt="n" )
# Add points and lines
points(x=x, y=y, pch=22, type="p", cex=3, col="orange",
      bg="green")
lines(x=c(10, 15, 31, 33), y=c(-6, -3, -8, -2)+25, col="red",
      lty="dashed")
# Custom axis, legend and box around plot:
axis(side=1, at=c(0, 15, 30, 45)  )
legend("topright", legend=c("ts", "more fake stuff"),
       lty=c(1,2), col=c(1,2) )
box(lwd=5)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Plotting II}
\includegraphics[width=.99\textwidth]{fig/ex5sola-1.pdf}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{boxplots, histograms}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Health data, county-aggregated for >3k regions in the US.}
\scriptsize
\vspace{-0.5em}
Found through reddit: \href{https://lionbridge.ai/datasets/18-free-life-sciences-medical-datasets-for-machine-learning}{18 Free Life Sciences, Healthcare and Medical Datasets}\\
\href{https://healthdata.gov/dataset/community-health-status-indicators-chsi-combat-obesity-heart-disease-and-cancer/resource}{Community Health Status Indicators (CHSI) to Combat Obesity, Heart Disease and Cancer}\\
\datalinkBlob{CHSI\_meta.csv} abstracted from DATAELEMENTDESCRIPTION.csv\\
\datalinkBlob{CHSI\_data.csv} which is RISKFACTORSANDACCESSTOCARE.csv\\
Remember you can simply update the material through \key{git pull}
\vspace{-0.8em}
\pause
\begin{exercise}{medical boxplots} %ex
\begin{enumerate}
\item Read both files. You'll need \rcode{na.strings=c(-1111.1,-2222, -2222.2)} for the data.
\item Reduce the dataset to the following columns: \rcode{DF[,c(7,10,13,16,19,22,25:31)]}.
\item Create a boxplot of any column that sounds interesting.
\item Create a histogram of one of the first 5 columns. Why does it look like a normal distribution? (I told you these don't usually occur in real life.)
\item Create a boxplot of the first 5 columns to compare percentages.
\item BONUS: Create a violin plot with the \rcode{vioplot} package (or \rcode{ggplot2::geom\_violin}).
\item Using the formula interface (\rcode{Y~X, data=someDF}), create a boxplot showing the \textbf{number of doctors per 100k people} (Prim\_Care\_Phys\_Rate) depending on whether it's a designated \textbf{health professional shortage area} (HPSA\_Ind).
\item BONUS: Create a histogram of the number of uninsured people per county. Why does the distribution look like this? See if \rcode{berryFunctions} has a way to create a histogram on a logarithmic axis. Contemplate the concept of a lognormal distribution in comparison to an exponential distribution.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{solutions medical boxplots}
<<medboxplot, eval=FALSE, size="small">>=
  meta <- read.csv("data/CHSI_meta.csv")
  health <- read.csv("data/CHSI_data.csv", 
                     na.strings=c(-1111.1,-2222, -2222.2))
  health <- health[,c(7,10,13,16,19,22,25:31)]
  meta   <-   meta[ c(7,10,13,16,19,22,25:31), ]
  
  hist(health$Obesity, breaks=30) 
  # Central limit theorem: aggregation -> normality
  # We're looking at percentage of obesity per county, 
  # not at individuals
  boxplot(health[,1:5])
  vioplot::vioplot(health[,1:5])
  boxplot(Prim_Care_Phys_Rate~HPSA_Ind, data=health)
  
  hist(health$Uninsured)
  berryFunctions::logHist(health$Uninsured, breaks=20)
  plot(1:100, dexp(1:100, rate=0.06), col="red", type="l")
  lines(1:100, dlnorm(1:100, 3, 0.6), col="blue")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{saving plots, multiple figures}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Saving plots to a file}
In the menu of the graphics window, you can save the current plot by hand.
For reproducible sizes and if you're creating many plots, use
\pause
<<plot_save, eval=FALSE>>=
png("FileName.png", width=12, height=9, units="in",
           res=300, bg="transparent", pointsize=14)
  plot(1:20)
  title(main="Plot title")
  points(5,9)
dev.off() # to close the external device
@
\pause
The functions \rcode{pdf}, \rcode{jpeg}, etc. are also available.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{multiple figure layout I}
\vspace{-1em}
<<mfrow, echo=1:3>>=
# 3 rows, 2 columns:
par(mfrow=c(3,2), mar=c(3,3,1,1), mgp=c(1.9, 0.7, 0), las=1)
plot(stackloss[ ,1:2]) # 6 plot commands
plot(stackloss[ ,2:3])
hist(rnorm(300), col="orange")
par(cex.lab=0.65, cex.axis=0.8)
plot(cumsum(rnorm(30)), type="l", col="blue")
plot(cumsum(rnorm(300)), type="l", col="cyan")
plot(cumsum(rnorm(3000)), type="l", col="purple")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{multiple figure layout II}
\vspace{-1.5em}
<<layout, size="footnotesize", fig.height=2.5>>=
lay <- layout(matrix(c(1,1,2,2,
                       5,5,2,2,
                       3,3,4,4,
                       3,3,4,4), ncol=4, byrow=TRUE),
              widths=c(6,6,4,4))
layout.show(lay)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{multiple figure layout III}
From the example in \rcode{?layout}:\\
\vspace{-1em}
<<layout_application, echo=F>>=
x <- pmin(3, pmax(-3, stats::rnorm(50)))
y <- pmin(3, pmax(-3, stats::rnorm(50)))
xhist <- hist(x, breaks = seq(-3,3,0.5), plot = FALSE)
yhist <- hist(y, breaks = seq(-3,3,0.5), plot = FALSE)
top <- max(c(xhist$counts, yhist$counts))
xrange <- c(-3, 3)
yrange <- c(-3, 3)
nf <- layout(matrix(c(2,0,1,3),2,2,byrow = TRUE), c(3,1), c(1,3), TRUE)
# layout.show(nf)
par(mar = c(3,3,1,1))
plot(x, y, xlim = xrange, ylim = yrange, xlab = "", ylab = "")
par(mar = c(0,3,1,1))
barplot(xhist$counts, axes = FALSE, ylim = c(0, top), space = 0)
par(mar = c(3,0,1,1))
barplot(yhist$counts, axes = FALSE, xlim = c(0, top), space = 0, horiz = TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Box}
<<box, echo=F, fig.height=3.6, eval=TRUE>>=
par(oma=c(1,2,2,4), lend=1) # outer margins, line end style
laymat <- matrix(c(4,rep(1,4), 3, rep(2,6)), ncol=6, byrow=TRUE)
lay <- layout( laymat, heights=c(0.6, 0.4) )  ; par(mar=c(3,4,1,1), cex=1)  ; set.seed(12)
plot(runif(6), las=1, type="l", ylab="Y-Axis")
box("plot",   lwd=2, col="gold")
box("figure", lwd=2, col="red")
box("inner",  lwd=2, col="green4")
box("outer",  lwd=4, col="blue")
par(mar=rep(0,4)) ; plot(1, type="n", axes=T, ann=F)
legend("center", c("'plot'","'figure', after par(mfrow) or layout()","'inner'","'outer', if outer margins were set by par(oma)"), bty="n", title="box( _ )", col=c(7,2,3,4), lwd=2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Enough talk, action...}
\begin{exercise}{Export (multipanel) plots} %ex5
\begin{enumerate}
  \item Read \datalinkText{Zugspitze.txt} with monthly weather records
  \item With \rcode{par(mfrow=...)}, set up a figure with two panels (left and right)
  \item Plot a histogram of the air temp (MO\_TT) records in the left panel
  \item Plot a line graph of the first 50 months in the right panel
  \item Now export this graph as png with useful size and resolution
  \item BONUS 1: also export as a vector graph (e.g. PDF, EPS, SVG, svglite package)
  \item BONUS 2: Set smaller margins (\rcode{mar}) around each panel
  \item BONUS 3: Set an outer margin (\rcode{oma}) with an outer \rcode{title} for the entire figure
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Export (multipanel) plots I}
<<explotexport>>=
wzug <- read.table("data/Zugspitze.txt", header=TRUE)

pdf("fig/zugspitze.pdf", height=4)
par(mfrow=c(1,2), mar=c(3,3,1,1), oma=c(0,0,2,0), las=1)
hist(wzug$MO_TT, col="coral", breaks=25,
     main="Histogram monthly values")
plot(wzug$MO_TT[1:50], type="l", lwd=2, 
     col="darkorchid", main="First 50 months")
title(main="Temperature Zugspitze 1900:2015", outer=TRUE)
dev.off()
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Export (multipanel) plots II}
\includegraphics[width=.99\textwidth]{fig/zugspitze.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Graphing paths: NA lines between entry groups}
<<riverpaths, echo=-1, size="scriptsize", out.width='.9\\textwidth'>>=
par(mar=c(3,3,1.5,0), mgp=c(2, 0.7, 0))
library("berryFunctions") # >= 1.9.2 (2015-10-22) for insertRows, colPoints
tfile <- system.file("extdata/rivers.txt", package="berryFunctions")
rivers <- read.table(tfile, header=TRUE, dec=",")
colPoints(x,y,n, data=rivers, add=FALSE, lines=TRUE, lwd=3,
          legargs=c(y1=0.8,y2=1, density=FALSE) )
@
% Orange$Tree <- as.numeric(as.character(Orange$Tree))
% library("berryFunctions") # >= 1.9.2 (2015-10-22) for insertRows, colPoints
% Or2 <- insertRows(Orange, r=which(diff(Orange$Tree)>0)+1:4, new=NA)
% colPoints(age, circumference, Tree, data=Or2, add=F, lines=T,
%          col=c("orange","blue","darkgreen","cyan","purple"), legend=F,
%          main="Orange tree growth paths", xlab="Age  [days]", ylab="Size")
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Base R vs ggplot2}
This has all been graphing with the possibilities of base R.\\
There is also the package \rcode{ggplot2} which a lot of people love to use.\\
I get everything done with base R and don't see a need to learn ggplot grammar.\\
You can do whatever you want - it's both R, both have their advantages.\\
A very good place to start learning ggplot2 is:\\
\url{http://minimaxir.com/2017/08/ggplot2-web/}\\
To compare both paradigms, see:\\
\url{http://flowingdata.com/2016/03/22/comparing-ggplot2-and-r-base-graphics/}\\
Be sure to follow the links in the beginning of the article...
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Practice multipanel plots + empirical distribution analysis}
\scriptsize
\begin{exercise}{Boxplots and histograms} %ex
\begin{enumerate}
\item Read \datalinkBlob{box.txt} into R. Remember you can simply update the material through \key{git pull}.
\item Set up a multipanel plot and compare the boxplots of the three columns. How do they differ?
\item Compare the histograms of the three columns. How do they differ? Use the same axis limits on each panel.
\item Arrange all 6 panels into one graph. 
\item Use a horizontal boxplot. Use the same axis limits (note: for horizontal, you still need to set \texttt{ylim}, not \texttt{xlim}).
\item BONUS: Write a loop to create the boxplots and histograms (note: you might need to change from \texttt{mfrow} to \texttt{mfcol} or vice versa).
\item BONUS: Make the graphs look nice through the use of colors, histogram breaks, nice spacing between the panels (\rcode{par mar}), an informative overall graph \rcode{title} in the outer margin (\rcode{par oma}) etc.
\item Change the histogram y axis from count to density (using the \texttt{freq} argument). Now add a line to each histogram with the density function of the normal distribution parametrized by the \rcode{mean} and \rcode{sd} of each sample. \rcode{dnorm} will need a vector of values like \rcode{0:60}.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution multipanel distribution plotting}
<<mulipaneldist, size="footnotesize", fig.show="hide", fig.height=4.5>>=
# Read data, set colors + multipanel plot:
box <- read.table("data/box.txt", header=TRUE)
colors <- c("salmon","brown","firebrick1")
par(mfrow=c(3,2), mar=c(2,0,0.4,0.4), oma=c(0,0,2,0), cex=0.7)

# for each column, create two plots:
for(i in 1:3)
  {
  # 1: Boxplot:
  boxplot(box[,i], ylim=c(2.3,60), horizontal=TRUE, col=colors[i])
  # 2: Histogram: 
  hist(box[,i], xlim=c(2.3,60), breaks=-3:62, freq=FALSE, main="", 
       yaxt="n", col=colors[i])
  # add density of normal distribution parametrized to data sample
  lines(0:65, dnorm(0:65, mean(box[,i]), sd(box[,i])))
}
# Add title to outer margin (par oma):
title(main="same boxplots, different distributions!", outer=TRUE)

@
\end{frame}

%------------------------------------------------------------%

\begin{frame}
\includegraphics[width=.99\textwidth]{fig/mulipaneldist-1.pdf}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{6. Character Operations}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Character strings: Intro}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Character strings I}
<<char1, echo=T, eval=TRUE, tidy=FALSE>>=
paste("NiceThing", 3:5) # Creates vector of Mode character
paste(2, "hot", 4, "U", sep="_")
letvec <- c("some different", "let", "ters")
letvec
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Character strings II}
<<char2, echo=T, eval=TRUE, tidy=FALSE>>=
length(letvec)
nchar(letvec)
paste("nice", letvec, sep="_")
@
\end{frame}

%------------------------------------------------------------%
\begin{frame}[fragile]{Character strings III}
<<char3, echo=T, eval=TRUE, tidy=FALSE>>=
paste(letvec, sep="")
paste(letvec, collapse="")
# remove spaces: substitute " " in letvec with ""
sub(" ", "", letvec)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Character strings IV}
<<char4, echo=T, eval=TRUE, tidy=FALSE>>=
substr("Monster Party", start=2, stop=5)
# If you need several string segments:
substring("Monster Party", first=c(1,3,5), last=c(2,5,9) )

strsplit("Die Aerzte - Monster Party", split=" - ")[[1]]
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Backslash "\textbackslash" : Escape Character}
"\textbackslash n" for return or line break (newline), eg in graphictitles and -texts\\
"\textbackslash t" for Tabstop, e.g. for \rcode{write.table("path/file.txt", yourdata, sep="\textbackslash t")}\\
"\textbackslash \textbackslash" for Backslash as symbol in \rcode{title, text, legend} etc.\\
"\textbackslash "" for " as character\\
"\textbackslash U" for Unicode, e.g.:
<<backsl, echo=T, eval=F, tidy=FALSE>>=
plot(1)
# average symbol without using "expression":
mtext(paste("\U00D8", 5.4, "\U00B0 C"), col="red")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Time to practice...}
\begin{exercise}{character string operations} %ex6
In the German chocolate industry, we love\\
\small{\rcode{schoko <- c("Ritter Sport", "Lindor", "Frigor", "Milka", "Frey", "More Lindor")}}
\begin{enumerate}
  \item which element \textbf{is} or \textbf{contains} "Lindor"?\\ Find out with \rcode{match}, \rcode{grep}, \rcode{\%in\%} and \rcode{grepl}. What are the differences between those?
  \item Replace "or" with "nicor" using \rcode{sub} and \rcode{gsub}.
  \item What's the problem with \rcode{"Ritter sport" \%in\% schoko}?
  \item What does \rcode{"Ritter [s,S]port" \%in\% schoko} do?
  % More on RegExp!
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1: Character strings}
<<ex6sola, size="small", eval=FALSE>>=
schoko <- c("Lindor", "Ritter Sport", "Frigor", "Milka",
            "Frey", "More Lindor")
# Which element in schoko IS Lindor
match("Lindor", schoko)
match(schoko, "Lindor")
match(schoko, c("Lindor", "Frigor") )

# Which element in schoko CONTAINS Lindor
grep("Lindor", schoko)
grep("or", schoko)
grepl("Lindor", schoko) # logical value

# Is one of the elements of schoko == "Lindor" at all?
"Lindor" %in% schoko
any(  grepl("Lindor", schoko)  ) # any TRUE?
all(  grepl("Lindor", schoko)  ) # All TRUE
! grepl("Lindor", schoko)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.2-41: Character strings}
<<ex6solb, eval=FALSE>>=
# Replace Character strings (substitute)
sub(pattern="or", replacement="nicor", schoko)
# Replace all occurences (global substitution)
gsub(pattern="or", replacement="nicor", schoko)

# Avoid capitalization issues with
tolower(schoko)
"Ritter [s,S]port" %in% schoko
# Does not work!!
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{7. Conditions \& loops}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Conditions}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Conditional execution I}
\vspace{-0.8em}
\footnotesize{\textit{If you follow along with the handout version (one page per slide), please don't view this slide yet.
We'll reveal piecewise.}}\\
\vspace{0.3em}
\pause
Syntax for a single logical value:\\
\rcode{\alert{if}(this\_is\_true) \{do\_something\} \alert{else} \{do\_other\_thing\}}\\[\baselineskip]
\pause
Syntax for a vector with several T/F values:\\
\rcode{\alert{ifelse}(condition, expression1, expression2)}\\[\baselineskip]
\pause
If condition == TRUE, then expression1 is evaluated,
if condition == FALSE, then expression2 is evaluated.\\[1em]
\pause
\begin{columns}
\begin{column}{.40\textwidth}
\texttt{7-3 > 2 \\
\textcolor{blue}{class}(7-3 > 2 ) \\
\textcolor{red}{if}(7-3 > 2) 18  \\
\textcolor{red}{if}(7-3 > 5) 18  \\
\textcolor{red}{if}(7-3 > 5) 18 \textcolor{red}{else} 17 }
\end{column}
\begin{column}{.59\textwidth}
\pause TRUE\\
\pause logical = truth value, boolean\\
\pause Condition is TRUE, so 18 is returned\\
\pause Condition is FALSE, so nothing happens*\\
\pause Condition FALSE, so 17 is returned.
\end{column}
\end{columns}
%' <<cond1b, eval=FALSE, size="small">>=
%' 7-3 > 2                # TRUE
%' class(7-3 > 2 )        # logical = truth value, boolean
%' if(7-3 > 2) 18         # Condition is TRUE, so 18 is returned
%' if(7-3 > 5) 18         # Condition is FALSE, so nothing happens
%' if(7-3 > 5) 18 else 17 # Cond. F, so 17 is returned.
%' @
%' % onslide doesn't work in a verbatim (fragile) environment
\pause
\footnotesize{\textit{*: technically, \rcode{NULL} is returned invisibly}}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Conditional execution II}
<<cond2, echo=TRUE, eval=FALSE, tidy=FALSE>>=
# Several commands must be held together with curly braces:
if(TRUE)
  {
  plot(1:10, main="TRUE in code")
  box("figure", col="blue", lwd=3)
  } else
# do something else: plot random numbers
    {
    plot(rnorm(500), main="FALSE in code")
    }
# these last brackets can (but should not) be left away
# indenting code makes it readable for humans

par(mfrow=c(1,2), cex=1, las=1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Conditional execution III}
<<cond3, echo=FALSE, eval=TRUE, tidy=FALSE>>=
par(mfrow=c(1,2), cex=1, las=1)
if(TRUE)
  {
  plot(1:10, main="TRUE in code")
  box("figure", col="blue", lwd=3)
  } else
    {
    plot(rnorm(500), main="FALSE in code")
    }
if(FALSE)
  {
  plot(1:10, main="TRUE in code")
  box("figure", col="blue", lwd=3)
  } else
    {
    plot(rnorm(500), main="FALSE in code")
    }
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Vectorising: \alert{if}(c) e1 \alert{else} e2 ~~~ vs ~~~ \alert{ifelse}(c, e1, e2)}
<<ifelse_vectorized1>>=
v <- c(13, 14, 15, 16, 17)
v>14
@
\pause
<<ifelse_vectorized2>>=
ifelse(v>14, v+10, NA) # can handle vector of input
@
\pause
<<ifelse_vectorized3>>=
if(v>14) v+10 else NA
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Notes on logical values}
\begin{itemize}[<+->]
\item as you might have seen in \rcode{read.table(header=T)}, logical values (TRUE, FALSE) can be abbreviated.
\item If you want to play a mean prank on someone, write\\ \rcode{T <- FALSE; F <- TRUE} in their \href{https://rclickhandbuch.wordpress.com/install-r/rprofile/}{Rprofile} (see \rcode{?Startup}).
\item Logical (boolean) values F and T internally are often converted to integers 0 and 1, thus \rcode{sum(c(T,F,F,T,T,T,F,F,T))} is the number of TRUEs in a vector, \rcode{mean} yields the proportion of TRUEs.
\item \rcode{which(logicalVec)} gives the indices (positions) of TRUE values.
\item \rcode{Vec[logicalVec]} returns only the values of vec corresponding to TRUE in logicalVec (No need to wrap it into \rcode{which}).
\item Logical operators: \rcode{!, \&, |, xor()} (not, and, or, exclusive or)
\item \rcode{||} and \rcode{\&\&} for a single logical value.\\
      In \rcode{a || b}, expression \rcode{b} will NOT be evaluated if \rcode{a} is not TRUE.\\
      In contrast, when you use \rcode{a | b}, expression \rcode{b} will be evaluated regardless of outcome of \rcode{a}.
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Notes on conditional code execution}
\begin{itemize}[<+->]
\item \rcode{\alert{if}(c)\{ex1\}} is valid code, thus R doesn't expect \alert{else} anymore.
\item If you execute code line by line (in a script, for example), \alert{\}} and \alert{else} must be on the same line.
\item Many people consider it good practice to do this in functions as well, but for machine-readability, it is technically fine to write\\
\texttt{\alert{if}(cond)\\
~~\{\\
~~ex1a\\
~~ex1b\\
~~\} \\
\alert{else}\\
~~ex2}
\item \rcode{\alert{if}(logicalValue==TRUE) ...} is usually unnecessary, you can write\\
\onslide<+-> \rcode{\alert{if}(logicalValue) ...}, but sometimes,\\
\onslide<+->  \rcode{\alert{if}(isTRUE(logicalValue)) ...} helps to deal with NAs.
% \item \rcode{cat(T, letters[c(12,15,22,5)])}
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Actual usage of if else statements}
See the \rcode{hist} source code: \\
\href{https://github.com/wch/r-source/blob/trunk/src/library/graphics/R/hist.R}{github.com/wch/r-source ~ -> ~ src / library / graphics / R / hist.R}\\[1em]
\pause
<<mad, eval=F>>=
mad
@
\pause
Multiple nested conditionals\\
\texttt{\alert{if}(a) b \alert{else} \alert{if}(c) d \alert{else} e}\\
can be avoided with \rcode{switch}.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time to practice}
\begin{exercise}{if else - Conditional code execution} %ex
\begin{enumerate}
  \item \rcode{sqrt} returns NaN for the negative values in \rcode{v <- -3:5} and warns about it. With a conditional expression, pass 0 instead of negative values to \rcode{sqrt}.
  \item Construct a statement that checks whether the variable \rcode{input <- 4} is a number smaller than 3. Let it write a useful \rcode{message} to the console (for both cases). Now test it with \rcode{input <- 1.8} and \rcode{input <- -17}.
  \item Now restrict the correct value of input to \emph{positive} numbers <3, i.e. the number must be <3 AND $\geq$ 0.
  \item BONUS 1: What happens if \rcode{input <- "2"} or if \rcode{input <- "b"}?
  \item BONUS 2: Create a character variable that, depending on the result of \rcode{rnorm(1)}, is initiated with "probable" or "unlikely".
  \item BONUS 3: \rcode{replicate} this experiment 1000 times and examine the result with \rcode{table}.
  \item BONUS 4: How could you do this with \rcode{ifelse}?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1: if else}
<<excondsol1a, eval=TRUE, size="footnotesize", echo=-1>>=
options(width=80, digits=5)
v <- -3:5
sqrt(v)
@
<<excondsol1b, eval=TRUE, size="footnotesize", echo=-1>>=
options(width=80, digits=5)
ifelse( v >= 0, sqrt(v), 0)
@
<<excondsol1c, eval=TRUE, size="footnotesize", echo=-1>>=
options(width=80, digits=5)
sqrt(ifelse( v >= 0, v, 0))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.2: if else}
<<excondsol2, eval=TRUE, echo=-1>>=
options(width=80)
input <- 4
if( input >= 3 ) message("Input was wrong.
                         It should be <3") else
                 message("Input OK")

# run it again after
input <- 1.8
input <- -17
@
<<resetopts2, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3: if else}
<<excondsol3, eval=FALSE>>=
# three different solutions:
if( input >= 3 ) message("Input is > 3") else
if( input < 0 )  message("Input is < 0") else
                 message("Input OK")

if( input >= 3 |  input < 0)
   message("Input outside 0...3") else
   message("Input OK")

if( input > 0  &  input <= 3 )   message("Input OK") else
           message("Input (",input,") outside 0...3")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3: if else BONUS}
<<ifelseexbonus, eval=FALSE>>=
result <- if(rnorm(1)>2) "unlikely" else "probable"

result <- replicate(n=1000, expr=
             if(rnorm(1)>2) "unlikely" else "probable")
table(result)

result <- ifelse(rnorm(1000)>2, "unlikely", "probable")
table(result)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{For Loops}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{For loops}
\vspace{-0.3em}
Execute a block of code several times, with different input values.\\
Syntax: ~ \texttt{\alert{for}(aRunningVariable \alert{in} aSequence)\{ doSomething \}}
\pause
Often, i (for index) is used, thus ~~ \texttt{\alert{for}(i \alert{in} 1:n) \rcode{doThis}(i)}\\
\pause
\textit{Curly brackets are optional if there is one single expression.}
\vspace{-0.5em}
\pause
<<for1, echo=T, eval=F>>=
help("for") # needs quotation marks!
@
\pause
<<for_print, eval=F>>=
print(1:2)
print(1:5)
print(1:9)
@
\pause
This is easier and less prone to human errors with:
\vspace{-0.5em}
\pause
<<for2, echo=T, eval=TRUE, tidy=FALSE>>=
for(i in c(2,5,9) ) { print(1:i) }
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: execute code multiple times I}
\hspace{5em} $y = f(x, n) = \frac{12.5*n}{(n-1)!}*(\frac{n x}{8})^{(n-1)}*e^{-\frac{n x}{8}}$
<<for3a, echo=F, size="footnotesize">>=
par(mar=c(3,3,1,1), mgp=c(2,0.8,0), las=1)
x <- seq(0,20,0.1)
plot(x, 12.5*10/factorial(10-1)*(x/8*10)^(10-1)*exp(-x/8*10),
     ylab="y  =  f(x, n=10)", type="l", lwd=2, col="orange")
@
\pause
We'll plot the curve for different n values (5,6,7,...,25)
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: execute code multiple times II}
\textblockrulecolour{red}
<<for3, echo=-1, size="footnotesize">>=
par(mar=c(3,3,1,1), mgp=c(2,0.8,0), las=1)
x <- seq(0,25,0.1)
plot(x,x, type="n", ylab="y = f(x,n)")
lines(x, 12.5*5/factorial(5-1)*(x/8*5)^(5-1)*exp(-x/8*5), col="red")
lines(x, 12.5*6/factorial(6-1)*(x/8*6)^(6-1)*exp(-x/8*6), col="red")
@
\only<2>{
\begin{textblock*}{0.2cm}(2.6cm,2.2cm)
\vspace{0.9cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(4.6cm,2.2cm)
\vspace{0.9cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(6.27cm,2.2cm)
\vspace{0.9cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(6.93cm,2.2cm)
\vspace{0.9cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(9.25cm,2.2cm)
\vspace{0.9cm} ~
\end{textblock*}
%
}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: execute code multiple times III}
<<for5, echo=-1, size="footnotesize">>=
par(mar=c(3,3,1,1), mgp=c(2,0.8,0), las=1)
x <- seq(0,25,0.1)
plot(x,x, type="n", ylab="y = f(x,n)")
for (n in 5:25)
lines(x, 12.5*n/factorial(n-1)*(x/8*n)^(n-1)*exp(-x/8*n), col="red")
@
\begin{textblock*}{0.2cm}(2.6cm,2.65cm)
\vspace{0.45cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(4.6cm,2.65cm)
\vspace{0.45cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(6.27cm,2.65cm)
\vspace{0.45cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(6.93cm,2.65cm)
\vspace{0.45cm} ~
\end{textblock*}
%
\begin{textblock*}{0.2cm}(9.25cm,2.65cm)
\vspace{0.45cm} ~
\end{textblock*}
%
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: fill a vector}
\vspace{-0.8em}
\textit{If you follow along with the handout version (one page per slide), please don't view this slide yet.
We'll reveal piecewise.}
\vspace{-0.8em}
\pause
<<for6>>=
v <- vector(mode="numeric", length=20)   ;  v
@
\pause \vspace{-1.8em}
<<for6b>>=
for(i in 3:17)  {  v[i] <- (i+2)^2  }  # what is now in v?
@
\pause \vspace{-1.8em}
<<for6b2, echo=2>>=
options(width=40)
v # the code above was executed once for each i
options(width=50)
@
\pause \vspace{-0.8em}
What objects are now in the global environment workspace?\\
\pause
-> \rcode{v} (as above) and \rcode{i} (with the last assigned value, 17)\\
\pause \vspace{0.3em}
In R, \rcode{for} loops are slow. Always try to vectorize (the best option, not always possible) or use \rcode{lapply} (less code, easy to parallize).
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: multiple graphs}
\small
\begin{exercise}{for loop}
\begin{enumerate}
\item Read \datalinkText{stocks.txt}, so that there are no factors in the data.frame
\item Change the first column type from \texttt{char} to \texttt{date} with \rcode{?as.Date}
\item What do you get with \rcode{plot(yourDF[ ,c(1,2)])}? Make it a line graph.
\item With a \rcode{for} loop, plot each stock time series, i.e. plot the \textit{i}th column
over the first column.
\item BONUS 1: Use good annotations (\texttt{main, ylab, xlab}) and turn y axis labels upright (\texttt{las})
\item BONUS 2: Plot all lines in a single graph (set \texttt{ylim} in the \rcode{plot} command.). 
      Label the lines directly. Use a logarithmic axis, enhanced with \rcode{berryFunctions::logAxis}
\item Tough BONUS 3: With \rcode{par(mfrow...)}, set up a two by three panel plot. Make the plot margins smaller (\rcode{par} \texttt{mar}) and move the axis labels closer to the plots (\texttt{mgp}).
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loops: multiple graphs}
\vspace{-1em}
<<forpanel, size="footnotesize", fig.height=2.8>>=
stocks <- read.table("data/stocks.txt", header=T, as.is=T)
stocks$Date <- as.Date(stocks$Date)
par(mfrow=c(2,3), mar=c(2,4,1,1), mgp=c(2.5,0.7,0),oma=c(0,0,2,0),las=1)
for(i in 2:7) plot(stocks[ ,c(1,i)], type="l")
mtext("stocks this decade", line=0, outer=TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{logarithmic axis}
\vspace{-0.9em}
<<forlines, fig.show="hide", echo=-1, size="footnotesize", fig.width=5>>=
 par(mar=c(2,5,1.5,3), mgp=c(3,0.7,0), cex=0.8)
 stocks <- read.table("data/stocks.txt", header=TRUE, as.is=TRUE)
 stocks$Date <- as.Date(stocks$Date)
 companies <- colnames(stocks)[-1]
 cols <- c("purple", "orange", "red", "green", "pink", "blue")
 names(cols) <- companies     # cols["AMAZON"]
 
 plot(stocks$Date, stocks$APPLE, type="n", log="y", yaxt="n", 
      xlim=as.Date(c("2007-01-03","2020-01-01")), 
      ylim=range(stocks[,-1], na.rm=TRUE), 
      ylab="Stock values, log axis  [USD]", xlab="Date", las=1,
      main="Tech companies rise faster than the car industry")
 berryFunctions::logAxis(2)
 
 for(comp in companies) 
     lines(stocks$Date, stocks[,comp], col=cols[comp])
 
 #legend("topleft", companies, fill=cols)
 berryFunctions::textField(x=tail(stocks[,1],1), labels=companies, adj=0,
                           y=as.numeric(tail(stocks[,-1],1)), col=cols, 
                           rrarg=list(bothsame=FALSE), cex=0.8, xpd=TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{logarithmic axis}
\includegraphics[width=\textwidth]{fig/forlines-1.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{multipanel graph}
\vspace{-1em}
<<forpanel2, size="scriptsize", fig.height=2.5>>=
par(mfrow=c(1,2), mar=c(4,4,2,0.1), mgp=c(2.5,0.7,0), cex=0.7, las=1)
for(i in 2:3)
 {
 plot(stocks[ stocks$Date>as.Date("2016-04-01") , c(1,i) ],
      main=colnames(stocks)[i], xaxt="n", type="l", xlab=" ",
      ylab=if(i==2) "Adjusted daily share price  [USD]" else "")
 berryFunctions::monthAxis(1)
 }
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{stocks data from \href{http://finance.yahoo.com}{finance.yahoo.com}}
In case you want to know how I create (and update) the stock dataset:
<<stocks_datapreparation, size="scriptsize", eval=F>>=
# Download current datasets:
if(!requireNamespace("quantmod")) install.packages("quantmod")
if(!requireNamespace("pbapply"))  install.packages("pbapply")
dummy <- pbapply::pblapply(c("F","VLKAF", "AMZN","AAPL","GOOG","MSFT"),
   function(x) zoo::write.zoo(x=quantmod::getSymbols(x, auto.assign=FALSE)[,6],
                           file=paste0("data/finance/",x,".txt"), col.names=T))

# read single files to R and merge into one file:
stocks <- lapply(dir("data/finance", full=TRUE),
                  read.table, as.is=TRUE, header=TRUE)
stocks <- Reduce(function(...) merge(..., all=T), stocks)

# Get nicer column names:
names <- sapply(strsplit(colnames(stocks), ".", fix=TRUE),"[", 1)
colnames(stocks) <- c(Index="Date", F="FORD", VLKAF="VOLKSWAGEN",
         AMZN="AMAZON", AAPL="APPLE", GOOG="GOOGLE", MSFT="MICROSOFT")[names]

# Save to disc:
write.table(stocks, file="data/stocks.txt", row.names=F, quote=F)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{\rcode{seq\_along(n)} is safer than \rcode{1:n} in \alert{for} loops}
\pause
\vspace{-0.5em}
<<seq_along0, size="scriptsize">>=
do_something <- function(x) if(x<1) stop("x must be >=1, not: ", x) else x
something <- 1:6
@
\pause
You'll often see the dangerous code \rcode{\alert{for}(i in 1:n)}: \vspace{-0.7em}
<<seq_along1, size="footnotesize">>=
for(i in 1:length(something)) do_something(i) # works with current sth
@
\pause
Imagine this:\vspace{-0.5em}
<<seq_along2, size="footnotesize">>=
something <- which(letters=="4")
for(i in 1:length(something)) do_something(i) # fails! (same code!)
@
\pause
Safer to use is:\vspace{-0.7em}
<<seq_along3>>=
for(i in seq_along(something)) do_something(i)
@
\pause
Because:\vspace{-0.5em}
<<seq_along4, size="scriptsize">>=
1:length(something)     ;   seq_along(something)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for loops: file exercise}
\begin{exercise}{for loops in file creation}
\scriptsize
We'll write many datasets to disc (and read them back).
\begin{enumerate}
\item With \rcode{paste0}, print a filename of the structure "mydata\_123.txt" 
      using the name, the number and the file ending as inputs. 
      We'll be changing the number later in a loop.
\item Print a data.frame with two columns, each with 10 random numbers: 
      one column from the normal, one from the exponential distribution
\item With \rcode{write.table}, write such a table to a file in a subfolder (remember \rcode{dir.create}), 
      using the number of rows (e.g. 10) in the filename.\\
\item BONUS: change the arguments so that row numbers and quotation marks are not printed and tabstops are used for column separation.
\item With a \rcode{for}-loop, now write files for different sample sizes, e.g. 10, 20, 50, 100, 500.
\item Using the output of \rcode{dir()}, read all the files into a list of data.frames.
      Remember to first create an empty list.
\item BONUS: name the list elements according to the filenames. 
\item BONUS: now replace the whole file reading construct with an \rcode{lapply} loop. 
      Celebrate how much nicer your code looks. 
      Check how you can get element names with \rcode{sapply(..., simplify=FALSE)}
\item BONUS: With \rcode{unlink}, delete the files from this exercise. 
      This function is vectorizable, so there's no need to do this in a for loop!
\end{enumerate}
\end{exercise}
\normalsize
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for loops: file exercise solution}
<<forloops_file_writing, eval=FALSE, size="footnotesize">>=
dir.create("loopexercise")
for(n in c(10,20,50,100,500)) 
    write.table(x=data.frame(norm=rnorm(n), exp=rexp(n)), 
                file=paste0("loopexercise/randomdata_", n, ".txt"),
                quote=F, row.names=F, sep="\t")

fnames <- dir("loopexercise", full=TRUE)
fcontents <- list()
for(fn in fnames) 
   fcontents[[fn]] <- read.table(fn, header=TRUE)

flist <- sapply(dir("loopexercise", full=TRUE), 
                read.table, header=TRUE, simplify=FALSE)

all.equal(fcontents, flist) # TRUE

unlink(paste0("loopexercise/randomdata_", c(10,20,50,100,500), ".txt"))
# unlink("loopexercise", recursive=TRUE) # less safe...
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{lapply, Rcpp}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{for -> lapply I: basics}
\vspace{-1em}
<<for_lapply1, eval=FALSE>>=
files <- dir("../rawdata", pattern="*.csv", full=TRUE)

#
@
\pause \vspace{-2.7em}
<<for_lapply2, eval=FALSE>>=
# bad and slow way:
ldfs <- list() # initiate empty list
for(i in 1:length(files))
   ldfs[[i]] <- read.csv(files[i], as.is=TRUE)

#
@
\pause \vspace{-2.7em}
<<for_lapply3, eval=FALSE>>=
# much better way: apply function to each file
ldfs <- lapply(X=files, FUN=read.csv, as.is=TRUE)

#
@
\pause \vspace{-2.7em}
<<for_lapply4, eval=FALSE>>=
# single data.frame if all files have n columns:
df <- do.call(rbind, ldfs)

#
@
\pause \vspace{-2.7em}
<<for_lapply5, eval=FALSE>>=
# PS: much faster in this example could be
library("data.table") # fread + rbindlist
ldfs <- lapply(X=files, FUN=fread, sep=",")
df <- rbindlist(ldfs)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for -> lapply II: progress bar, names, indexing etc}
\vspace{-0.6em}
<<for_lapply6, eval=FALSE>>=
ldfs <-   lapply(X=files, FUN=read.csv, as.is=TRUE)

#
@
\pause \vspace{-3.48em}
<<for_lapply7, eval=FALSE>>=
# progress bar with remaining time
library("pbapply")
ldfs <- pblapply(X=files, FUN=read.csv, as.is=TRUE)

#
@
\pause \vspace{-3.48em}
<<for_lapply8, eval=FALSE>>=
# nice additional stuff:
names(ldfs) <- files
str(ldfs, max.level=1)
ldfs[[2]] # second list element

#
@
\pause \vspace{-3.58em}
<<for_lapply9, eval=FALSE>>=
# get third column / fifth row from each df:
sapply(ldfs, "[",  , j=3)
sapply(ldfs, "[", 5,    )
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{lapply exercise}
\begin{exercise}{lapply}
\begin{enumerate}
\item Get the average of each element in the built-in dataset 
      \rcode{Harman23.cor} with \rcode{lapply}.
\item Now use \rcode{sapply} instead. What changes?
\item BONUS: Do this again with a \rcode{for} loop.
\item Please create \rcode{max\_n <- function(...) max(rnorm(1e7))}. 
      Now run this 10 times with an \rcode{sapply} loop.
\item Display a progress bar along with it.
\item BONUS: From each element of \rcode{Harman74.cor}, get the first 5 values.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{lapply exercise solution I}
<<exlapply_sol1>>=
lapply(Harman23.cor, mean)
sapply(Harman23.cor, mean) # simplified into a vector
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{lapply exercise solution II}
<<exlapply_sol2>>=
harmeans <- rep(NA,length(Harman23.cor))
for(i in 1:length(Harman23.cor) ) 
    harmeans[i] <- mean(Harman23.cor[[i]])
names(harmeans) <- names(Harman23.cor)
harmeans

max_n <- function(...) max(rnorm(1e5))
pbapply::pbsapply(1:5, max_n)
@
<<exlapply_sol3, eval=FALSE>>=
lapply(Harman74.cor, "[", 1:5)
@
\end{frame}

%------------------------------------------------------------%
\begin{frame}[fragile]{for -> lapply IIIa: parallel on multiple CPU cores}
\vspace{-1em}
<<for_lapply10, eval=FALSE>>=
library("parallel") # already comes with R
# -> don't try to  install.packages("parallel")
nc <- detectCores()-1

#
@
\pause \vspace{-2.6em}
<<for_lapply11, eval=FALSE>>=
# multicore parallel execution
ldfs <-        lapply(X=files, FUN=read.csv, as.is=TRUE)
ldfs <-      mclapply(X=files, FUN=read.csv, as.is=TRUE,
                      mc.cores=nc) # easy on linux

#
@
\pause \vspace{-2.6em}
<<for_lapply12, eval=FALSE>>=
# more code needed on windows:
cl <- makePSOCKcluster(nc)
ldfs <- parLapply(cl, X=files, fun=read.csv, as.is=TRUE)
stopCluster(cl)

#
@
\pause \vspace{-2.6em}
<<for_lapply13, eval=FALSE>>=
# sometimes needed before parLapply call:
clusterExport(cl, c("files","otherObjects"))
clusterEvalQ(cl, library("somePackage"))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for -> lapply IIIb: parallel AND progress bar}
\vspace{-1em}
<<for_lapply11b, eval=FALSE>>=
berryFunctions::parallelCode() # template for windows

library(parallel)
library(pbapply) # (>2016-10-30)
cl <- makeCluster( detectCores()-1 )
myfun <- function(...) mean(rnorm(1e6))
clusterExport(cl, "myfun")
dfs1 <- pblapply(X=1:500, FUN=myfun) # 36 sec on 1 CPU core
dfs2 <- pblapply(X=1:500, FUN=myfun, cl=cl) # 10 s on 7
stopCluster(cl)

# selects windows or linux method for you!
# Peter Solymos and Zygmunt Zawadzki are awesome!
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for -> lapply IV: code timing}
\vspace{-0.8em}
\scriptsize
<<for_lapply14, eval=FALSE>>=
begintime <- Sys.time(); begintime
parLapply(cl, X, fun)
Sys.time() - begintime ; rm(cl, begintime)
@
\pause \vspace{-1.2em}
<<for_lapply15, eval=TRUE, echo=-1, size="scriptsize", warning=FALSE>>=
options(width=100)
#install.packages("microbenchmark")
library(microbenchmark)
forbad <- function(n)  # fibonacci
  {
  fibvals <- c(1,1)
  for (i in 3:n) fibvals[i] <- fibvals[i-1]+fibvals[i-2]
  fibvals
  }
forgood <- function(n)
  {
  fibvals <- rep(1,n)
  for (i in 3:n) fibvals[i] <- fibvals[i-1]+fibvals[i-2]
  fibvals
  }
mb <- microbenchmark(forbad(2000), forgood(2000))  ;  mb
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{for -> C++ code: \rcode{Rcpp}}
\small
Loops are fast in C++, so outsource that part of your code into C.
The package \rcode{Rcpp} will compile it for you and make it available as a normally accessible R function.\\
\pause
Start learning at
\url{http://adv-r.had.co.nz/Rcpp.html}\\
\pause
Speed gain is highly variable, of course, but you might be able to reduce your computing time from 2 hours to 20 seconds!\\[1em]
\pause
To find the slow parts of your code, you perform a process called "profiling":\\
\url{https://www.r-bloggers.com/profiling-r-code}\\
\url{https://www.rdocumentation.org/packages/utils/topics/Rprof?}\\
\url{https://adv-r.had.co.nz/Profiling.html}\\
\pause
New and very promising:\\
\scriptsize
\url{https://blog.rstudio.org/2016/05/23/profiling-with-rstudio-and-profvis}\\
\url{https://support.rstudio.com/hc/en-us/articles/218221837-Profiling-with-RStudio}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{For loop: Fibonacci}
The Fibonacci sequence consists of the following integers:\\
1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ...\\
The first two values are 1, the following values are always the sum of the previous two elements.
\begin{exercise}{Fibonacci}
\begin{enumerate}
\item Create the first 100 numbers of the fibonacci sequence with a for loop
\item BONUS 1: "forget" to create an empty vector of the correct length first, and compare the computational time of the two expressions. Hint: Use \rcode{install.packages("microbenchmark"); library(microbenchmark); mb <- microbenchmark(...)}
\item BONUS 2: Can you also do this with sapply?
\item BONUS 3: Find a fast fibonacci creator function online and compare the timings of that as well
\item BONUS 4: With the package \texttt{Rcpp}, write the for loop in C++ and compare the speed with the other variants
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Fibonacci solution}
<<fibonacci_sol, echo=-1>>=
options(width=40)
len <- 20
fn <- rep(1, len)
for(i in 3:len)  fn[i] <- fn[i-1] + fn[i-2]
fn
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Fibonacci solution II}
<<fibonacci_sol_speed, size="tiny", echo=-1>>=
options(width=90)
#install.packages("microbenchmark")
library(microbenchmark)
#install.packages("numbers")
suppressMessages(library(numbers))
forbad <- function(n)
  {fibvals <- c(1,1)
  for (i in 3:len) fibvals[i] <- fibvals[i-1]+fibvals[i-2]
  fibvals
  }
forgood <- function(n)
  {fibvals <- rep(1,n)
  for (i in 3:len) fibvals[i] <- fibvals[i-1]+fibvals[i-2]
  fibvals
  }
numfib <- function(n) suppressWarnings(fibonacci(n, seq=T))
applfib <- function(n)
  {fibvals <- rep(1,n)
  sapply(3:n, function(i) {fibvals[i]<<-fibvals[i-1]+fibvals[i-2]})
  }
mb <- microbenchmark(numfib(2000), forbad(2000), forgood(2000), applfib(2000))
mb
@
<<resetopts3, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Repeat + While Loops}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Repeat loops}
\vspace{-0.5em}
Syntax:
\texttt{\alert{repeat} \{expressions\}\\
\alert{next} ~\# jump to next iteration\\
\alert{break} \# leave the loop}
\vspace{-0.5em}
\pause
<<repeatloop, echo=T, eval=T, size="small">>=
i <- 0 # Create object i with the value 0
repeat # keep repeating the following block of code
   {                    # Codeblock begins
   i <- i + 1           # overwrite object i with new number
   if (i < 3)  print(i) # conditional output to console
   if (i == 3)   break  # conditional leaving of loop
   }                    # Codeblock ends
@
\vspace{-0.5em}
\footnotesize What is now the value of i?
\pause
i is now 3, because in the last iteration, 1 was added to 2 and the result saved as i.
\pause
\vspace{-0.9em}
<<repeatloopsemicolons, eval=F, size="small">>=
i <- 0 ; repeat{i <- i+1 ; if(i<3) print(i) ; if(i==3) break} 
@
\vspace{-1.4em}
R doesn't care about line breaks in the code.\\
\vspace{-0.5em}
They are there for us humans. Because we matter more than R. \pause <Blasphemy!>
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{While loops}
Syntax: \texttt{\alert{while}(condition)\{expressions\}}\\[\baselineskip]
The following code is executed as long as  (while) i is lesser then 3:
<<whileloop, echo=T, eval=T>>=
i <- 0
while(i < 3) i <- i + 1
i
@
\pause
\rcode{repeat} loops are hardly ever used in R, and \rcode{while} loops fairly seldom as well.\\
\rcode{while} loops are helpful when the number of iterations is unknown prior to the task.\\
To get out of an endlessly repeating \rcode{while} loop, hit \key{ESC} (with the mouse cursor in the console) or the STOP button provided by Rstudio.

\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Practice while loops}
\begin{exercise}{while loop}
\begin{enumerate}
\item Why is the character string \rcode{folder <- "path/to/file///"} unsuitable for reading in a file?
\item With a while loop, make it suitable. Hints: \rcode{substring}, \rcode{nchar}
\item BONUS 1: enable your solution to deal with \textbackslash \textbackslash ~at the end as well. Hint: \rcode{\%in\%}.
\item BONUS 2: Use a regular expression (regexp) instead of \rcode{substring}/\rcode{nchar}. 
You'll need \rcode{grepl} with \texttt{"endswith\$"} and \rcode{sub}
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: while loop}
\rcode{folder <- "path/to/file///"} would link to empty-named subfolders at the end
<<whilefile>>=
folder <- "path/to/file///"
while(substring(folder, nchar(folder))=="/")
     folder <- substring(folder, 1, nchar(folder)-1)

while( substring(folder, nchar(folder)) %in% c("/", "\\") )
     folder <- substring(folder, 1, nchar(folder)-1)


# Or, more elegantly, with regular expressions:
while(grepl("/$", folder))  folder <- sub("/$","",folder)
while(grepl("[\\/]$", folder))
     folder <- sub("[\\/]$","",folder)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{The grand duel {\scriptsize (\url{http://www.janko.at/Raetsel/Mathematik/095.a.htm})}}
Sir Adam and Sir Bart confront each other in a duel with pistols.
By good old English custom, the two shoot at each other alternately, until one of them dies.
Being gentlemen, they decide that the worse shooter may fire the first shot.
Sir Adam has a hit ratio of 30\% and Sir Bert one of 40\%.\\
What are the chances of survival for each of the two?\\
\small
\begin{exercise}{while loop duel}
\begin{enumerate}
\item BONUS 1: Derive the probabilities mathematically.
\item Simulate the duel numerically. Hint: repeat the experiment \rcode{while} both are alive. In each step, let Sir Bert die with a 30\% change; if he survives, let Sir Adam die with a 40\% change.
\item BONUS 2: Write a function simulating the duel and returning the outcome.
\item Run the simulation 1000 (10k) times and assess Sir Bert's chance of survival.
\item BONUS 3: How many rounds are fought on average? (How is that quantity distributed?)
\end{enumerate}
\end{exercise}
\normalsize
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{The grand duel - resolved}
<<duel_analytical, echo=-c(1,4), size="small", fig.height=2.8>>=
par(mar=c(2,3,2,0), las=1)
plot(cumsum(sapply(0:20, function(i) 0.42^i*0.3)), type="l",
     ylim=c(0.26,0.58), main="cumulative death chance ~ round")
lines(cumsum(sapply(0:20, function(i) 0.42^i*0.7*0.4)), col="red")
text(15, c(0.55,0.44), c("Sir Bert, 0.5172","Sir Adam, 0.4828"), col=1:2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{The grand duel - resolved}
<<duel_fun>>=
duel_simulation <- function()
{
a <- b <- TRUE # TRUE = 1 = alive
n <- 0 # number of rounds
while(a&b)
  {
  if(  runif(1)<0.3) b <- FALSE # = 0 = dead
  if(b&runif(1)<0.4) a <- FALSE
  n <- n+1
  }
# return simulation result
c(a=a,b=b, n=n)
}
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{The grand duel - resolved}
\vspace{-1em}
<<duel_sim, echo=2:4, size="small">>=
options(width=60)
simu_res <- replicate(10000, duel_simulation())
# head(t(simu_res), 30)
apply(simu_res, 1, table) # / 10000 *100
options(width=50)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Arrays}
%------------------------------------------------------------%
%------------------------------------------------------------%

<<econcalc, eval=F, echo=F>>=
load("../rclick/Daten/11_econ.Rdata")
for(i in 1:5) write.table(econ[,,i], file=paste0("data/econ/e", 2011+i, ".txt"), quote=FALSE)
@

%------------------------------------------------------------%

\begin{frame}[fragile]{Read files in a loop, create an array}
\begin{exercise}{Create an array from files} %ex
\begin{enumerate}
\item Download the \datalinkRaw{econ.zip} file (e.g. with \rcode{download.file}), 
      then \rcode{unzip} it.
\item Get a vector of filenames in the econ folder with \rcode{dir}. 
      Remember to set the \texttt{full.names} argument.
\item Using \rcode{lapply}, read all the datasets into a list.
\item BONUS: With \rcode{basename} and \rcode{substr}, 
      use the years in the filename as names of the list elements.
\item Convert each element of the list to a \rcode{?matrix}.
\item With \rcode{?berryFunctions::l2array}, convert the list to an array.
\item Examine it with \rcode{str}
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Array creation - solution}
\vspace{-1em}
<<econ_unzip, eval=FALSE, size="small">>=
download.file(
 "https://github.com/brry/course/raw/master/data/econ.zip",
 destfile="econ.zip")
unzip("econ.zip")
@
\vspace{-1em}
<<econ_read, size="small">>=
files <- dir("data/econ", full.names=TRUE)
econ <- lapply(files, read.table)
names(econ) <- substr(basename(files), 2,5)
econ <- lapply(econ, as.matrix)
econ <- berryFunctions::l2array(econ)
str(econ)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Array subsetting and aggregation}
%Array subsetting and aggregation works like this:
\vspace{-1em}
<<arrayops, eval=FALSE>>=
some_array[x,y,z, ...]
apply(some_array, MARGIN=c(1,3), FUN=mean)
@
\vspace{-0.5em}
MARGIN denotes the dimensions to keep (i.e. aggregate over the other dimensions)
\begin{exercise}{subsets and aggregates from arrays} %ex
\begin{enumerate}
\item Display all the values for Germany (by name).
      Extract the values in the second economic category (by number).
      Display a time series of the agricultural branch in Switzerland.
\item Compute the median per category and country (aggregate over time). 
      Compute the maximum of each year.
\item BONUS: Compute the max per year, excluding the industrial sector.
      If there are many items in the second dimension, 
      how could you automatize the request for a particular entry (like "Industrie") 
      without hard-coding the position? 
      Hint: \rcode{str(some\_array)} shows a useful attribute you'll need.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Array subsetting - solution}
\vspace{-1em}
<<econ_subset, eval=FALSE>>=
econ["DE",,]
econ[,2,]
econ["CH","Landwirtschaft",]

apply(econ, 1:2, median)
apply(econ, 3, max)

apply(econ[,-2,], 3, max)
which(dimnames(econ)[[2]]=="Industrie")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{8. Functions \& packages}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Functions}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Functions I}
\label{functions1}
\href{http://r4ds.had.co.nz/functions.html}{http://r4ds.had.co.nz/functions.html}\\
\pause
\rcode{?"function"}\\
\pause  Syntax:\\
\rcode{Functionobjectname <- \alert{function}(argument1, argument2, ...) \\
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\{"DoSomething"\}}\\
\pause
<<funct2, echo=T, eval=T, tidy=FALSE>>=
myfunct <- function(grappig)
       {plot(grappig, type="l"); return(grappig*7)  }
@
\pause
After \rcode{return()}ing, the execution of the function is terminated, so it should only be positioned at the end. It can also be left away, the last instruction ("expression") will then be returned.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Functions II}
<<funct3>>=
myfunct(   c(5,11,3,7)  )
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Functions with more arguments}
<<funct4, size="small", echo=-1>>=
par(mar=c(4,5,1,1), mgp=c(2.8,0.8,0))
myfunct <- function(x, type="o", ...) plot(x, type=type, ...)
# type="o" is now the default, thus used unless specified
# The ellipsis (...) passes arguments to other functions
myfunct(  c(5,11,3,7) , col="red", las=1)
@
\vspace{-2em}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Functions: example I}
If you needed to find the zeros of quadratic functions very often, you could use
<<funct5, echo=T, eval=T, tidy=FALSE>>=
pq <- function(p,q) # y = x^2 + px + q
              {
              w <- sqrt( p^2 / 4 - q )
              c(-p/2-w, -p/2+w)
              } # End of function

pq(3, -12)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Functions: example II}
<<pqfunplot>>=
x <- seq(-10, 10, len=100)
plot(x,  x^2 +3*x -12, type="l", col="red")
abline(h=0, v=0)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Exercise: add circles with given radius}
<<circlebasics, echo=-1, fig.height=2.1, fig.width=2.5, out.width="0.4\\textwidth">>=
par(mar=c(2,2,1,1), las=1)
plot(1:10, asp=1) # aspect ratio y/x of graph range
grid(col="gray") # the next part sould go into a function:
x <- 8 ;  y <- 6 ;  r <-2
p <- seq(0, 2*pi, len=50)
cx <- x+r*cos(p) ;  cy <- y+r*sin(p)
polygon(cx, cy)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time to practice programming}
\begin{exercise}{Writing functions} %ex
Write a function that
\begin{enumerate}
  \item - draws a circle with a certain radius at user-specified locations of an existing plot (see last slide).
  \item - uses ellipsis to allow the user to customize the appearance
  \item - checks all the arguments and gives useful warnings if the wrong type of input is provided
  \item - has useful explanations for each argument (documentation)
  \item - has readable indentation, spacing and comments explaining the code
  \item Now let your neighbor use it without explaining how it is to be used (this should be inferred from the code and comments!)
  \item Use your neighbor's function with a vector to draw several circles at once. (unintended use?) What happens?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]
<<exfunsola, size="scriptsize">>=
# Small helper function drawing circles into existing graphics
# Berry Boessenkool, berry-b@gmx.de, 2012
circle <- function(
  x, # x-coordinate of points, numeric value of length 1
  y, # ditto for y
  r, # radius of the circle, in the graphic's units
  locnum=100, # number of points on circle (more means smoother but slower)
  ...) # Further arguments passed to polygon, like col, border, lwd
 {
 # input checking - only one circle can be drawn:
 if(length(x) >1 | length(y) >1 | length(r) >1 | length(locnum) >1)
   {
   warning("Only the first element of the vectors is used.")
   x <- x[1]; y <- y[1]; r <- r[1]; locnum <- locnum[1]
   }
 # input checking - is every value numeric?
 if(!is.numeric(x)) stop("x must be numeric, not ", class(x))
 if(!is.numeric(y)) stop("y must be numeric, not ", class(y))
 if(!is.numeric(r)) stop("r must be numeric, not ", class(r))
 
 # prepare circle line coordinates:
 cx <- x+r*cos( seq(0,2*pi,len=locnum) )
 cy <- y+r*sin( seq(0,2*pi,len=locnum) )
 polygon(cx, cy, ...) # actually draw it
 }
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount} II: functions}
<<exfunsolb, echo=-1>>=
par(mar=c(3,3,0,0), las=1)
plot(1:20, type="n", asp=1, cex=2)
circle(5,5, r=3)
circle(15,10, r=4, locnum=12, col="red", border=4, lwd=3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount} III: functions}
<<exfunsolc, echo=-1, size="scriptsize", out.width='0.65\\textwidth'>>=
par(mar=c(3,3,0,0), las=1, cex=2)  ; plot(1:20, type="n")
# can not be vectorized:
x <- sample(1:20, 15) ;  y <- sample(1:20, 15) ; r <- runif(20)*4
circle(x,y,r, col=rgb(1,0.5,0,alpha=0.4), border=NA)
for(i in 1:15) circle(x[i],y[i],r[i], col=rgb(1,0.5,0,alpha=0.4), border=NA)
@
\end{frame}

%------------------------------------------------------------%

%\addtocounter{exercisecount}{-4} % make up for 5 onslides
\begin{frame}[fragile]{Coding elegance I}
Suppose you have two related vectors, perhaps as a result from \rcode{approx}:\\
\texttt{a: 1 \hspace{0.5em} 2 \hspace{0.5em} 3 \hspace{0.5em} 4 \hspace{0.5em} 5 ... \\
b: 1  2  3  4  5  6  7  8  9 ...} \\
\onslide<2->
For any element \emph{i} in \texttt{a}, you want to select the corresponding surrounding values of \texttt{b}. \onslide<3-> Example: if i=3, you want to select the elements 4,5 and 6. \onslide<4-> However, at the border, you cannot select with negative indices.
\onslide<5->
\begin{exercise}{Elegant Coding: surrounding indices} %ex
\begin{enumerate}
  \item Write a function using conditionals that performs the task described above.
  \item BONUS: If it's not a "one-liner", try to find a different approach.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Coding elegance II}
Here is how to write this with conditional statements:
\onslide<2->
<<indexfun1>>=
index_1 <- function(i)
{
if(i == 1)                       1 : 2
else if(i == length(a))  ((i-1)*2) : (i*2-1)
else                     ((i-1)*2) : (i*2)
}
@
\onslide<3->
Here's the elegant way:
<<indexfun2>>=
index_2 <- function(i)
  pmax((i-1)*2, 1) : pmin(i*2, length(a)*2-1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Coding elegance III}
Both functions yield the same result:
<<indexfun3, size="small">>=
a <- 1:5
index_1(1); index_2(1)
index_1(3); index_2(3)
index_1(5); index_2(5)
@
\end{frame}

%------------------------------------------------------------%

\subsection{Writing R packages}

%------------------------------------------------------------%

\begin{frame}{Why you should write R packages}
\pause
\begin{itemize}[<+->]
\item Collect your own functions in one place
\item Combine functions and documentation in the right way
\item Share code with others
\item Make your research reproducible !
\end{itemize}
\onslide<+->
\vspace{1em}
Good introductions linked here:
\href{https://github.com/brry/misc\#package-development-with-rstudio-and-github}{github.com/brry/misc}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Package development: devtools + github}
We'll create a cat package together following the instructions in
\datalinkText{packdev.R}.\\[1em]

Version control with git:
\begin{itemize}%[<+->]
\item \hyperlink{installGit}{slides with Git installation instructions}
\item github.com, log in, on "+" in top-right select "New repository", initialize with readme!
\item On the green field "clone or download": copy link
\item Rstudio - file - new project - version control - git: paste url and create
\item \rcode{devtools::setup()} instead of \rcode{create}, choose option number to Overwrite 'yourPackage.Rproj'
\item Work. Commit. Push. Repeat.
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Package exercise}
\begin{exercise}{create LSC package (solutions on next 2 slides)}
\begin{enumerate}
\item Create a package for linear storage cascade functions (lsc)
\item BONUS: Use git from the beginning, commit often!
\item Check the package, correct description file and check again
\item Now add the functions in \datalinkRaw{lsc\_functions.zip} to the R folder
\item Done? Help your peers.
\item Document the nse function (we'll do this one together)
\item Create datasets within the package (following instructions in data.R)
\item Document the rmse function
\item Check and install the package
\end{enumerate}
\end{exercise}
\end{frame}

% ---------------------------

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: create LSC package}
<<solcreate, eval=FALSE>>=
library(devtools)
create("lsc") # or devtools::setup() if using git
document() # calls roxygen2::roxygenise()
check() # will also update documentation
install() # install the package locally
load_all(".") # CTRL + SHIFT + L    - faster than install!
@
\end{frame}

% ---------------------------

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Documenting functions}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.961, 0.961, 0.961}\color{fgcolor}\begin{kframe}
\texttt{\textcolor[rgb]{0,0.392,0}{
\doc \textcolor{blue}{@title} ~~~~~~Nash-Sutcliffe efficiency\\
\doc \textcolor{blue}{@description} Nash-Sutcliffe efficiency as a measure of goodness of fit.\\
\doc ~~~~~~~~~~~~ Removes incomplete observations with a warning.\\
\doc \textcolor{blue}{@return} ~~~~~Single numerical value\\
\doc \textcolor{blue}{@export}\\
\doc \textcolor{blue}{@seealso} ~~~~\textbackslash \textcolor{blue}{code}\{\textbackslash \textcolor{blue}{link}\{rmse\}\}\\
\doc \textcolor{blue}{@references} ~based on eval.NSeff  in RHydro Package\\
\doc ~~~~~~~~~~~~ \textbackslash \textcolor{blue}{url}\{https://r-forge.r-project.org/R/?group\_id=411\}\\
\doc \textcolor{blue}{@examples}\\
\doc x <- rnorm(20) ;  y <- 2*x + rnorm(20)\\
\doc x[2:4] <- NA\\
\doc nse(x,y)\\
\doc \\
\doc \textcolor{blue}{@param} obs Numerical vector with observed values\\
\doc \textcolor{blue}{@param} sim Simulated values (Num vector with same length as \textbackslash \textcolor{blue}{code}\{obs\})\\
\doc}}
\end{kframe}
\end{knitrout}
\vspace{-1.5em}
<<fundoc, eval=FALSE, size="scriptsize">>=
nse <- function(obs, sim)
{
if(!(is.vector(obs) & is.vector(sim))) stop("Input is not a vector.")
if(length(obs) != length(sim)) stop("Vectors are not of equal length.")
#[...]
1 - ( sum((obs - sim)^2) / sum((obs - mean(obs))^2) )
}
@
\end{frame}

% ---------------------------

\subsection{Debugging}

% ---------------------------

\begin{frame}[fragile]{Debugging}
\begin{itemize}[<+->]
\item Your code throws an error.
You didn't call the mentioned function.
Obviously, your code calls some function calling some function calling some function calling [you get the idea] which in the end creates an error.
To trace back this path, you can use \rcode{traceback()}.

\item Now that you know where the error originates from, you set \rcode{options(error=recover)}.
You run your code again, but this time R waits at the level creating an error.
You examine the environment within the function, play around with the objects and internal function code, until the bug has been fixed.
You have just debugged a function.

\item You want to step into the function you are developing at a specific point.
You add \rcode{browser()} at that point of the code.
You want to go line by line in one specific function. You set \rcode{debug(thatFunction)}.

\item You want to learn about lexical scoping (Where does R find variables?).\\
\small
\href{http://trestletech.com/2013/04/package-wide-variablescache-in-r-package/}{http://trestletech.com/2013/04/package-wide-variablescache-in-r-package/}
\href{http://adv-r.had.co.nz/Environments.html}{http://adv-r.had.co.nz/Environments.html}
\end{itemize}
\end{frame}

% ---------------------------

\begin{frame}[fragile]{Debugging: useful functions}
\begin{tabular}{ll}
\pause source("projectFuns.R") & execute complete file\\
\pause traceback() & find error source in sequence of function calls\\
\pause options(warn=2) & warnings to error. default 0\\
\pause browser() & go into function environment: \rcode{n}, \rcode{s}, \rcode{f}, \rcode{c}, \rcode{Q}\\
\pause \alert{options(error=recover)} & \alert{open interactive session where error occurred}\\
\pause debug(funct) & toggle linewise function execution\\
\pause undebug(funct) & after calling and fixing funct\\
\end{tabular}\\
\pause
\vspace{-0.5em}
<<stopfun, eval=F, size="footnotesize">>=
if(length(input)>1) stop("length must be 1, not ", length(input))
@
\vspace{-1em}
\pause
\rcode{stop}: Interrupts function execution and gives error\\
\rcode{warning}: continues but gives warning\\
\rcode{message}: to inform instead of worry the user\\[1em]
\pause
\href{http://www.biostat.jhsph.edu/~rpeng/docs/R-debug-tools.pdf}{R. Peng (2002): Interactive Debugging Tools in R}\\
\href{https://www.stats.umanitoba.ca/files/statsweb/2011/03/debugging.pdf}{D. Murdoch (2010): Debugging in R}\\
\href{http://adv-r.had.co.nz/Exceptions-Debugging.html}{H. Wickham (2015): Advanced R: debugging}\\
Example: \href{https://www.r-bloggers.com/tracking-down-errors-in-r/}{Pete Werner Blog Post (2013)}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Practice debugging, \datalinkText{lsc\_functions.R}}
\begin{exercise}{Debugging}
\begin{enumerate}
\item Load your package and the datasets. Correct the functions until\\
\rcode{lsc(calib\$P, calib\$Q, area=1.6)} returns the result below.
\item BONUS: commit each change to git.
\end{enumerate}
\end{exercise}

<<PQ_lsc, echo=F, warning=F, fig.height=2.8>>=
qpfile <- system.file("extdata/Q_P.txt", package="berryFunctions")
qp <- read.table(qpfile, sep="\t", dec=",", header=TRUE)
calib <- qp[1:90, ]
valid <- qp[-(1:90), ]
lsc_cal <- berryFunctions::lsc(calib$P, calib$Q, area=1.6)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Debugging}
\begin{itemize}
\item \rcode{stupid error you can easily remove} - traceback - find location of error - lsc\#73 - just comment it out
\item \rcode{harder to find but still stupid} - traceback - nse\#11 - ditto
\item \rcode{Error in plot: need finite 'ylim' value} - debug/browser/options(error=recover) - lsc\#105 - NAs in Q - range(Q, na.rm=TRUE) - also in other applicable locations
\item \rcode{There were 50 or more warnings} - come from rmse being called in optimization - add argument quietNA (or similar) to lsc that is passed to rmse in lsc\#79
\end{itemize}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Programming exercise}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Chapter practice: sample size dependency}
\begin{exercise}{Programming part 1 - functions}
\begin{enumerate}
\item Write a function (\#1) that computes the backtransformed arithmetric average of logtransformed values. It should \rcode{stop} with a useful error message if there are \rcode{any} negative values in the input vector.
\item Write a second function (\#2) taking a vector of values that returns the mean, sd, coefficient of variation and the output of function \#1.
\item It should return these values with names as in \rcode{c(a=5,b=-3)}.
\item If the average is zero, it should inform the user that the CV cannot be computed. Remember to check only rounded values for equality.
\item Test both functions with \rcode{c(88,31,73,21,08,52,66,48)}, with \rcode{c(4,7,5,6,4,5,3,NA,6,4,5,6,8,5)} and with \rcode{c(0,0,0)}.
\item Write a function (\#3) taking \texttt{\textbf{n}}, \texttt{\textbf{mean}} and \texttt{\textbf{sd}} that
\begin{itemize}
\item breaks if \texttt{\textbf{n}} is not a single value
\item draws \texttt{\textbf{n}} random numbers from the normal distribution with \texttt{\textbf{mean}} and \texttt{\textbf{sd}}
\item returns the output of function \#2 of that sample.
\end{itemize}
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 1 - functions 1}
backtransformed arithmetric average of logtransformed values
<<progexfun1, echo=-(1:2)>>=
set.seed(42)
options(width=65)
logmean <- function(x)
  {
  if(any(x<0)) stop("x has ", sum(x<0), " negative values.")
  lx <- log10(x)
  10^mean(lx)
  }

logmean(c(88,31,73,21,08,52,66,48))
#logmean(c(4,7,5,6,4,5,3,NA,6,4,5,6,8,5))
logmean(c(0,0,0))
@
<<resetopts4, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 1 - functions 2}
Statistical properties of a vector
<<progexfun2, echo=-1>>=
options(width=60)
meanvar <- function(vals)
  {
  m <- mean(vals) # average
  s <- sd(vals) # root of variation
  if(round(m)==0) stop("mean is 0, CV cannot be computed")
  c(mean=m, sd=s, CV=s/m, logmean=logmean(vals))
  }

meanvar(c(88,31,73,21,08,52,66,48))
#meanvar(c(4,7,5,6,4,5,3,NA,6,4,5,6,8,5))
#meanvar(c(0,0,0))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 1 - functions 3}
Dependency on sample size
<<progexfun3, echo=-1>>=
options(width=65)
dep_n <- function(n, mean, sd)
  {
  if(length(n)!=1) stop("n must be a single value, not ",
                        length(n))
  # draw n numbers randomly from normal distribution:
  v <- rnorm(n, mean=mean, sd)
  meanvar(v)
  }

dep_n(20, 70,5)
#
@
<<resetopts5, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Chapter practice: sample size dependency}
\begin{exercise}{Programming part 2 - debugging}
\begin{enumerate}
\item Test function \#3 with \rcode{n=20:30, mean=70,sd=5}
\item What happens if you use it with \rcode{n=NA, mean=70,sd=5}?
\item After you call it with \rcode{n=20, mean=-70,sd=5}, run \rcode{traceback()} Explain the result.
\item What is the result of \rcode{ls.str()}?
\item Set you upper level function \#3 to \rcode{debug}ging mode. Now call it again. What happens? What is now the result of \rcode{ls.str()}?
\end{enumerate}
\end{exercise}
\begin{itemize}
\item With enter, you can now execute the function line by line and observe how objects (variables) in functions change over execution time, thus making it easier to find the source of an error.
\item Don't forget to \rcode{undebug} your function again.
\item If you only want to step into the function at a certain point, write \rcode{browser()} at that position, redefine the function and call it again.
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 2 - debugging}
<<progexdebug1>>=
dep_n(20, -70,5)
@
<<progexdebug1b, eval=F>>=
traceback()
@
\texttt{4: stop("x has ", sum(x < 0), " negative values.") at \#3\\
3: logmean(vals) at \#6\\
2: meanvar(v) at \#5\\
1: dep\_n(20, -70, 5)}\\[1em]
In debugging mode, you step into the function when it is called (visible by \rcode{Browse[2]>} in the console). \rcode{ls.str()} now returns the structures of the objects defined within the function environment.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Chapter practice: sample size dependency}
\begin{exercise}{Programming part 3 - loops for computation}
For this task, use \rcode{n <- rep(1:50, each=100)}
\begin{enumerate}
\item Create an empty \rcode{data.frame} with the column names according to the output of function \#3.
\item With a for loop, fill each row with the result of the n-corresponding call to function \#3.
\item Obtain the computing time by either wrapping it in \rcode{system.time} or calling \rcode{Sys.time()} before and afterwards and computing the \rcode{difftime}.
\item Time the usage of \rcode{sapply} for the same task. How many times is it faster? What does that imply for a 5-hour for loop computation?
\item BONUS: Get uncertainties on the computing time estimation with \rcode{microbenchmark} (You might want to reduce the length of n for that).
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 3 - loops computation}
<<progexloop_c1, echo=-1>>=
options(width=65)
n <- rep(1:50, each=100)
results_for <- data.frame(mean=NA, sd=NA, CV=NA, logmean=NA)
system.time( for(i in 1:length(n))
  {results_for[i, ] <- dep_n(n[i], 70,5)})
tail(results_for, 5)
@
<<resetopts6, echo=F>>=
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 3 - loops computation}
<<progexloop_c2>>=
system.time(res_lapply <- sapply(n, dep_n, mean=70,sd=5)  )
@
In this case with (only) 5000 iterations, lapply is ca 7 times faster than the badly initiated for loop. 5 hrs of computation would reduce to 40 minutes.\\
Notice you get similar to lapply speed  results for properly initiated data.frames with the correct dimension.\\
For more speed hints, read \href{http://www.win-vector.com/blog/2015/07/efficient-accumulation-in-r/}{win-vector.com efficient accumulation in R}.\\
Remember: your code is much cleaner with lapply:\\
<<for_vs_apply, eval=FALSE>>=
results <- matrix(NA, ncol=4, nrow=length(n2))
for(i in 1:length(n2)) results[i, ] <- dep_n(n2[i], 70,5)

results <- sapply(n2, dep_n, mean=70,sd=5)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 3 - loops computation}
<<progexloop_c3, eval=F, size="small">>=
n2 <- rep(1:50, each=10)

dep_n_for <- function()
 {results <- data.frame(mean=NA, sd=NA, CV=NA, logmean=NA)
  for(i in 1:length(n2)) results[i, ] <- dep_n(n2[i], 70,5)}

dep_n_for_good <- function()
 {results <- matrix(NA, ncol=4, nrow=length(n2))
  for(i in 1:length(n2)) results[i, ] <- dep_n(n2[i], 70,5)}

dep_n_sapply <- function()
{results <- sapply(n2, dep_n, mean=70,sd=5)}

mb <- microbenchmark(dep_n_for(), dep_n_for_good(),
                     dep_n_sapply())
save(mb, file="data/mb.Rdata")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 3 - loops computation}
<<progexloop_c4, echo=-1>>=
par(mar=c(4.5,4.5,1,1))
load("data/mb.Rdata"); library(microbenchmark)
boxplot(mb, yaxt="n"); berryFunctions::logAxis(2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Chapter practice: sample size dependency}
\begin{exercise}{Programming part 4 - loops for plotting}
\begin{enumerate}
\item Plot the mean estimate over sample size, using fully colored but semitransparent dots (see \rcode{rgb} or \rcode{berryFunctions::addAlpha}).
\item Add a nicely visible horizontal line at the population mean. {\footnotesize(we drew random samples from some defined distribution, which is the general population whose parameters are usually unknown in real life)}.
\item BONUS: add lines limiting the 90\% confidence region.
\item Set up a multipanel plot to automatically hold a figure for each of the rows of the previous results (mean, sd, CV, logmean). To automatically dimension the panels, you could use \rcode{berryFunctions::panelDim(n)}
\item With a for loop, fill each of the panels and add nice annotations.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 4 - loops plotting}
<<progexloop_p1, echo=-1, fig.width=3, fig.height=2.5, out.width="0.55\\textwidth">>=
par(mar=c(4,4,.5,.5), mgp=c(2.5,0.7,0), las=1)
transp <- rgb(0,0,0, alpha=0.1)
plot(n, res_lapply["mean", ], pch=16, col=transp, cex=0.6)
abline(h=70, col="blue", lwd=2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 4 - loops plotting}
\vspace{-0.17em}
<<progexloop_p1b, echo=-(1:4), size="footnotesize", fig.width=3, fig.height=2.5, out.width="0.55\\textwidth">>=
par(mar=c(4,4,.5,.5), mgp=c(2.5,0.7,0), las=1)
transp <- rgb(0,0,0, alpha=0.1)
plot(n, res_lapply["mean", ], pch=16, col=transp, cex=0.6)
abline(h=70, col="blue", lwd=2)
conf <- tapply(res_lapply["mean", ], n, quantile, probs=c(0.05, 0.95))
conf <- sapply(conf, I)
conf_x <- as.numeric(colnames(conf))
for(i in 1:2) lines(conf_x, conf[i, ], col="red", lwd=2)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 4 - loops plotting}
<<progexloop_p2, fig.show="hide">>=
library(berryFunctions) # for panelDim

par(mfrow=panelDim(nrow(res_lapply)), mar=c(2,4,1,1),
    mgp=c(2.5,0.7,0), las=1 )

truevals <- c(mean=70, sd=5, CV=5/70, logmean=70)
for(nm in rownames(res_lapply))
  {
  plot(n, res_lapply[nm, ], ylab=nm, pch=16, col=transp)
  abline(h=truevals[nm], col="blue", lwd=2)
  if(nm=="sd") points(60,2, col="red")
  }
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Programming practice solutions part 4 - loops plotting}
\includegraphics[width=.99\textwidth]{fig/progexloop_p2-1.pdf}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{9. Distributions}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Exploratory Data Analysis (EDA)}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{A quick example I}
<<grades>>=
grades <- c(3.0, 2.3, 5, 1.3, 4, 1.7)
grades         # Show the object
mode(grades)   # numeric
sum(grades)    # sum of all values
diff(grades)   # difference from one value to the next
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]
<<grades2>>=
mean(grades)   # Average
median(grades) # median*
var(grades)    # variance
sd(grades)     # Standard deviation
@
* If you sort all the numbers ascendingly, the median is in the middle. Thus, it is not as sensitive to outliers as the mean. We'll get back to this later on.
\end{frame}

%------------------------------------------------------------%

\begin{frame}{The dataset we'll be looking at}
  \begin{figure}[h]
    \begin{center}
  	\includegraphics[width=.8\linewidth]{./externalfig/IrisComposition.png}
    \end{center}
  \end{figure}
	sources: \href{http://mirlab.org/jang/books/dcpr/dataSetIris.asp}{mirlab.org},
  \href{http://www.desirableplants.com/images/i/iris_versicolor_mysterious_monique.jpg}{desirableplants.com},
  \href{http://3.bp.blogspot.com/-0dZyClxOh8E/TrFc00J8AcI/AAAAAAAABrA/AJJl4HbMboU/s400/Iris\%2Bsetosa\%2B8.JPG}{3.bp.blogspot.com}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{iris data set}
\small
<<iris1, echo=2, eval=TRUE, tidy=FALSE>>=
options(width=100)
head(iris)
options(width=50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}
\begin{exercise}{EDA - Exploratory Data Analysis} %ex7
\begin{enumerate}
  \item Look at \rcode{iris} with \rcode{summary}.
  \item Assign \rcode{iris\$Sepal.Length} to an object with a short name.
  \item Calculate \rcode{min} and \rcode{max}, the \rcode{median} and the median absolute deviation (\rcode{mad}), the quartiles and octiles (via \rcode{quantile}), the fourthspread (\rcode{IQR}) and \rcode{diff(range)} of the iris values.
  \item With \rcode{par(mfrow=c(2,1))}, set the graphic device to contain two graphics.
  \item Draw a horizontal \rcode{boxplot} in the upper window and compare it with the statistics calculated above. Interpret them.
  \item What happens when the argument \texttt{notch} is set to true?
  \item Draw a \rcode{hist}ogram with the bars filled with orange color, and experiment with the number of breaks.
  \item BONUS: What are the (dis-)advantages of boxplots and histograms?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1}
% <<ex7sola, eval=FALSE>>=
% # ToDo
% @
% \end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Mean vs. Median etc.}
\href{https://mathwithbaddrawings.com/2016/07/13/why-not-to-trust-statistics/}{mathwithbaddrawings.com/2016/07/13/why-not-to-trust-statistics}
<<histbox1, echo=F, fig.height=2>>=
par(mfrow=c(1,2), mar=c(2,2,2,0.4), oma=c(0,0,3,0), cex=0.7)
boxplot(faithful$eruptions, horizontal=TRUE, ylim=c(1,6),    col="orange", main="Eruption duration [min]")
boxplot(faithful$waiting  , horizontal=TRUE, ylim=c(40,100), col="purple", main="Waiting Time between eruptions [min]")
title(main="'faithful' - Old Faithful Geyser (Yellowstone)", outer=TRUE)
@
\pause
<<histbox2, echo=F, fig.height=1.6>>=
par(mfrow=c(1,2), mar=c(2,2,0.4,0.4), oma=c(0,0,0,0), cex=0.7, las=1)
hist(faithful$eruptions, xlim=c(1,6),    col="orange", main="", breaks=20)
hist(faithful$waiting  , xlim=c(40,100), col="purple", main="", breaks=30)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Similar boxplots...}
<<badbox1, echo=F, fig.height=3.9>>=
set.seed(4)
n <- 20000
x <-      berryFunctions::rescale(rbeta(n*0.97, 2, 25), from=13, to=60)
x <- c(x, berryFunctions::rescale(rbeta(n*0.03, 25, 3), from= 1, to=15))
m <- mean(x)
s <- 6
y <- c(rnorm(n*0.995, mean=m, sd=s), runif(n*0.005,45,60))
z <- c(rnorm(n*0.98, mean=m, sd=s), rnorm(n*0.02, mean=50, sd=4))
r <- berryFunctions::lim0(60)
b <- -30:100
par(mfcol=c(3,1), mar=c(2,0,0.4,0.4), cex=0.7)
boxplot(x, ylim=r, horizontal=TRUE, col="salmon")
boxplot(y, ylim=r, horizontal=TRUE, col="brown")
boxplot(z, ylim=r, horizontal=TRUE, col="firebrick1")
write.table(data.frame(K=round(x,2),L=round(y,2),M=round(z,2)), 
            file="data/box.txt", quote=FALSE, row.names=FALSE,
            sep="\t")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{... different distributions!}
<<badbox2, echo=F, fig.height=3.9>>=
par(mfrow=c(3,1), mar=c(2,0,0.4,0.4), cex=0.7)
hist(x, xlim=r, breaks=b, freq=FALSE, main="", yaxt="n", col="salmon")
lines(0:65, dnorm(0:65, mean(x), sd(x)))
hist(y, xlim=r, breaks=b, freq=FALSE, main="", yaxt="n", col="brown")
lines(0:65, dnorm(0:65, mean(y), sd(y)))
hist(z, xlim=r, breaks=b, freq=FALSE, main="", yaxt="n", col="firebrick1")
lines(0:65, dnorm(0:65, mean(z), sd(z)))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Random numbers}
R has a very good random number generator. If you want to set a starting point for it, you can use \rcode{set.seed(n)}, with n being some number you like. After R has set the seed, it will always generate the same "random" numbers. This creates reproducible numbers.
%\onslide<2> % Messes up the exercise count
\begin{exercise}{Random numbers} %ex8
\begin{enumerate}
  \item With \rcode{sample}, put the numbers 5 to 15 in random order. Out of the possible numbers 1:3, draw 25 realizations.
  \item Via \rcode{?Distributions}, find out how to generate 200 random numbers from the exponential distribution and look at those with a boxplot and a histogram (BONUS: look at \rcode{ecdf} and \rcode{density}).
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: random numbers}
<<ex_random_sola, eval=F, size="scriptsize">>=
sample(5:15)  ;  sample(1:3, 25, replace=TRUE)  ;  r <- rexp(200)
par(mfrow=c(2,1), mar=c(2,2,0,0))
hist(r, breaks=20, col="green4")
boxplot(r, horizontal=T, notch=T, col="green4")
lines(density(r)$x, density(r)$y +par("usr")[3], lwd=3)
lines(0:50/10, dexp(0:50/10) +par("usr")[3], col="red")
@
<<ex_random_solb, echo=F, out.width="0.8\\textwidth">>=
set.seed(5) ; r <- rexp(200)
par(mfrow=c(2,1), mar=c(2,2,0,0))
hist(r, breaks=20, col="green4")
boxplot(r, horizontal=T, notch=T, col="green4")
lines(density(r)$x, density(r)$y +par("usr")[3], lwd=3)
lines(0:50/10, dexp(0:50/10) +par("usr")[3], col="red")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Normal distribution}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{normal distribution: data}
\vspace{-1em}
<<normdist_data, size="scriptsize", message=FALSE, echo=-1, fig.height=2.9>>=
par(mar=c(2,3.5,2,0.5), mgp=c(2.3,0.7,0), las=1)
url <- rdwd::selectDWD("Potsdam", res="annual", var="kl", per="h")
clim <- rdwd::dataDWD(url)
clim$Year <- as.numeric(substr(clim$MESS_DATUM_BEGINN, 1, 4))
plot(clim$Year, clim$JA_RR, type="l", col="blue", lwd=3,
     xlab="Year", ylab="Precipitation sum  [mm]", 
     main="Annual rainfal in Potsdam appears trendless")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{normal distribution: empirical histogram}
\vspace{-0.8em}
<<normdist_hist, echo=-1, size="scriptsize">>=
par(mar=c(2,3.3,2,0.5), mgp=c(2.3,0.7,0), las=1)
hist(clim$JA_RR, breaks=20, col="azure3", main="Histogram Rainfall",
     ylab="Number of values in rainfall bin", 
     xlab="Annual rainfall sum Potsdam 1894:2017")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{normal distribution: density histogram}
<<normdist_function, echo=FALSE>>=
plotnorm <- function(step=50){
par(mar=c(2,3.9,2,0.5), mgp=c(3,0.7,0), las=1)
hist(clim$JA_RR, breaks=20, col="azure3", 
     main="Probability density, total histogram area=1",
     xlab="Annual rainfall sum Potsdam 1894:2017", freq=FALSE)
if(step==3) return(invisible(NULL))
abline(v=mean(clim$JA_RR), col="red", lwd=5)
textField(650, 0.005, paste0("mean = ", round(mean(clim$JA_RR),0)), col="red")
if(step==4) return(invisible(NULL))
musd <- function(x,f=1) mean(x,na.rm=TRUE)+c(-f,f)*sd(x, na.rm=TRUE)
segments(musd(clim$JA_RR,1), rep(-1,2), y1=rep(0.0025,2), col="red", lwd=5)
textField(690, 0.004, paste0("sd = ", round(sd(clim$JA_RR),0)), col="red")
if(step==5) return(invisible(NULL))
textField(589, 0.002, "70% of values between\nmu +- 1 sd")
if(step==6) return(invisible(NULL))
segments(musd(clim$JA_RR,2), rep(-1,2), y1=rep(0.0006,2), col="red", lwd=5)
textField(589, 0.0007, "95% of values between\nmu +- 2 sd")
if(step==7) return(invisible(NULL))
lines(200:900, dnorm(200:900, mean(clim$JA_RR), sd(clim$JA_RR)), col="red", lwd=3)
}
@
\only<1| handout:0>{
<<normdist3, echo=FALSE>>=
plotnorm(3)
@
}
\only<2| handout:0>{
<<normdist4, echo=FALSE>>=
plotnorm(4)
@
}
\only<3| handout:0>{
<<normdist5, echo=FALSE>>=
plotnorm(5)
@
}
\only<4| handout:0>{
<<normdist6, echo=FALSE>>=
plotnorm(6)
@
}
\only<5| handout:0>{
<<normdist7, echo=FALSE>>=
plotnorm(7)
@
}
\only<6>{
<<normdist8, echo=FALSE>>=
plotnorm(8)
@
}
\end{frame}
%------------------------------------------------------------%

\begin{frame}[fragile]{normal distribution: code}
\vspace{-0.6em}
<<normdist_code, eval=FALSE, size="scriptsize">>=
par(mgp=c(3,0.7,0), las=1)
hist(clim$JA_RR, breaks=20, col="azure3", 
     main="Probability density, total histogram area=1",
     xlab="Annual rainfall sum Potsdam 1894:2017", freq=FALSE)
abline(v=mean(clim$JA_RR), col="red", lwd=5)
textField(650, 0.005, paste0("mean = ", round(mean(clim$JA_RR),0)), col="red")
musd <- function(x,f=1) mean(x,na.rm=TRUE)+c(-f,f)*sd(x, na.rm=TRUE)
segments(musd(clim$JA_RR,1), rep(-1,2), y1=rep(0.0025,2), col="red", lwd=5)
textField(690, 0.004, paste0("sd = ", round(sd(clim$JA_RR),0)), col="red")
textField(589, 0.002, "70% of values between\nmu +- 1 sd")
segments(musd(clim$JA_RR,2), rep(-1,2), y1=rep(0.0006,2), col="red", lwd=5)
textField(589, 0.0007, "95% of values between\nmu +- 2 sd")
lines(200:900, dnorm(200:900, mean(clim$JA_RR), sd(clim$JA_RR)), col="red",lwd=3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Distributions: normal distribution I}
<<normaldistr, echo=F, eval=TRUE>>=
generalnormplot <- function(m=600,s=10, val=NULL)
{
value <- seq(m-3.5*s, m+3.5*s, len=200)
par(mar=c(3,3,2.5,0.5), mgp=c(1.9,0.6,0), mfrow=c(1,2), cex.main=1)
plot(value, dnorm(value,m,s), type="l", las=1, lwd=2, xaxs="i",
     main=paste0("probability density function\ndnorm (value, mean=",m,", sd=",s,")   "))
if(!is.null(val)){
w <- seq(value[1], val, len=100)
polygon(c(w, val, value[1]), dnorm(c(w,0,0),m,s), col="blue")
points(val, dnorm(val,m,s), pch=3, col="red", cex=2, lwd=3)
}
box("figure", col="black")
#
plot(value, pnorm(value,m,s), type="l", las=1, lwd=2, xaxs="i",
     main=paste0("cumulated probability\npnorm(value, mean=",m,", sd=",s,")   "))
if(!is.null(val)){
abline(h=pnorm(val,m,s), v=val, col="blue")
points(val, pnorm(val,m,s), pch=3, col="red", cex=2, lwd=3)
}
box("figure", col="black")
}
generalnormplot()
@
\vspace{2.72em}
\end{frame}
% normal:
% hist(chickwts$weight, breaks=20, col="red")
% hist(eurodist, breaks=20, col="red")
% hist(iris$Sepal.Length, breaks=20, col="red")
%
% two groups
% hist(faithful$eruptions, breaks=20, col="red")

%------------------------------------------------------------%

\begin{frame}[fragile]{Distributions: normal distribution II}
\only<1| handout:0>{
<<normaldistr1, echo=FALSE>>=
generalnormplot(val=590)
@
}
\only<2| handout:0>{
<<normaldistr2, echo=FALSE>>=
generalnormplot(val=598)
@
}
\only<3-4>{
<<normaldistr3, echo=FALSE>>=
generalnormplot(val=615)
@
}
\onslide<4> \rcode{pnorm(q=615, mean=600, sd=10)} = 93\% of the values of a normal distribution (ND) with $\mu=600$ and $\sigma=10$ are smaller than 615.
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Get familiar with the Gaussian distribution}
\begin{exercise}{normal distribution} %ex9
In 1981, Fries and Crapo estimated future life expectancy to be 85 years with a standard deviation of 4.5 years.\\
\tiny Fries, J., Crapo, L.: Vitality and Aging: Implications of the Rectangular Curve. Freeman \& Co Publishers, San Francisco (1981)
\normalsize
\begin{enumerate}
\item Plot the distribution density curve
\item Plot it again using \rcode{normPlot} in the package \texttt{berryFunctions}.
\item What proportion of people would die before age 75?\\
      Is that a realistic likelihood?
\item How many Germans (pop \textasciitilde 80 mio) would exceed 90 years?
\item In which symmetric age range would 95\% of the people die?\\
      Give the rough estimate and the exact number.
\item How likely is it to die at age 85.3?
\item What are the biggest problems with this task?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Normal distribution I}
Examples taken from: Wolfgang Tschirk (2014): Statistik: Klassisch oder Bayes - Zwei Wege im Vergleich
<<exnormsol1, eval=FALSE>>=
plot(70:100, dnorm(70:100, 85, 4.5), type="l")
berryFunctions::normPlot(85, 4.5)
pnorm(75, 85, 4.5)*100 #  1.3%
(1-pnorm(90, 85, 4.5))*80e6   # 10.7 mio
85-4.5*2; 85+4.5*2 # 76, 94
qnorm(c(0.025, 0.975), 85, 4.5) # 76.2 - 93.8
@
The probability to die at age 85.3 is 0 percent, as there are infinite possibilities in a continuous distribution. (You could also die at 85.331761 years). That's why we look at probability "density" in intervals.\\
But: we don't know if life expectancy is normally distributed. We also don't know whether it is parametrized correctly.

\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Normal distribution II}
<<exnormsol2, echo=FALSE, eval=TRUE>>=
berryFunctions::normPlot(85, 4.5)
pnorm(75, 85, 4.5)*100 #  1.3%
(1-pnorm(90, 85, 4.5))*80e6   # 10.7 mio
qnorm(c(0.025, 0.975), 85, 4.5) # 76.2 - 93.8
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Test for normality of a distribution}
<<normaltest_ex, eval=FALSE>>=
data <- rnorm(1000, mean=97, sd=8.9)
shapiro.test(data)
ks.test(data, "pnorm", mean(data), sd(data))
# if p > 0.05: accept Nullhypothesis
# (that data are normally distributed.)
@
More on \hyperlink{nortest}{slide \ref{nortest}} et sequentes.
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Other distribution functions}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Get familiar with the discrete Binomial distribution}
\begin{exercise}{binomial distribution} %ex10
149'291 of 279'371 students in Austria are female.
\tiny Statistik Austria: Studierende in OEsterreich im Wintersemester 2009/10. Statistik Austria, Wien (2010).
\normalsize This is a population for which we know the actual proportion, which happens rarely in inferential statistics. 100 students are randomly chosen.
\begin{enumerate}
\item Guess how likely it is that the majority (at least half) of those are female.
\item Plot the probability for each reasonable possible outcome using \rcode{dbinom}. (This is the actual probability, not probability density, for each discrete number of females in a group of 100 randomly chosen students). Now guess again.
\item Actually calculate the probability.
\item At which proportion of females would you accuse the experimenter of selection bias (or cheating)?
\end{enumerate}
\end{exercise}
\end{frame}
% inference: statistics from a sample to estimates properties of an unknown population.\\
% descriptive statistics: Looking at a complete population (so called \texttt{n=all} study).

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Binomial distribution}
\vspace{-1.5em}
<<exbinomsol, size="tiny", echo=-1, out.width='.6\\textwidth'>>=
par(mar=c(1.8,4,0.5,0.5), mgp=c(1.8,0.7,0), las=1)
prop_f <- 149291/279371 # Proportion of females among students in Austria
plot(30:70, dbinom(x=30:70, size=100, prob=prop_f)*100, 
     ylab="Probability for n females\nin a sample of 100 stundents  [%]")
HDI <- qbinom(p=c(0.025, 0.975), size=100, prob=prop_f)
abline(v=c(49.5, prop_f*100, HDI), col=c("purple","grey","red","red"))
1-pbinom(q=49.5, size=100, prob=prop_f)   ;  HDI
@
In 78.5\% of samples, a majority should be female. 
Improper sampling is assumed if the probability of the result happening by chance is under e.g. 5\%, in this case $\leq 44$ or $\geq 63$  females (two-sided confidence interval).
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Other distributions: density}
<<otherdistr, echo=F, eval=TRUE>>=
par(mar=c(2,3,1,1))
x <- seq(-5, 5, .01)
x2 <- (-5):5
plot(-5:5, -5:5, type="n", las=1, ylab="cumulated probability", ylim=c(0,0.57), xaxs="i", yaxs="i")
# abline(h=0:10/5, v=-5:5, col="gray", lty=2) ; box()
lines(x, dnorm(x, mean=0, sd=1), col="black", lwd=2)
lines(x, dexp(x, rate=1), col="red", lwd=2)
lines(x, dgamma(x, shape=0.1, scale=1), col="green4", lwd=2)
lines(x2, dpois(x2, lambda=1), col="blue", lwd=2, pch=16, type="b", lty=2)
lines(x2, dbinom(x2, size=10, prob=1/5), col="cyan", lwd=2, pch=16, type="b", lty=2)
lines(x, dcauchy(x, location=0, scale=1), col="purple", lwd=2)
lines(x, dunif(x, min=-4, max=4), col="orange", lwd=2)
legend("topleft", c("dnorm, mean=0, sd=1", "dgamma, shape=0.1, scale=1", "dcauchy, location=0, scale=1", "dunif, min=-4, max=4", "dexp, rate=1", "dpois, lambda=1", "dbinom, size=10, prob=1/5"),
       col=c(1,3,6,"orange",2,4,5), lty=1, cex=0.8)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Other distributions: cumulated}
<<otherdistr2, echo=F, eval=TRUE>>=
par(mar=c(2,3,1,1))
x <- seq(-5, 5, .01)
plot(-5:5, -5:5, type="n", las=1, ylab="cumulated probability", ylim=c(0,1), xaxs="i", yaxs="i")
# abline(h=0:10/5, v=-5:5, col="gray", lty=2) ; box()
lines(x, pnorm(x, mean=0, sd=1), col="black", lwd=2)
lines(x, pexp(x, rate=1), col="red", lwd=2)
lines(x, pgamma(x, shape=0.1, scale=1), col="green4", lwd=2)
lines(x, ppois(x, lambda=1), col="blue", lwd=2)
lines(x, pbinom(x, size=10, prob=1/5), col="cyan", lwd=2)
lines(x, pcauchy(x, location=0, scale=1), col="purple", lwd=2)
lines(x, punif(x, min=-4, max=4), col="orange", lwd=2)
legend("topleft", c("pnorm, mean=0, sd=1", "pgamma, shape=0.1, scale=1", "pcauchy, location=0, scale=1", "punif, min=-4, max=4", "pexp, rate=1", "ppois, lambda=1", "pbinom, size=10, prob=1/5"),
       col=c(1,3,6,"orange",2,4,5), lty=1, cex=0.8)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Overview of distributions in R}
\begin{center}
\begin{tabular}{| c | m{2cm} | m{7cm} |}   \hline
  \textbf{prefix} & \textbf{meaning} &\textbf{usage}  \\ \hline  \hline
  d & \textbf{d}ensity               & calculate probability (density) for value x\\ \hline
  p & cumulated \newline \textbf{p}robability & area under density curve up until value x\\ \hline
  q & \textbf{q}uantile              & reciprocal to p: calculate value x \newline for a given cumulated probability\\ \hline
  r & \textbf{r}andom                & draw random numbers from distribution\\ \hline
\end{tabular}
\\[\baselineskip]
\onslide<2>
\begin{tabular}{| l | l | l |}   \hline
  \textbf{distribution} & \textbf{parameters} & \textbf{type}  \\ \hline  \hline
   binom & size, prob     &  \multirow{2}{*}{discrete}\\ \cline{1-2}
   pois  & lambda         &  \\ \hline
   norm  & mean, sd       &  \multirow{3}{*}{continuous}\\ \cline{1-2}
   exp   & rate           &   \\ \cline{1-2}
   beta  & shape1, shape2 &\\ \hline
\end{tabular}
\end{center}
\end{frame}

%------------------------------------------------------------%

\begin{frame}
\begin{exercise}{classical statistical analysis} %ex10
\begin{enumerate}
  \item Calculate \rcode{mean}, \rcode{var}, \rcode{sd} and standard error of the mean (SEM =$\frac{\sigma}{\sqrt{n}}$) of the \rcode{iris} sepal length data and interpret these values.
  \item Visualize the theoretical distribution of the dataset. Use a sequence of values and calculate \rcode{pnorm} and \rcode{dnorm} on it with mean and sd according to the previous task.
  \item Compare this with the actual distribution of the sample. First draw a histogram with \texttt{freq=FALSE}, then add the theoretical distribution with \rcode{lines}.
  \item If this distribution were from the general and complete "population" of iris sepal lengths, we could say: 20\% of the sepal lengths are smaller than a certain value. Use \rcode{qnorm} to find out this value. What is the limit of this approach?
  \item BONUS: What are the (dis-)advantages of mean and median?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Classical statistics}
% <<ex9sola, eval=FALSE>>=
% # ToDo
% @
% \end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Beta distribution}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Beta distribution: motivating example}
\label{beta}
\pause Imagine you are the scientific advisor to the government of India. \pause \\
It has recently been found that some of the \href{https://aditimukherji.wordpress.com/2012/07/13/how-many-wells-and-tubewells-in-india-no-one-really-knows/}{millions} (\href{http://www.iwmi.cgiar.org/iwmi-tata/PDFs/2012_Highlight-05.pdf}{yes, millions}) of wells contain dangerous levels of arsenic. \pause \\
If more than 25\% of the wells are affected, the government will pass a law constraining well construction. \pause \\
You sample 10 wells and find that 2 surpass the safety limit of arsenic concentration. \pause \alert{What will you do?} \pause \\
To graph the uncertainty, you want to use the beta distribution. \pause \\
You remember (from this class) that for a binomial trial, the two parameters can be defined as:\\
\pause $\alpha-1$ = number of successes\\
\pause $\beta-1$ = number of failures\\
\pause What are the parameters in this case?\\
\pause ~~~~ $\alpha = \pause 2+1 = \pause 3$\\
\pause ~~~~ $\beta = \pause 10-2 + 1 = \pause 9$
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta distribution: some theory + density plot}
\pause
\begin{itemize}[<+->]
\item Continuous, values between 0 and 1
\item Suitable for proportions and probabilities
\item Very versatile, different shapes
\item Used extensively in Bayesian statistics, see e.g. \href{https://journal.r-project.org/archive/2015-2/liu-kong.pdf}{Liu and Kong (2015)}.
\item Two parameters: a=alpha=\rcode{shape1} ~ and ~ b=beta=\rcode{shape2}.
\end{itemize}
\onslide<+->
\begin{exercise}{Beta distribution density}
\begin{enumerate}
\item Plot the beta distribution density (\rcode{dbeta}) for alpa=3 and beta=9.\\
\item If this describes the true distribution of contaminated well proportions across subregions of India, how likely is it to have a sample with 25\% or more of the wells contaminated?\\
\item BONUS: Plot the distribution with \rcode{polygon}.
\end{enumerate}
\end{exercise}
\textcolor{gray}{Two hints:}\\
\onslide<+-> Hint 1: Create a vector from 0 to 1 with, say, 200 values.\\
\onslide<+-> Hint 2: Plot \texttt{dbeta(x)} over x using \texttt{type="l"}.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution to exercise \arabic{exercisecount}: Beta density}
\vspace{-1em}
<<betadensitysol, echo=-1, fig.height=2.5>>=
par(mar=c(3,3,0,0), mgp=c(2,0.7,0), las=1)
proportion <- seq(0,1, len=200)
plot(proportion, dbeta(proportion, 3,9), type="l")
segments(x0=0.25, y0=-1, y1=3.097, col="red")
@
\vspace{-1em}
\pause
<<betamoresol>>=
1-pbeta(0.25, 3,9)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
\pause
Large $\alpha$: HDI (Highest Density Interval) more to the \only<beamer>{\only<+>{\textit{left/right}?}}\only<+->{right}\\
\onslide<+-> Large $\beta$: HDI rather left, lower values\\
\onslide<+-> Both large: \onslide<+-> (\textit{more samples}) \onslide<+-> narrow HDI\\
\vspace{1.5em}
\onslide<+->
<<betadist1, eval=FALSE>>=
install.packages("berryFunctions")
@
\onslide<+->
<<betadist1b, eval=FALSE>>=
library(berryFunctions) # >= version 1.9.6 (2015-12-18)
betaPlot(shape1=alpha, shape2=beta, ...)
betaPlotComp()
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot0>>=
betaPlot(14, 2.4, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot1, echo=1>>=
betaPlot(6, 16, ylim=lim0(5))
text(0.98,3, "In 20 binomial trials
     the expected number of successes is 5
     thus mode= 5/20 = 0.25", adj=1)
abline(v=0.25)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot2>>=
betaPlot(10, 10, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot3>>=
betaPlot(3, 3, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot4>>=
betaPlot(1, 1, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot5>>=
betaPlot(0.8, 2, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta parameters}
<<betaplot6>>=
betaPlot(0.4, 0.4, ylim=lim0(5))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]%{Beta distribution shapes}
<<bet, echo=F, fig.height=4.6, size="footnotesize">>=
library(berryFunctions)
betaPlotComp(oma=c(2,2,2,2), ylim=lim0(4.8),
             shape1=c(0.5, 1:4, 10), textargs=c(y=4), cex=0.75)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta distribution properties}
\pause ~~~~~ $\alert{mean} = \mu = \scalebox{1.3}{$\frac{a}{a+b}$}$ ~~~~~~~~~
\pause $\alert{variance}= \sigma^2 = \scalebox{1.3}{$\frac{ab}{(a+b)^2 * (a+b+1)}$}$\\[\baselineskip]
\pause With these formulas, if a and b $\gg$ 1, you can estimate an approximation to the normal distribution.\\
To get a \& b from mean \& var, see \href{https://stats.stackexchange.com/a/12239}{https://stats.stackexchange.com/a/12239}\\[2em]
\pause ~~~~~ $\alert{mode} = density ~peak = m = \scalebox{1.3}{$\frac{a - 1}{a+b -2}$} ~~~  \textit{ for } a,b > 1$\\[\baselineskip]
\pause If you want to set the mode at a certain value, you can compute beta with\\[1em]
~~~~~ $b = \scalebox{1.3}{$\frac{a-1}{m}$} - a + 2$ ~~~ and alpha with ~~~ $a = \scalebox{1.3}{$\frac{(2-b-1/m)*m}{m-1}$}$
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta distribution specification}
\begin{exercise}{Beta distribution parameter determination}
You want to specify a distribution with the peak at 90\%, reached in a sample of 100.
\begin{enumerate}
\item What are the parameters?
\item What does the distribution look like? (Graph it)
\item BONUS: How does the HDI (highest density interval) width change for a sample size of 10?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Beta distribution parametrization solution}
\vspace{-1em}
<<betapar, echo=-1, fig.height=2.5, size="small">>=
par(mar=c(2,3,0,0))
v <- seq(0,1, len=200)
plot(v, dbeta(v, 91,11), type="l", las=1)
lines(v, dbeta(v, 10,2), col="red")
points(qbeta(c(0.1, 0.9), 91,11), rep(-0.5,2), pch=3)
points(qbeta(c(0.1, 0.9), 10,2), rep(-0.5,2), pch=3, col="red")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Bayesian inference with beta distribution}
Prior: weak knowledge that true proportion of cats among pets must be around 10 to 30\%, but may also be more.\\ \pause
Data: observation in survey: 35 of 100 households with a pet have a cat.\\ \pause
Posterior beta parameters: a\_prior + successes, b\_prior + failures \pause
\vspace{-0.8em}
<<bayesbeta, echo=3:4, size="small", fig.height=2.5>>=
par(mgp=c(3,0.7,0))
x <- seq(0,1, len=200)
betaPlot(3, 9, ylim=lim0(10), cum=F, mar=c(2,2,0,0), keeppar=T)
lines(x, dbeta(x, 3+35, 9+65), lwd=2, col="green4")
abline(v=0.35)
text(0.45,6, "Posterior probability (density)\nfor true population proportion.
Mode = (38-1)/(38+74-2) = 0.336\nHDI (TeachingDemos::hpd)\n90% HDI = 0.27 - 0.41)", adj=0, col="green4")
hdi <- TeachingDemos::hpd(qbeta, shape1=38, shape2=74, conf=0.90)
arrows(x0=hdi[1], y0=dbeta(hdi[1],38,74), x1=hdi[2], col="red", code=3, length=0.1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Shift + scale values}
If values do not lie between 0 and 1, but between m and n, you can transform the raw values (y) to the 0:1 space (y') with\\[1em]
~~~~~~ \scalebox{1.3}{$y'=\frac{(y-m)}{(n-m)}$}\\[1em]
and beta values (y') to raw values (y) with\\[1em]
~~~~~~ \scalebox{1.1}{$y=y'*(n-m)+m$}\\[2em]
Outlook: used for beta regression, see \href{https://journal.r-project.org/archive/2015-2/liu-kong.pdf}{Liu and Kong (2015)}: zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One Inflated Beta Regression. In: the R Journal Vol. 7/2, December 2015
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Shift + scale values}
<<betaregr, echo=2:4, size="small">>=
par(mar=c(2.5,4,1,0.5))
x <- 400:580; m <- 120 ; n <- 570
plot(x, dbeta((x-m)/(n-m),30,4), type="l")
lines(x, dnorm((x-m)/(n-m),30/34, sd=sqrt(120/(34^2*35))), 
      col="red")
text(525,4, "normal\napproximation", col="red")
text(560,5, "shifted\nbeta")
@
\end{frame}


%------------------------------------------------------------%

\begin{frame}[fragile]{Shift + scale values}
\vspace{-1.5em}
<<betaregr2, echo=-1, size="footnotesize", warning=F>>=
par(mar=c(2,5,2,0.5), mgp=c(3,0.7,0))
m <- 120 ; n <- 570; set.seed(1)
x <- rbeta(800,30,4) * (n-m)+m
library(extremeStat) # github.com/brry/extremeStat
plotLfit(distLfit(x, quiet=T), breaks=30, nbest=11, legargs=c(x="left"))
@
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Extreme Value Statistics}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Extreme value statistics (EVS)}
More extensive script version of these slides (in German):\\
\footnotesize
\url{https://github.com/brry/rclick/blob/master/15-Extremwertstatistik.r}\\[2em]
\normalsize
\begin{enumerate}
\item Data
\item Return period, plotting positions
\item Fitting extreme value distribution functions
\item Plotting and computing quantiles from evd
\item L-moments
\item R package \texttt{extremeStat}
\end{enumerate}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Dataset}
Annual streamflow maxima 1976-2010 at a stream in Austria
<<EVS_data>>=
JM <- c(61.5, 77.0, 37.0, 69.3, 75.6, 74.9, 43.7, 50.8,
55.6, 84.1, 43.6, 81.9, 60.1, 72.4, 61.6, 94.8, 82.6, 57.2,
63.1, 73.8, 51.3, 93.6, 56.9, 52.1, 40.4, 48.9, 113.6, 
35.4, 40.1, 89.6, 47.8, 57.6, 38.9, 69.7, 110.8)
@
\pause
Annual maxima must be independent from each other \\ 
-> no extreme event at year-separation used for both years\\[1em]
\pause
The alternative to this Block Maxima (BM) approach is using Peak-Over-Threshold (POT) extremes.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Dataset time series graph}
\vspace{-1em}
<<EVS_data_graph, echo=-1, fig.height=2.4>>=
par(mar=c(2,2,2,0.5), mgp=c(3,0.8,0))
plot(1976:2010, JM, type="l", las=1, ylab="", xlab="",
     main="Annual streamflow maxima [m\U00B3/s]")
# Moving Average (in berryFunctions):
lines(1976:2010, movAv(JM), col="red", lwd=3) 
# can indicate trends or cycles, but:
# window width = "researcher degree of freedom"
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Dataset histgram}
\vspace{-1em}
<<EVS_data_hist, fig.height=3.4>>=
hist(JM, col="salmon", las=1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: empirical quantiles}
<<EVS_empquant>>=
quantile(JM) 
@
\pause
75\% of the annual maxima are smaller than 76.3 m\textsuperscript{3}/s (upper quartile).
This discharche is exceeded in 25 of 100 years.
Statistically, we'd expect an event of this magnitude (or larger) once every \pause
4 years.
Each year, there's a statistical probability of 25\% for 76 m\textsuperscript{3}/s to be reached/exceeded.\\[1em]
\pause
This all assumes a stationary runoff regime in the catchment, i.e. no relevant changes over time in rainfall patterns or landscape composition.\\[1em]
\pause
This is also purely empirical, based on past observations only, with no assumptions
on how the extrema are generally (supposed to be) distributed.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Plotting Positions + Return Period}
Plotting Positions (PP) were used back in the olden days to graphically fit 
extreme value distributions on a Gumbel-scaled axis.\\
\pause
Several methods to compute PP are compared in the mentioned \href{https://github.com/brry/rclick/blob/master/15-Extremwertstatistik.r#L71}{Rclick script.}
\pause
We'll only use the method from Weibull (1939) with $Pne=\frac{R}{n+1}$, 
\textcolor{gray}{but there are also e.g. Hazen (1914) $\frac{R-0.50}{n}$, 
Gringorton (1963) $\frac{R-0.44}{n+0.12}$ or Beard (1943) $\frac{R-0.31}{n+0.38}$}.
\pause
These all overestimate the return period and hence underestimate flood risk (compared to Weibull).
E.g. for 35 years of data, Hazen assigns an RP of 70 years to the highest measured value,
Weibull 36 years.
\vspace{-0.5em}
\pause
<<EVS_plottingpos_comp>>=
m <- sort(JM) # ascendingly sorted maxima
n <- length(m)
Rank <- 1:n
# empirical non-exceedance probability = Percentile:
Pne <- Rank / (n+1) 
# RP: Return Period = annuality = 1/Pe = 1/(1-Pne)
RP <- 1/(1-Pne) 
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Plotting Positions - Graph}
\vspace{-1em}
<<EVS_plottingpos_plot, echo=-1, size="footnotesize", fig.height=2.2>>=
par(mfrow=c(1,3), mar=c(4,4,1,0.5), mgp=c(2.2,0.8,0), las=1)
plot(m,Pne, xlab="Value", ylab="Probability of not being exceeded")
plot(ecdf(JM), ylab="empirical cumulated density")
plot(m,RP, xlab="Streamflow value", ylab="Return Period [years]")
@
\vspace{-0.5em}
\footnotesize
\pause
{\setstretch{0.9}Plot 1 and 2 are almost equal in nature, but the ECDF goes from 0 to 1 exactly.
It leaves no room for potentially even higher or lower values.\\
\pause
The second-highest value is reached or exceeded twice in the 35 years.
Statistically, this occurs once in every 18 years. 
The return period of the third-largest value is 36/3 = 12 years. 
This reciprocal relationship (1/x) causes the counterintuitive leaps in RP.\\}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Fitting the Gamma distribution}
The plotting positions are irrelevant for fitting distributions.
E.g. the parameters of the Gamma-distribution can be determined from the 
statistical moments of the observations - mean, var, skew (non-symmetry), kurtosis (non-normality).
\pause
\vspace{-0.8em}
<<EVS_gammafit, size="scriptsize", fig.height=2, echo=-1>>=
par(mar=c(2,2,2,1), mgp=c(3,0.8,0))
shape <- mean(m)^2/var(m)   ;   rate  <- mean(m)/var(m) 
hist(m, freq=FALSE, col="salmon", 
     main="Gamma is OK for this dataset, but underestimates tail")
Q <- seq(par("usr")[1], par("usr")[2], len=200)
lines(Q, dgamma(x=Q, shape=shape, rate=rate), lwd=4)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Discharge over Return Periods I}
\vspace{-1em}
<<EVS_value_RP_plot, size="scriptsize", fig.height=2.4, echo=-1>>=
par(mar=c(3.2,3,2,0.5), mgp=c(2.1,0.7,0))
# remember: RP   =   1/(1-Pne)   =   1/(1- Rank/(n+1) )
plot(RP, m, ylab="Discharge HQ  [m\U00B3/s]", xlab="Return Period RP  [a]",
     las=1, main="yearly streamflow extrema / return period", pch=20)
RPgamma <- 1/( 1-  pgamma( Q, shape=shape, rate=rate)    )
lines(RPgamma, Q, col="orange", lwd=2)
text(15,79, paste("mean =",round(mean(m),3),"  sd =",round(sd(m),3)),adj=0)
text(15,66, bquote("shape = "* mu^2/sigma*" = "*.(round(shape, 2))), adj=0)
text(15,53, bquote("rate = " * mu/sigma * " = "*.(round(rate,  4))), adj=0)
text(15,40, bquote("scale = "* 1/rate *   " = "*.(round(1/rate,3))), adj=0)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Return levels}
$ RP = \frac{1}{Pe} = \frac{1}{1-Pne} $\\[0.5em]
$ Pne = 1 - \frac{1}{RP} $\\[0.5em]
$ RL = quantile(x, ~~ prob=Pne) $

<<EVS_value_RP_calc>>=
ReturnYears <- c(5,10,20,50)
qgamma(p=1-(1/ReturnYears), shape=shape, rate=rate)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Practicing with the Gumbel distribution}
\begin{exercise}{Extreme value statistics}
\begin{enumerate}
\small
\item Plot a density histogram of the built-in \rcode{Nile} dataset. 
\item Fit the Gamma distribution by estimating its parameters from the sample moments.
$ shape = \mu^2/var$ ~~ ; ~~ $ rate = \mu/var$
\item Fit the Gumbel distribution as well, using \\
$ scale = \sqrt{6}*\sigma/\pi $ ~~ ; ~~ $ loc = \mu-0.5772*scale $
\item Add both distributions to the graph. You can use \rcode{evd::dgumbel}.
\item BONUS: add a legend or label the lines directly
\item Plot streamflow over return period using Weibull plotting positions:\\
\rcode{N\_s <- sort(Nile) ; n <- length(Nile)  ;  RP <- 1/(1-1:n/(n+1))}
\item Using the help of \rcode{?plot.default}, use a logarithmic axis for the RP.
\item BONUS: suppress axis drawing and add \rcode{berryFunctions::logAxis(1)}
\item Add both fitted lines (in the same colors used in the previous plot)
\item From both distributions, estimate the discharge expected with RPs:\\
\rcode{ReturnYears <- c(5,10,20,50,100,200)}
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Solutions to EVD exercise - prob density}
\vspace{-0.8em}
<<EVS_ex_hist, echo=-1, fig.height=2.4, size="footnotesize">>=
par(mar=c(2,2,1,1), mgp=c(3,0.8,0))
hist(Nile, freq=FALSE, col="burlywood", main="Nile", breaks=20)
shape <- mean(Nile)^2/var(Nile)   ;   rate  <- mean(Nile)/var(Nile) 
scale <- sqrt(6)*sd(Nile)/pi  ;  loc <- mean(Nile)-0.5772*scale
Q <- seq(400, 1600, len=200)
lines(Q, dgamma(x=Q, shape=shape, rate=rate), lwd=4, col="blue")
lines(Q, evd::dgumbel(x=Q, loc=loc, scale=scale), lwd=4, col="red")
legend("topright", c("Gamma", "Gumbel"), col=c("blue","red"), lwd=3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Solutions to EVD exercise - EV plot}
\vspace{-0.8em}
<<EVS_ex_plot, echo=-1, fig.height=2.4, size="footnotesize">>=
par(mar=c(2.7,3.7,1,1), mgp=c(2.6,0.7,0), las=1)
N_s <- sort(Nile) ; n <- length(Nile)  ;  RP <- 1/(1-1:n/(n+1))
plot(RP, N_s, ylab="Nile flow", xlab="", log="x", ylim=c(500,1500), 
     xlim=c(1,200), xaxt="n") ; berryFunctions::logAxis(1)
title(xlab="Return period", line=1.5)
lines(1/(1-    pgamma(q=Q, shape=shape, rate=rate)), Q, lwd=4,col="blue")
lines(1/(1-evd::pgumbel(q=Q, loc=loc, scale=scale)), Q, lwd=4, col="red")
legend("bottomright", c("Gamma", "Gumbel"), col=c("blue","red"), lwd=3)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: Solutions to EVD exercise - return levels}
\vspace{-0.8em}
<<EVS_ex_calc, echo=2:4>>=
options(digits=0)
ReturnYears <- c(5,10,20,50,100,200)
      qgamma(p=1-(1/ReturnYears), shape=shape, rate=rate)
evd::qgumbel(p=1-(1/ReturnYears), loc=loc, scale=scale)
options(digits=7)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: L moments I, \url{http://en.wikipedia.org/wiki/L-moment}}
\small
Block maxima should approach the General Extreme Value Distribution (GEV)\\
Peaks over a threshold should approach the General Pareto Distribution (GPD).
<<EVS_lmom_calc>>=
# SAMLMU: Unbiased SAMple L-Moments
moments <- lmom::samlmu(JM, sort.data=TRUE, nmom=3)
# PEL: Parameter Estimation from L-moments
param <- lmom::pelgev(moments) 
moments;   param 
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: L moments II}
\vspace{-1em}
<<EVS_lmom_plot, fig.height=2.2, echo=-1>>=
par(mar=c(2,2,2,1))
hist(JM, freq=FALSE, col="salmon", main="GEV")
lines(Q, evd::dgev(x=Q, loc=param["xi"],
                   scale=param["alpha"], shape=param["k"]), 
      col="purple", lwd=3)
@
\vspace{-0.6em}
<<EVS_lmom_quant, eval=FALSE>>=
lmom::quagev(f=0.99, param) # 99% of values under 127.5
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: extremeStat}
Read the \href{https://cran.r-project.org/web/packages/extremeStat/vignettes/extremeStat.html}{extremeStat vignette}, especially the 
\href{https://cran.r-project.org/web/packages/extremeStat/vignettes/extremeStat.html#extreme-value-statistics-return-periods}{last section} for more info.
<<EVS_ES_calc>>=
library(extremeStat)
Q50 <- distLextreme(JM, gpd=FALSE, quiet=TRUE)
quantile(Q50$returnlev[1:16,"RP.50"])
@
107-132, quite a range! Most suitable distributions agree around 115.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: extremeStat plots: streamflow - return period}
<<EVS_plot, echo=-1, fig.height=3.5>>=
par(mar=c(3,4,1,1))
plotLextreme(Q50)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: extremeStat plots: streamflow distribution}
<<EVS_plot_nbest, echo=-1, fig.height=3.5>>=
par(mar=c(3,4,1,1))
plotLfit(Q50, nbest=17, legargs=list(x="topright"))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: extremeStat plots: streamflow CDF}
<<EVS_plot_cdf, echo=-1, fig.height=3.5>>=
par(mar=c(3,4,1,1))
plotLfit(Q50, cdf=TRUE, legargs=list(x="bottomright"))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: use extremeStat}
\begin{exercise}{extremeStat}
\begin{enumerate}
\item Using distLextreme, printL and plotLextreme in extremeStat, 
explore the extremes of the \rcode{Nile} streamflow.
\item What streamflow is expected once per 200 years?
\item BONUS 1: get uncertainty ranges for the GEV estimate with \rcode{distLexBoot}
\item BONUS 2: use the POT method with a useful truncation
\end{enumerate}
\end{exercise}
\end{frame}
%------------------------------------------------------------%

\begin{frame}[fragile]{EVS: use extremeStat}
<<EVS_ES_Nile, echo=2:3>>=
options(digits=0)
nile <- distLextreme(Nile, RPs=c(50,100,200), quiet=TRUE)
head(nile$returnlev)
options(digits=7)
@
\vspace{-1em}
<<EVS_ES_Nile_explore, eval=FALSE>>=
printL(nile)
plotLextreme(nile)
plotLweights(nile)
nile_b <- distLexBoot(nile, selection="gev")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{10. Statistics}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Simpsons Paradox}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Simpson's Paradox}
\begin{itemize}
\item Kievit et al (2015): \href{http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00513/full}{Simpson's paradox in psychological science: a practical guide} (Frontiers in Psychology)
\item \href{http://vudlab.com/simpsons/}{vudlab app}
\item \href{https://en.wikipedia.org/wiki/Simpson\%27s\_paradox\#Examples}{Wikipedia entry}
\item 2016 example: \href{http://www.nytimes.com/2016/09/28/us/murder-rate-cities.html}{development of crime rates in the USA}
\item \href{https://youtu.be/ebEkn-BiW5k}{minutephysics video (2017)}
\end{itemize}
\label{simpson}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Simpson's Paradox: Kidney stone treatment success rate}
\begin{tabular}{|c|c|c|}
\hline
& \textcolor{ForestGreen}{open surgery} & \textcolor{red}{small puncture}\\
\hline
&&\\
small stones & \onslide<2->{ $\frac{81}{87}$ = \textbf{93\%}} & \onslide<2-> {$\frac{234}{270}$ = 87\%} \\ &&\\
large stones &\onslide<3->{$\frac{192}{263}$ = \textbf{73\%}} & \onslide<3-> {  $\frac{55}{80}$ = 69\%} \\ &&\\
\hline
&&\\
together& $\frac{273}{350}$ = 78\% &   $\frac{289}{350}$ = \textbf{83\%}\\
&&\\
\hline
\end{tabular}\\
\href{https://en.wikipedia.org/wiki/Simpson\%27s\_paradox\#Kidney\_stone\_treatment}{Wikipedia},
\href{http://www.bmj.com/content/309/6967/1480}{Julious + Mullee (1994)}\\
\onslide<4->
In less severe cases (small kidney stones), doctors favor \textcolor{red}{percutaneous nephrolithotomy (which involves only a small puncture)}.
Doctors tend to give the severe cases (large stones) the \textcolor{ForestGreen}{better treatment (open surgery)}.
The success rate is more strongly influenced by the severity of the case than by the choice of treatment.
When the \textcolor{red}{less effective treatment (small puncture)} is applied more frequently to less severe cases, it can appear to be a more effective treatment.
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Simpson's Exercise}
\begin{exercise}{Simpson}
Visualize \datalinkText{farming.txt}, a fictional dataset measuring crop yield on 30 study fields after pesticide application.
\end{exercise}
\end{frame}

%------------------------------------------------------------%

<<simpsonparadox, echo=F, eval=FALSE>>=
# Yield of a crop field goes down with increased pesticide application:
pest <- runif(10, 0, 2)      # random numbers from uniform distribution between 0 and 2
yield <- -3*pest+25+rnorm(10) # linear regression with downwards trend (negative slope)
plot(pest, yield, las=1, xlab="Amount of pesticide applied to field", ylab="Crop yield",
     main="Pesticide application actually decreases yield")

# On previously high performing fields more pesticide was applied (bad study design)
farming <- lapply(1:30, function(field)
  {
  pesticide <- sort(runif(10, field-1, field+1))  # input depending on performance rank of field
  yield <- -3*pesticide+25+rnorm(10) + 5*field
  data.frame(pesticide=round(pesticide,2), yield=round(yield,1), field)
  })
farming <- do.call(rbind, farming) # put lists together in a single data.frame

write.table(farming, "data/farming.txt", row.names=FALSE, quote=FALSE)
@

%------------------------------------------------------------%

\begin{frame}{Farming solution I}
<<farminghw1, echo=FALSE, fig.height=4>>=
par(mar=c(3,3,2,0.5), mgp=c(2,0.7,0))
farming <- read.table("data/farming.txt", header=TRUE)
plot(yield~pesticide, data=farming, las=1, xlab="Amount of pesticide applied",
     ylab="Crop yield", main="Farmers applying pesticides can harvest more!")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Farming solution II}
<<farminghw2, echo=FALSE, fig.height=4>>=
par(mar=c(3,3,2,0.5), mgp=c(2,0.7,0))
cols <- rgb(runif(30), runif(30), runif(30))
plot(yield~pesticide, col=cols[field], data=farming, las=1, pch=3,
    xlab="Amount of pesticide applied", ylab="Crop yield",
    main="On second thought: maybe they shouldn't.")
# function to draw in partial regression line
regression <- function(field)
 {
 x <- farming[farming$field==field, ]
 mod <- lm(yield~pesticide, data=x)
 pesticide <- seq(min(x$pesticide)-0.5, max(x$pesticide)+0.5, length=50)
 lines(pesticide,predict(mod, newdata=data.frame(pesticide)), col=cols[field])
 }
dummy <- sapply(unique(farming$field), regression)
@
\end{frame}

% ToDO: make exercise clearer + Solution code

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Normality tests}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Normality Test: Kolmogorov-Smirnov}
\pause
\begin{itemize}[<+->]
  \item If a population is normally distributed, it is described by only two parameters: the mean (position) and the sd (width, dispersion) of the bell shaped curve.
  \item This is an important assumption for many classical statistical methods.
  \item Whether a dataset is normally distributed can be checked with a histogram (visually effective, but the class limits are subjective), with qqplots (I don't find them very intuitive), or with statistical tests.
\item  \tiny
<<normaltest, echo=T, eval=F, tidy=FALSE>>=
data <- rnorm(1000, mean=97, sd=8.9)
shapiro.test(data)
ks.test(data, "pnorm", mean(data), sd(data))
# if p > 0.05: accept Nullhypothesis that data are normally distributed.

if(!requireNamespace("nortest")) install.packages("nortest")
library(nortest)          # with Lilliefors-correction!
help(package="nortest")
lillie.test(data)  # Lilliefors (Kolmogorov-Smirnov) test for normality
ad.test(data)      # Anderson-Darling test for normality
cvm.test(data)     # Cramer-von Mises test for normality
pearson.test(data) # Pearson chi-square test for normality
sf.test(data)      # Shapiro-Francia test for normality
@
\end{itemize}
\label{nortest}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Normality Test: Kolmogorov-Smirnov}
KS Hypothesis Test: Reject the null hypothesis (H0) that the values are drawn from a normal distribution if
$\textcolor{red}{D} < \frac{k_\alpha}{\sqrt{n}}$.\\[0.1em]
\pause
$\textcolor{red}{D} = max(~|~\textcolor{ForestGreen}{F_{(n)}(x)} - \textcolor{blue}{F(x)}~|~)$~
\textit{Difference between \textcolor{ForestGreen}{empirical} and \textcolor{blue}{statistical (theoretical, population)} Cumulated Density Function (CDF)}\\[0.5em]
\pause
$k_\alpha = \frac{\sqrt{-0.5*ln(\frac{\alpha}{2})}}{\sqrt{n}} ~~ (for~n>35)$
~~ $\alpha$ often 0.05 (95\% confidence)\\[1em]
\pause
<<kstest1, echo=F, fig.height=2.5, out.width='0.9\\textwidth'>>=
par(mar=c(3,3,0.3,0), mgp=c(1.9,0.7,0), las=1)
set.seed(42)
x <- sort(rnorm(30, mean=300, sd=5))
x2 <- ecdf(x)(x)
plot(x, x2, pch=16, cex=0.7, col="forestgreen", ylim=0:1, yaxs="i", ylab="ECDF(x)")
lines(280:320, pnorm(280:320, mean(x), sd(x) ), lwd=1, col="blue")
# Distance between empirical and theoretical cumulated probability
D <- abs(x2-pnorm(x,mean(x),sd(x)))
cols <- round(D,5)==max(round(D,5))
segments(x0=x, y0=pnorm(x,mean(x),sd(x)), y1=x2, col=cols+1)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Normality Test: Kolmogorov-Smirnov}
<<k_alphaE, echo=FALSE, fig.height=3.5>>=
par(mfrow=c(1,2), mar=c(3,3,2,0.5), mgp=c(1.9,0.7,0), las=1)
n <- 0:105
k_alpha <- sqrt(-0.5*log(0.05/2))/sqrt(n)
plot(n, k_alpha, type="l", las=1, main="KS-test critical value",
     xaxs="i", ylim=lim0(1), xlab="sample size n", col="orange")
lines(n, sqrt(-0.5*log(0.10/2))/sqrt(n), col="red")
lines(n, sqrt(-0.5*log(0.01/2))/sqrt(n), col="blue")
textField(c(8,12,15,20), c(0.3, 0.4, 0.5, 0.6), c("0.10", "0.05", "0.01", "alpha"), col=c(2,"orange",4,1))
#
plot(n, k_alpha/sqrt(n), type="l", las=1, main="comparison with D",
     xaxs="i", ylim=lim0(0.2), xlab="sample size n", yaxt="n", col="orange")
axis(2, c(0,0.1,0.2))
lines(n, sqrt(-0.5*log(0.10/2))/n, col="red")
lines(n, sqrt(-0.5*log(0.01/2))/n, col="blue")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Confidence Intervals}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Background confidence intervals}
\pause
\begin{itemize}[<+->]
  \item About 70\% of the values in a Gaussian distribution lie between mean-1sd and mean+1sd, as is shown by \rcode{pnorm(1) - pnorm(-1)}\texttt{: \Sexpr{pnorm(1) - pnorm(-1)}}.\\
  \item 95\% of the values are between mean $\pm$ 1.96 sd, as is shown by \rcode{qnorm(0.975)}\texttt{: \Sexpr{qnorm(0.975)}}. (As the bell curve is symmetrical, we want to know below what value 97.5\% of the values are in the cumulated density).\\
  \item This is the famous parameter in calculating the limits of confidence intervals (CI).
\begin{center}
\onslide<4->
$CI =  \mu \pm p*\frac{sd}{\sqrt{n}}$\\[1ex] %\mu \pm p*\sqrt{\frac{var}{n}} \ \ = \ \
%$p = qt(1-\frac{alpha}{2}, \ df=n-1)$
\onslide<5->
$p = $ \rcode{qt(1-alpha/2,  df=n-1)}
\end{center}
\end{itemize}
\end{frame}
%------------------------------------------------------------%

\begin{frame}[fragile]{Parameter confidence intervals}
\href{http://en.wikipedia.org/wiki/Student\%27s_t-distribution\#Table_of_selected_values}{en.wikipedia.org/wiki/Student's\_t-distribution\#Table\_of\_selected\_values}
For a two-sided confidence interval with \rcode{qt(1-alpha/2,  df=n-1)}:
\begin{center}
\begin{tabular}{| r | l | l | l |}   \hline
       & a=0.01 & a=0.05 & a=0.10 \\ \hline \hline
n=10   & 3.2498 & 2.2622 & 1.8331 \\ \hline
n=30   & 2.7564 & 2.0452 & 1.6991 \\ \hline
n=50   & 2.6800 & 2.0096 & 1.6766 \\ \hline
n=100  & 2.6264 & 1.9842 & 1.6604 \\ \hline
n=1000 & 2.5808 & 1.9623 & 1.6464 \\ \hline
\end{tabular}
\end{center}
\onslide<2>
code for generating this table:
<<cipar, size="small", echo=T, eval=F, tidy=FALSE>>=
alpha <- c(0.01, 0.05, 0.10)
n <- c(10, 30, 50, 100, 1000)
ttab <- t(sapply(n, function(x) qt(1-alpha/2 ,df=x-1)))
colnames(ttab) <- paste0("a=",alpha)
rownames(ttab) <- paste0("n=",n)
ttab
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{CI example}
\begin{exercise}{Confidence intervals} %ex11
\begin{enumerate}
  \item Comment the code below.
  \item plot the points along a number line and add the mean value with \rcode{points} and the confidence interval with \rcode{arrows} with \texttt{angle=90, code=3}. BONUS: plot the points as filled dots in a semitransparent color, see \rcode{rgb}.
\end{enumerate}
\end{exercise}
<<ciex, echo=TRUE, eval=F, tidy=F>>=
values <- rnorm(80, 53, 4)
m <- mean(values)   ; m #
v <- var(values)    ; v #
n <- length(values) ; n #
p <- qnorm(0.975)   ; p #
p <- qt(0.975, df=n-1)  ; p #
cl <- m - p * sqrt(v/n) ; cl #
cu <- m + p * sqrt(v/n) ; cu #
@
\end{frame}

%------------------------------------------------------------%

% \begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}: Confidence intervals}
% <<ex10sola, eval=FALSE>>=
% # ToDo
% @
% \end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{CI in a faster way}
<<ci_ttest1, echo=FALSE, eval=TRUE, tidy=FALSE>>=
values <- rnorm(80, 53, 4)
@
Scripting this manually needs several LOC (lines of code):
<<ci_ttest2, size="small", echo=TRUE, eval=TRUE, tidy=F>>=
m <- mean(values)
v <- var(values)
n <- length(values)
p <- qt(0.975, df=n-1)

m + c(-1,1)* p * sqrt(v/n)
@
\onslide<2>
You can use the side effect of \rcode{t.test}:
<<ci_ttest3, size="small", echo=TRUE, eval=TRUE, tidy=F>>=
t.test(values, conf.level=.95)$conf.int
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{(Linear) regression}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Linear Regression}
This section (linear models) was originally written by Matthias Seibert (GFZ).\\
It is excluded from this main document and can be obtained as \href{https://dl.dropboxusercontent.com/u/4836866/R_course_Berry/RcourseBerry_Mathias.pdf}{pdf}.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Linear Regression}
\href{http://www.econ.queensu.ca/files/other/storks.pdf}{Storks Deliver Babies (p = 0.008)}\\
Fit multiple functions: berryFunctions::mReg. See the mReg sections in the 
\href{https://cran.rstudio.com/web/packages/berryFunctions/vignettes/berryFunctions.html}{Vignette} 
and \href{https://rclickhandbuch.wordpress.com/rpackages/}{Rclick page}

\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{11. Time series handling and analysis}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Date and time formatting}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Char to date / time and back}
\begin{exercise}{char time} %ex
\begin{enumerate}
\item Convert the character string "2017-11-29 13:41:16" to a time object with 
      \rcode{?strptime} (string parsed to time). Check the \rcode{str}ucture.
\item BONUS: reflect the local or GMT time zone.
\item \rcode{?paste} the following charstrings together "14.2.2016" and "17:18", 
      separated with a minus symbol.
\item Convert the result with \rcode{strptime}. 
      Convert it to a number (what does it mean?) and with \rcode{as.POSIXct}.
\item BONUS: format the current \rcode{Sys.Date()} as 
      "Mi, 29.Nov.2017 (= ein Mittwoch im November)". On what weekday were you born?
\item BONUS: Print the names in English, even if the locale is German.
      See \href{https://github.com/brry/rclick/blob/master/13-Zeit\%2CDatum.r\#L102}{Rclick chapter 13}
      on \rcode{?Sys.setlocale}.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Char - Time Solutions}
<<chartime1, size="footnotesize">>=
now <- strptime("2017-11-29 13:41:16", format="%Y-%m-%d %H:%M:%S")
now ; class(now); str(now)
strptime("2017-11-29 13:41:16", format="%F %T", tz="UTC")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Char - Time Solutions}
<<chartime2, size="footnotesize">>=
now <- paste("14.2.2016", "17:19", sep="-")
now <- strptime(now, "%d.%m.%Y-%H:%M")
as.numeric(now) # number of seconds since 1970-01-01
str(as.POSIXct(now))
format( Sys.Date(), "%a, %d.%b.%Y (= some %A in %B)")
format(as.Date("1997-04-13"), "%A") # Born on Sunday
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time sequences}
\begin{exercise}{equally spaced time sequences} %ex
\begin{enumerate}
\item Create a weekly sequence with \rcode{seq()} starting \vspace{-0.7em}
<<tseq_task1>>=
t1 <- as.Date("2007/10/18") # and ending at
t2 <- as.Date("2007/11/25")
@
\item BONUS: How about monthly sequences? (by = number of days not helpful)
\item From the time range "tr", create a sequence in steps of 15 minutes:\vspace{-0.7em}
<<tseq_task2>>=
tr <- strptime(c("05.08.2010, 12:15",
                 "09.02.2013, 14:45"),
               format="%d.%m.%Y, %H:%M")
@
\item Create a data.frame with that time sequence and values from a random walk 
      (see \rcode{rnorm} and \rcode{cumsum}). Both columns should be named aptly.
\item BONUS: Correct the by argument in \rcode{seq(as.Date("2017-08-30"), as.Date("2017-06-30"), by=7)}.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time sequence solutions}
<<time_seq_sol>>=
seq(t1, t2, by=7)
seq(t1,t2+150, by="month") # uses seq.Date
tseq <- seq(tr[1], tr[2], by="15 min")
fakeTS <- data.frame(time=tseq,
                    values=cumsum(rnorm(length(tseq)))
                    )
# str(fakeTS)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time Series aggregation}
\begin{exercise}{TS aggregation} %ex
\begin{enumerate}
\item Plot the random walk time series from the previous task. 
      BONUS: label the axis nicely with \rcode{berryFunctions::monthAxis()}
\item Add a column uniquely identifying the month of each data point.
\item Compute monthly averages with \rcode{?tapply}
\item BONUS: Browse through \href{https://github.com/brry/rclick/blob/master/13-Zeit\%2CDatum.r}{Rclick chapter 13}
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{TS aggregation solutions}
<<time_agg_sol, fig.show="hide">>=
plot(fakeTS, type="l", xaxt="n", las=1)
berryFunctions::monthAxis(mcex=0.5)
#
fakeTS$month <- format(fakeTS$time, "%Y-%m-15")
agg_month <- tapply(X=fakeTS$values, INDEX=fakeTS$month, 
                    FUN=mean)
# compute mean of values, split into month groups

head(agg_month) # View(data.frame(agg_month))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{TS aggregation solutions}
\includegraphics[width=\textwidth]{fig/time_agg_sol-1.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Task}
\pause
Your professor asks you to visually examine temperature and precipitation trends
at certain meteorological stations in Germany.
She hands you the files \datalinkBlob{Potsdam.txt} and \datalinkText{Zugspitze.txt}.
How do you approach the project?\\[1em]
\pause
\scriptsize Data selection, download, processing and saving:\\[-1em]
<<rep1, eval=FALSE, size="scriptsize">>=
library(rdwd) # github.com/brry/rdwd 
links <- selectDWD(c("Potsdam","Zugspitze"), current=TRUE,
                   res="monthly", var="kl", per="hist", outvec=TRUE)
clim <- dataDWD(links)
write.table(clim[[1]], file="data/Potsdam.txt", row.names=F, quote=F)
write.table(clim[[2]], file="data/Zugspitze.txt", row.names=F, quote=F)
@
\normalsize
\vspace{-1em}
\pause
<<todate, eval=F, size="scriptsize">>=
potsdam$date <- as.Date(as.character(potsdam$MESS_DATUM_BEGINN), "%Y%m%d")
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Time series}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Authorship note}
% make note to first slide clickable.
This section (time series) was originally written by Matthias Seibert (GFZ).\\
It is currently excluded from this main document but can be obtained as \href{https://github.com/brry/course/raw/master/RcourseBerry_Mathias.pdf}{pdf}.

<<librariests>>=
library(xts)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{12. Spatial data and GIS functionality}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Geostatistics: Kriging}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Overview}
Geostatistics: Kriging - spatial interpolation between points, using semivariance
\begin{enumerate}
\item Packages
\item read shapefile
\item Variogram
\item Kriging
\item Plotting
\end{enumerate}

This material has also been featured by Packt publishing:\\
\href{https://datahub.packtpub.com/analytics/kriging-interpolation-geostatistics/}{datahub.packtpub.com/analytics/kriging-interpolation-geostatistics}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: packages}
<<krig_pack_inst, eval=FALSE>>=
# install packages if needed:
if(!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(rgeos, sf, geoR, berryFunctions) 
@
Alternatively:
<<krig_pack_lib, eval=FALSE>>=
library(sf)   # for st_read (read shapefiles), 
              # st_centroid, st_area, st_union
library(geoR) # as.geodata, variog, variofit,
              # krige.control, krige.conv, legend.krige
@
<<krig_pack_lib2, echo=FALSE>>=
suppressMessages(library(rgeos))
suppressMessages(library(sf))
suppressMessages(library(geoR))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: read shapefile / few points for demonstration}
<<krig_pack_shp, echo=-1>>=
par(mar=c(4,4,1,1), mgp=c(2.5,0.8,0), las=1)
x <- c(1,1,2,2,3,3,3,4,4,5,6,6,6)
y <- c(4,7,3,6,2,4,6,2,6,5,1,5,7)
z <- c(5,9,2,6,3,5,9,4,8,8,3,6,7)
plot(x,y, pch="+", cex=z/4)
@
\vspace{-2em}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: read shapefile II}
<<krig_pack_shp2>>=
GEODATA <- as.geodata(cbind(x,y,z))
plot(GEODATA)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Variogram I}
<<krig_var, size="scriptsize">>=
EMP_VARIOGRAM <- variog(GEODATA)
FIT_VARIOGRAM <- variofit(EMP_VARIOGRAM)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Variogram II}
<<krig_var_plot>>=
plot(EMP_VARIOGRAM)
lines(FIT_VARIOGRAM)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Kriging}
<<krig_krig>>=
res <- 0.1
grid <- expand.grid(seq(min(x),max(x),res),
                    seq(min(y),max(y),res))
krico <- krige.control(type.krige="OK",
                       obj.model=FIT_VARIOGRAM)
krobj <- krige.conv(GEODATA,
                    locations=grid, krige=krico)
# KRigingObjekt
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Plotting I}
<<krig_plotc, eval=F>>=
image(krobj, col=rainbow2(100))
legend.krige(col=rainbow2(100),
             x.leg=c(6.2,6.7), y.leg=c(2,6),
             vert=T, off=-0.5,
             values=krobj$predict)
contour(krobj, add=T)
colPoints(x,y,z, col=rainbow2(100), legend=F)
points(x,y)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Plotting II}
<<krig_plotd, echo=F, width="\\textwidth">>=
image(krobj, col=rainbow2(100))
legend.krige(col=rainbow2(100), x.leg=c(6.2,6.7), y.leg=c(2,6), vert=T, off=-0.5, values=krobj$predict)
contour(krobj, add=T) ; colPoints(x,y,z, col=rainbow2(100), legend=F); points(x,y)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Plotting III}
<<krig_plota, width="\\textwidth">>=
library("berryFunctions") # scatterpoints by color
colPoints(x,y,z, add=F, cex=2, legargs=list(y1=0.8,y2=1))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: Plotting IV}
<<krig_plotf, width="\\textwidth">>=
colPoints(grid[ ,1], grid[ ,2], krobj$predict, add=F,
          cex=2, col2=NA, legargs=list(y1=0.8,y2=1))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Kriging: All in one script, for reference}
<<krig_allinonescript, eval=FALSE, size="tiny">>=
if(!requireNamespace("pacman", quietly=TRUE)) install.packages("pacman")
pacman::p_load(geoR, berryFunctions) # installs packages if needed
# berryFunctions: seqPal, distance, seqR, colPoints
# geoR: as.geodata, variofit, variog, krige.conv, krige.control

K_X <- c(4,4,5,5,6,6,6,7,7,8,9,9,9)
K_Y <- c(6,9,5,8,4,6,8,4,8,7,3,7,9)
K_Z <- c(5,9,2,6,3,5,9,4,8,8,3,6,7)
K_COLS <- seqPal()
K_MDIST <- max(distance(K_X,K_Y))
K_RESOLUTION <- median(distance(K_X,K_Y))/10

K_GEODATA <- as.geodata(cbind(K_X,K_Y,K_Z))
K_VARIOGRAM <- variofit(variog(K_GEODATA, max.dist=K_MDIST))
K_GRID <- expand.grid(seqR(K_X, by=K_RESOLUTION, extend=0.1),
                      seqR(K_Y, by=K_RESOLUTION, extend=0.1))
K_OK <- krige.conv(K_GEODATA, locations=K_GRID, 
        krige=krige.control(type.krige="OK", obj.model=K_VARIOGRAM))

geoR:::image.kriging(K_OK, col=K_COLS)
colPoints(K_X, K_Y, K_Z, col=K_COLS, zlab="Kriging", cex=1)
points(K_X, K_Y)

# optional: interactive map:
pacman::p_load(raster, mapview) # installs packages if needed
K_RASTER <- raster::rasterFromXYZ(cbind(K_GRID, temp=K_OK$predict), 
                          crs="+proj=longlat +datum=WGS84 +no_defs") 
mapview::mapview(K_RASTER, col.regions=seqPal(256))
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time for a real dataset}
Precipitation from ca 250 gauges in Brandenburg as Thiessen Polygons with steep gradients at edges:\\[\baselineskip]
\includegraphics[width=\textwidth]{./externalfig/PrecBRB.PNG}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Time for a real dataset}
\begin{exercise}{Kriging} %ex
\begin{enumerate}
  \item Load and plot the shapefile in \datalinkRaw{PrecBrandenburg.zip} with \rcode{sf::st\_read}.
  \item With \rcode{colPoints} in the package \texttt{berryFunctions}, add the precipitation values at the centroids of the polygons.
  \item Calculate the variogram and fit a semivariance curve.
  \item Perform kriging on a grid with a useful resolution (keep in mind that computing time rises exponentially with grid size).
  \item Plot the interpolated values with \rcode{image} or an equivalent (\href{http://RclickHandbuch.wordpress.com}{Rclick} 4.15) and add contour lines.
  \item What went wrong? (if you used the defaults, the result will be dissatisfying.) How can you fix it?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.1-2: Kriging Data}
<<ex_krig_data, eval=T, size="small", fig.show="hide">>=
# Shapefile:
p <- sf::st_read("data/PrecBrandenburg/niederschlag.shp", 
                 quiet=TRUE)
# Plot prep
pcol <- colorRampPalette(c("red","yellow","blue"))(50)
clss <- berryFunctions::classify(p$P1, breaks=50)$index
# Plot
par(mar = c(1, 1, 1.2, 1)) # for sf plots / colPointsLegend
sf:::plot.sf(p, col=pcol[clss], max.plot=1) # P1: Precipitation
# kriging coordinates
cent <- sf::st_centroid(p)
berryFunctions::colPoints(cent$x, cent$y, p$P1, add=T, cex=0.7,
                          legargs=list(y1=0.8,y2=1), col=pcol)
points(cent$x, cent$y, cex=0.7)
@

<<ex_krig_oldwithsp, eval=FALSE, echo=FALSE>>=
library(maptools)
p2 <- rgdal::readOGR("data/PrecBrandenburg/niederschlag.shp", verbose=FALSE)
cent2 <- as.data.frame(rgeos::gCentroid(p2, byid=TRUE)@coords)
plot(p2, col=pcol[clss])
colPoints(cent2$x, cent2$y, p2$P1, add=T,legend=T,legargs=list(y1=0.8,y2=1), col=pcol); points(cent2$x, cent2$y)
colPoints(p2$x, p2$y, p2$P1, add=F, asp=1)
plot(p2, add=T)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3: Variogram}
<<ex_krig_vario, eval=T, size="scriptsize", fig.show="hide">>=
library(geoR)
# Semivariance:
geoprec <- as.geodata(cbind(cent$x,cent$y,p$P1))
vario <- variog(geoprec, max.dist=130000)
fit <- variofit(vario)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.3: Variogram}
<<ex_krig_visvario, echo=-1, size="scriptsize", fig.height=2.5>>=
par(mfrow=c(1,2), mar=c(3,4,2,0.2), mgp=c(2,0.7,0))
plot(vario) ; lines(fit)
# distance to closest other point:
d <- sapply(1:nrow(cent), function(i) min(berryFunctions::distance(
                          cent$x[i], cent$y[i], cent$x[-i], cent$y[-i])))
hist(d/1000, breaks=20, main="distance to closest gauge [km]")
mean(d) # 8 km  - grid resolution in next slide
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.4-5: Kriging}
<<ex_krig_kriging, eval=T, size="small", fig.show="hide">>=
# Kriging:
res <- 1000 # 1 km, since stations are 8 km apart on average
grid <- expand.grid(seq(min(cent$x),max(cent$x),res),
                    seq(min(cent$y),max(cent$y),res))
krico <- krige.control(type.krige="OK", obj.model=fit)
krobj <- krige.conv(geoprec, locations=grid, krige=krico)

# Set values outside of Brandenburg to NA:
grid_sf <- sf::st_as_sf(grid, coords=1:2, crs=sf::st_crs(p))
isinp <- sapply(sf::st_within(grid_sf, p), length) > 0
krobj2 <- krobj
krobj2$predict[!isinp] <- NA
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Solution for exercise \arabic{exercisecount}.5: Kriging Visualization}
<<ex_krig_vis, echo=-(1:3), size="small", fig.height=2.5, warning=FALSE>>=
par(mar=c(0,3,0,3))
p <- sf::st_read("data/PrecBrandenburg/niederschlag.shp", quiet=TRUE)
pcol <- colorRampPalette(c("red","yellow","blue"))(50)
geoR:::image.kriging(krobj2, col=pcol)
colPoints(cent$x, cent$y, p$P1, col=pcol, zlab="Prec", cex=0.7,
     legargs=list(y1=0.1,y2=0.8, x1=0.78, x2=0.87, horizontal=F))
plot(p, add=T, col=NA, border=8)#; points(cent$x,cent$y, cex=0.8)
@
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{R as GIS}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{interactive shapefile editing - \href{http://r-spatial.org}{http://r-spatial.org}}
\pause
This is R. There is no if. Only how.
\pause
<<shp_int, eval=FALSE, size="scriptsize">>=
# Data and Packages:
download.file(
  "https://github.com/brry/course/raw/master/data/PrecBrandenburg.zip", 
  destfile="prec.zip")
unzip("prec.zip")

library(sf)
library(mapview)
library(mapedit)

p <- sf::st_read("data/PrecBrandenburg/niederschlag.shp")
map <- mapview::mapview(p) 
map

p2 <- mapedit::editMap(map) # add polygons, lines, points, rectangles
mapview::mapview(p2$finished)
names(p)[2] = "x1" # x column problem, see Issue 2017-12-05
p3 <- mapedit::editFeatures(p)
?franconia # from mapview package
ed <- mapedit::editFeatures(franconia[1:5,])
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{shapefile operations}
sf replaces the old sp package since 2017 (sp will be deprecated). \\
Vignettes:\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf1.html}{1. intro: simple features, geometry, reading/writing, projections, units}\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf2.html}{2. reading/writing, conversion}\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf3.html}{3. transformation, coordinate reference systems, geometrical operations}\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf4.html}{4. subsetting, aggregation, joining by attribute / geometry}\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf5.html}{5. plotting, projections}\\
\href{https://cran.r-project.org/web/packages/sf/vignettes/sf6.html}{6. miscellaneous}\\
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{point data (coordinates) - leaflet}
<<coord_data>>=
ddd <- read.table(header=TRUE, sep=",", as.is=TRUE, text="
lat, lon, city, LOA # LOA: Level of Awesomeness
48.858271,   2.294245, Paris , 5
51.503162,  -0.131082, London, 3
52.514687,  13.350012, Berlin, 6
52.407160,  12.972761, Golm  , 9
")
ddd$display <- berryFunctions::popleaf(ddd)
@
\pause
Interactive plots: \vspace{-0.8em}
<<coord_leaflet, eval=FALSE>>=
library(leaflet)
leaflet(ddd) %>% addTiles() %>%
  addCircleMarkers(~lon, ~lat, popup=~display)
@
\vspace{-0.8em}
\href{https://rstudio.github.io/leaflet/basemaps.html}{Different background maps}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{point data (coordinates) - OSMscale}
Static maps: (\href{https://github.com/brry/OSMscale/#installation}{OSMscale installation instructions})\vspace{-0.8em}
<<coord_OSMscale, eval=TRUE>>=
library(OSMscale)
pointsMap(lat, lon, data=ddd, quiet=TRUE)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{R geo, further material}
Use the sf, mapview, osmar and osmplotr packages!\\[1em]
Combine city names with geolocations:\\ \href{http://blog.revolutionanalytics.com/2015/11/marriott.html}{blog.revolutionanalytics.com/2015/11/marriott.html}\\[1em]
For this section (spatial data / GIS), a lot was originally written by Matthias Seibert (GFZ). 
With the advance of the \rcode{sf} package (late 2016), that material is mostly outdated.
Until new material is created here, his slides can be obtained as \href{https://github.com/brry/course/raw/master/RcourseBerry_Mathias.pdf}{pdf}.
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{NETcdf files}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{read nc files: \rcode{ncdf4::nc\_open}}
Install mhmVis with the instructions on github:\\
\href{https://github.com/brry/mhmVis\#installation}{github.com/brry/mhmVis}\\
Get the example file: \datalinkRaw{tavg.zip}
<<read_nc>>=
unzip("data/tavg.zip", exdir="data")
library(mhmVis)
nc <- read_nc("data/tavg.nc")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{visualize nc files: \rcode{mhmVis::vis\_nc}}
<<vis_nc, fig.width=5, fig.height=5, out.width='0.55\\textwidth'>>=
vis_nc(nc, cex=11.5)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{visualize nc files}
\rcode{mhmVis::vis\_nc\_all} and \rcode{mhmVis::vis\_nc\_film}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\section{13. Final tasks}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Practice tasks}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}
\begin{exercise}{Final exercises to solve at home I} %ex22
\begin{enumerate}
  \item What is the difference between \rcode{c(5,3,-8)} and \rcode{vec $<-$ c(5,3,-8)}?
  \item What methods do you know to generate a vector?
  \item What are object, element, command, argument, assignment, Workspace, Working Directory?
  \item What data and object types do you know?
  \item How do you call the help about the \rcode{lines} command?
  \item How do you read a text file? What are the main arguments of the function?
  \item How do you examine the imported table?
  \item How do you obtain / change subsets of the table (column, row, element)?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}
\begin{exercise}{Final exercises to solve at home II} %ex23
\begin{enumerate}
  \item How often is Peter Pan mentioned in the E-book? \datalinkText{peterpan.txt}. 
        Exclude the meta data about the book!
  \item Interpret the results from \rcode{pairs(iris)} and \rcode{cor(iris[ ,1:4])}. Why does \rcode{cor(iris)} not work?
  \item What are the most important functions and arguments for creating graphics?
  \item Write a for loop including a while statement to distribute points randomly, but with a certain minimal distance to each other, along a line (segment sampling design). A solution is in my \href{http://rclickHandbuch.wordpress.com/hauptseite}{RclickHandbuch} Chapter 10.4.
  \item What functions and packages are useful for dealing with time series?
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Exam task}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}
\begin{exercise}{Final exam} %
{\footnotesize
\begin{enumerate}
  \item Download a long time series (e.g. weather data from DWD, NOAA), see \hyperlink{realdata}{slide \ref{realdata}}.
  \item Read the data into R and control the data types. Change the date (or time) to appropriate types with \rcode{as.Date}, \rcode{as.POSIXct} or \rcode{strptime}.
  \item Write a subsection of the data (eg your birth year) to a tab-separated file so it's easy to copypaste this to Excel/Calc.
  \item Plot the development of some aggregate (e.g. monthly 90\% Quantile of windspeed, annual precipitation sum or temperature mean depending on \href{ftp://ftp-cdc.dwd.de/pub/CDC/observations_germany/climate/hourly/}{hour of the day}).
  Hints: \rcode{tapply}, \rcode{strftime}, \rcode{berryFunctions::monthLab}
  \item Examine \rcode{cor}relations between variables.
  \item Write a small report on your data analysis project with max 3 pages, including (beautiful) graphs. You can mail the code in a separate file.\\
  \alert{This is a requirement for the participation certificate with credit points.}
  \item BONUS 1: Write the report via Rnw, Rhtml, Rmd or Rpres (see \hyperlink{rnw}{slide \ref{rnw}}).
  \item BONUS 2: Make some interactive stuff (e.g. user can choose decade of analysis), e.g. via \href{http://www.htmlwidgets.org}{HTMLwidgets} or \href{http://shiny.rstudio.com}{Shiny} (\href{http://biostatistics.dk/useR/IntGraph.html\#1}{see more}). This is a lot of initial effort, but you'll enable an awesome interactive graphical analyses!
\end{enumerate}
}
\end{exercise}
%\vspace{1em}
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\section{Course plan}
%------------------------------------------------------------%
%------------------------------------------------------------%

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Session 1/4: Why R, read file, select and plot data}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Session 1: Aim (Chapter 1)}
\label{plansessionone}
\pause get a general impression on how R works, without going too much into technical detail\\
\pause afterwards, you should be able to:
\pause
\begin{itemize}[<+->]
\item start a new script in Rstudio and execute lines of code
\item read a data file into R
\item select a column and rows that fullfill a certain criterion
\item generate basic graphics with annotation and added elements
\item open and read the documentation for R functions
\end{itemize}
\onslide<+->
\vspace{2em}
\hyperlink{iderstudio}{Jump to Rstudio}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Session 1: Recap \footnotesize{(They tried to make me go to recap and I said, 'Yes, yes, yes.')}}
\pause
\begin{itemize}[<+->]
  \item R is awesome. You're here, thus you will be R-some, too
  \item Console for code execution (R), ready with \rcode{$>$}, waiting with \rcode{$+$}
  \item Script for code writing (you) + exchange
  \item Objects are created with the assignment operator \rcode{$<$-}%, see \rcode{ls()} % in the workspace
  \item Get help with \rcode{help(median)}, \rcode{?matrix}, or pressing F1
  \item Create vectors with \rcode{c(42,3,-4)}, \rcode{1:n}
  \item \rcode{data.frame}s hold tables with one data type per column
  \item \rcode{read.table}, with \texttt{header=TRUE} to read files into R
  \item Index objects with \rcode{values[8:5]}, \rcode{tab[4,2:6]}
  \item df columns with \rcode{tab[ ,3]}, \rcode{tab[ ,"precip"]}, \rcode{tab\$wind}
  \item \rcode{hist(vals)}; \rcode{plot(x,y, las=1, pch=16, type="b")}
\end{itemize}
\onslide<+-> The homework is at \url{https://github.com/brry/course/blob/master/uni.md\#homework}
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Session 2/4: Objects, file reading, Rstudio}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Session 2: Aim (Chapters 2  - 4.3)}
\pause - itensify and fortify the knowledge obtained in session 1\\
\pause - learn about Rstudio and objects\\[0.5em]
\pause afterwards, you should be able to:
\pause
\begin{itemize}[<+->]
% \item install and load add-on packages written by the R community
\item find the appropriate place and way to get help if you're stuck
\item distinguish common data and object types
\item use Rstudio more effectively
% \item explain the difference between object types and data types
% \item read 'medium difficult' files into R
% \item merge two datasets together
% \item ignore NAs
% \item apply a function to each column / row of a dataset
% \item know where to look if you need to
%    \begin{itemize}[<+->]
%    \item create matrices and lists and index each to get subsets
%    \item apply a function to each element in a list (or vector)
%    \end{itemize}
\end{itemize}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Session 2: Take home message}
\begin{itemize}[<+->]
% \item Packages are basically (documented) scripts from other people $\rightarrow$ \rcode{install.packages} and \rcode{library}
\item Reading data: \rcode{setwd}, \rcode{dir}, \rcode{read.table}, \rcode{str}
% \item \rcode{read.table} arguments: header=TRUE, sep="\textbackslash t", dec=",", skip, fill, comment.char, na.strings, \textit{many more}
\item Function documentation with \rcode{help} (or F1), \href{www.StackOverflow.com}{StackOverflow} for questions, Reference Cards (\hyperlink{refcards}{slide \ref{refcards}}) for an overview and books / tutorials (\hyperlink{books}{slide \ref{books}}) for self-learning
% \item factors (categories, groups) are integers internally, useful for color specification in plotting, dangerous when converting to \rcode{as.numeric}!
\item Rstudio is awesome!
\item Objects (vector, data.frame, matrix, list, function) can have several data types (numeric, logical, character), see \hyperlink{datatypes}{slide \ref{datatypes}}
% \item \rcode{rbind} and \rcode{cbind} to join data.frames, \rcode{merge} to (surprise) merge them.
% \item \rcode{na.rm} argument in many functions, \rcode{na.omit} command otherwise
\end{itemize}
\end{frame}



%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Session 3/4: if-else conditionals, for loops}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{to R or not to R}
\begin{center}
\pause
\textit{Lucius Annaeus Seneca (4BC - 65AD):}\\[2em]
\pause To err is human\\[1em]
\pause to \includegraphics[width=1cm]{externalfig/Rlogo.png} ~ is better
\end{center}
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Session 3: Aim (Chapter 7.1 + 7.2)}
\pause - conditional code execution (if-else)\\
\pause - repetitional coding (for-loops)\\
\pause afterwards, you should be able to:
\pause
\begin{itemize}[<+->]
% \item create a plot with multiple panels
% \item reproducibly save figures with useful settings
\item make reasonable guesses about logical values by looking at code
\item write conditionally executed code using if/else
\item decide whether to use \rcode{if(cond) A else B} or \rcode{ifelse(cond, A, B)}
\item explain the concept of a loop
\item write simple for-loops
% \item structurally know how to use the lapply function
\end{itemize}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}{Recap from last two sessions}
% Please fill out the recap online:\\[1em]
% \href{http://bit.ly/recapR}{bit.ly/recapR}
% \end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Session 3: Recap}
\begin{itemize}[<+->]
% \item Create project folder with raw data set(s) and empty (or given) script
% \item set up script: comments on analysis, \rcode{setwd}, \rcode{dir}
% \item Read data: \rcode{read.table}, \rcode{str}
% \item Percentile: \rcode{Q90 <- quantile(weather\$rain, probs=0.9)}
% \item Select data: \rcode{weather[ weather\$rain >= Q90, "temp" ]}
% \item Multiple figures in one graph with \rcode{par(mfrow)} / \rcode{par(mfcol)} or \rcode{layout}
% \item Export graphics with \rcode{png} or \rcode{pdf} with good size and resolution settings.
\item \rcode{if(TRUE) message("Yo!") else message("Dude...")}
% \item be careful with line breaks
\item \rcode{ifelse(c(T,T,F,T), 7, else 7.3)} for vectors
\item for loops repeat a block of code with a different \rcode{i} each time
\item \rcode{for(i in 1:20) plot(df[,i], main=colnames(df)[i])}
\item \rcode{for(cn in colnames(df)) plot(df[,cn], main=cn)}
\item for loops should not be called too often, as they are slow
\item instead: vectorize, use lapply, write C++ code
\end{itemize}
% \onslide<+->  \href{http://bit.ly/recapRif}{bit.ly/recapRif}
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Session 4/4: functions and apply loops}
%------------------------------------------------------------%
%------------------------------------------------------------%

% \begin{frame}{Unicode}
% \center \includegraphics[height=0.65\textheight]{externalfig/rtl.png}\\
% Collaborative editing can quickly become a textual rap battle fought with increasingly convoluted invocations of U+202a to U+202e (\href{https://xkcd.com/1137/}{xkcd.com/1137})
% \end{frame}

%------------------------------------------------------------%

\begin{frame}{Today's plan}
\begin{enumerate}[<+->]
  \item Recap if else + for loop
  \item Writing functions
  \item optional: debugging functions
\end{enumerate}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Recap \alert{if else} I}
\begin{enumerate}
\item Create a new R file and write \rcode{x <- 3.14} into it.
\item Now  assign the absolute value of x to \rcode{y} by using conditional code execution (control structures).
\item \rcode{source} the complete document.
\item Test the result of y by setting \rcode{x} to a negative number in the script and running the document again.
\item BONUS: Make it also work for vectors like \rcode{x <- (-5):8} .
\item BONUS 2: Which R function gives the absolute value? How is it implemented? \\
    What's in \href{https://github.com/wch/r-source/blob/trunk/src/main/names.c#L278}{github.com/wch/r-source ~-> src/main/names.c L278} and
    \href{https://github.com/wch/r-source/blob/trunk/src/main/arithmetic.c#L1315}{-> src/main/arithmetic.c L1315}?
\end{enumerate}
\pause
<<ifelserecap>>=
x <- -5:8
y <- ifelse(x<0, -x, x)
y
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Recap \alert{if else} II}
<<ifelserecap2>>=
(  requireNamespace("some_package", quietly=TRUE)  )
@
invisibly returns TRUE if it succeeds loading a package. The outer brackets are for printing in the slides.
\begin{enumerate}
\item Use it to conditionally install the package \href{https://cran.r-project.org/package=quantmod}{quantmod} (i.e. if it is not already available).
\end{enumerate}
\pause
<<ifelserecap3, size="small">>=
if(!requireNamespace("quantmod")) install.packages("quantmod")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Recap loops and conditions}
\pause
\begin{exercise}{conditional loop}
Repetition from last week with the built-in dataset \rcode{quakes} (locations of earthquakes off Fiji)
\begin{enumerate}
\item Create a multiple figure graph with \rcode{par(mfrow=c(2,3))}
\item With a for loop, create a histogram of each column in \rcode{quakes}. (One hist per panel).
\item Suppress the x and y axis label (using an empty label) in all plots (\texttt{xlab, ylab}).
\item Using conditional code execution, write a y axis label in the upper left panel (\rcode{title}).
\item BONUS1: Using \rcode{\%in\%}, how can you write a label in both left panels?
\item BONUS2: use the column name as titles for each graph.
\item BONUS3: use the same y axis limit (\texttt{ylim}) in each panel.
\item BONUS4: generally improve the graphic labeling, spaces etc.
\end{enumerate}
\end{exercise}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{conditional loop exercise solution}
\vspace{-0.5em}
<<conditional_loop, eval=TRUE, size="scriptsize", fig.height=2.7>>=
par(mfrow=c(2,3), mar=c(3,3,2,0.5), mgp=c(2,0.7,0), las=1)
for(c in colnames(quakes))
 {
 hist(quakes[,c], main=c, xlab="",ylab="", ylim=c(0,300), col="coral")
 if(c=="mag") title(ylab="Number of Obs")
 }   #  if(c %in% c("lat","mag")) title(ylab="Number of Obs")
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}{Now let's start learning about functions}
\hyperlink{functions1}{Jump to Functions}
\end{frame}

%------------------------------------------------------------%

% \begin{frame}{Small research project}
% Please write down the answers to the following questions / instructions as pseudocode
% \begin{itemize}
% \item What do you do to start a (small) research project?
% \item Read a file into R where columns are tab-separated and the decimal marker is German.
% \item In a data set with monthly weather records (\datalinkText{Potsdam.txt}): Get the average temperature of months with more than 90 mm rainfall.
% \item Visually compare wind speed and rainfall.
% \item Describe and visualize the distribution of relative humidity.
% \end{itemize}
% <<weatherproject, eval=FALSE, echo=FALSE>>=
% wetter <- read.table("data/Potsdam.txt", header=T)
% hist(wetter$NIEDERSCHLAGSHOEHE, breaks=30, col="salmon")
% @
% \end{frame}

%------------------------------------------------------------%

% \begin{frame}{Recap, Homework}
% Please select the topic(s) for next week online:\\[1em]
% \href{http://bit.ly/selectR}{bit.ly/selectR}
% \end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Session x: Recap all}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}[fragile]{Floyd Recap}
Download the recap tasks at \datalinkRaw{FloydRecap.pdf}
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Floyd Recap Solutions}
1. \vspace{-1em}
<<floyd_read, eval=FALSE>>=
setwd("S:/Dropbox/R/Project")
reed <- read.table("file.name", header=T, sep="\t", skip=2)
@

2. Spaces in column names, 
comments in the middle of data fields (use NA instead), 
tab-stop separated columns are not the safest option (semicolon ";" is better).
\rcode{str(reed)} output: \vspace{-1em}
<<floyd_str, eval=F, size="small">>=
data.frame, n observations in 4 variables (rows, columns)
$Site         : factor with n levels ...
$moisture     : factor with 3 levels "wet","moist",...: 1 2 2...
$plant.height : int 154 120 173 ...
$stem_diameter: num 1.80.95 2.6 ...
@

3. 
see \hyperlink{datatypes}{slide \ref{datatypes}}. 
\rcode{c(pi,"pi")} gives a vector with charstrings, number gets converted in order of coercion.
You cannot compute with a characterstring, but you could run \rcode{as.numeric(c(pi,"pi")[1])*1.8}.
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Floyd Recap Solutions}
4. join "reed" with second dataset "chem":\vspace{-1em}
<<floyd_merge, eval=FALSE>>=
merge(reed, chem, by.x="Site", by.y="columname", all=TRUE)
@
\vspace{-1em}5.\vspace{-1em}
<<floyd_scat, eval=FALSE>>=
plot(reed$chem, reed$growth)
@
\vspace{-1em}6.\vspace{-1em}
<<floyd_mp, eval=FALSE, size="small">>=
par(mfrow=c(2,3), mar=c(2.9,3,1,0.5), mgp=c(2.1,0.7,0), las=1)
plot(a,b)
plot(C,D, col="pink")
...
@
\vspace{-1em}7-9.\vspace{-1em}
<<floyd_multipanel, fig.show="hide">>=
par(mfrow=c(4,4), mar=rep(0,4), oma=c(3,5,2,1), las=1)
for(i in 1:16)
  {plot(rnorm(20), type="l", yaxt="n", xaxt="n")
  if( i %in% c(1,5,9,13) ) axis(side=2)
  }
title(ylab="hi there", outer=TRUE, cex.lab=2)
title(main="I'm cool", outer=TRUE)
box("outer", col="blue", lwd=5)
@
\end{frame}

%------------------------------------------------------------%

\begin{frame}[fragile]{Floyd Recap Solutions}
\includegraphics[width=\textwidth]{fig/floyd_multipanel-1.pdf}
\end{frame}


%------------------------------------------------------------%
%------------------------------------------------------------%
\subsection{Feedback, additional material}
%------------------------------------------------------------%
%------------------------------------------------------------%

\begin{frame}{Feedback}
\center{
Please fill out the feedback form at\\[1em]
\href{https://bit.ly/feedbackR}{bit.ly/feedbackR}\\[1em]
(it only takes a few minutes and helps to improve the course)\\[1em]
Thanks!\\[1em]
}
\end{frame}

%------------------------------------------------------------%
%------------------------------------------------------------%
\end{document}
%------------------------------------------------------------%
%------------------------------------------------------------%

